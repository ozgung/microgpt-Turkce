{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ozgung/microgpt-Turkce/blob/main/microgpt_T%C3%BCrk%C3%A7e.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QtZhh4rYb6S"
      },
      "source": [
        "# MicroGPT-Türkçe\n",
        "Kod: Andrej Karphaty\n",
        "\n",
        "Türkçe anlatım ve grafikler: Özgün Genç"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Du-f9vMsbvNw"
      },
      "source": [
        "> GPT’yi saf, bağımlılıksız Python ile eğitmenin ve çıkarım yapmanın en “atomik” yolu.\\\n",
        "> Bu dosya algoritmanın tamamı.\\\n",
        "> Geri kalan her şey sadece verimlilik.\\\n",
        "> @karpathy\n",
        "\n",
        "200 satırda GPT eğiten ve çıkarım (inference) yapan microgpt projesinin Türkçe açıklamasına hoşgeldiniz. Aşağıda kodu aşama aşama ve satır satır inceleyeceğiz.\n",
        "\n",
        "Andrej Karphaty bu kodu ve blog yazısını yakın zamanda yayımladı (Şubat 2026). Kodda neredeyse hiç değişiklik yapmadım ama bol bol yorum ekledim. Ayrıca kodda olan biten her şeyi ve kullanılan teknikleri uzun uzun Türkçe olarak anlattım. Amacım günümüz için bu kadar önemli bir teknolojiyi anlamak için bütün engelleri en aza indirmek ve gizemleri ortadan kaldırmaya çalışmak. Umarım anlaşılır bir yazı olmuştur.\n",
        "\n",
        "Orijinal blog posttaki bir çok ayrıntıyı da eklemeye çalıştım ama ayrıca oraya bakmanızı da tavsiye ederim. Ayrıca takıldığınız yerleri Colab ortamında okuyorsanız direkt yandaki Gemini'ya sorabilirsiniz.\n",
        "\n",
        "İngilizce orijinal [Colab](https://colab.research.google.com/drive/1vyN5zo6rqUp_dYNbT4Yrco66zuWCZKoN?usp=sharing) ve\n",
        "[Blog yazısına](https://karpathy.github.io/2026/02/12/microgpt/) linklerden ulaşabilirsiniz.\n",
        "\n",
        "Hazırsanız başlayalım.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-JqNc8xMQwn"
      },
      "source": [
        "\n",
        "Bu proje en yalın haliyle Python kullanıyor ve dışarıdan hiçbir hazır kütüphane kullanmayacağız. Standart kütüphaneden de yalnızca logaritma (`math.log`) ve üstel fonksiyonlar (`math.exp`) ile rastgele sayı modülünü (`random`) import ederek başlıyoruz. `os.path.exists` ve `urllib.request.urlretrieve` fonksiyonlarını ise sadece örnek veri dosyasını indirmek için kullanıyoruz.\n",
        "\n",
        "`random.seed(42)` rastgele sayıların her zaman aynı sırada üretilmesini sağlayarak bize yardımcı olacak. Böylece hep aynı sonuçları göreceğiz. Bu sadece geliştirme sırasında hataları kolay bulabilmemiz için kullanılan bir teknin. Normalde bu satırı kaldırabiliriz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeNezXgVzgSo"
      },
      "outputs": [],
      "source": [
        "'''https://colab.research.google.com/drive/1vyN5zo6rqUp_dYNbT4Yrco66zuWCZKoN?usp=sharing'''\n",
        "'''https://karpathy.github.io/2026/02/12/microgpt/'''\n",
        "\n",
        "import os       # os.path.exists\n",
        "import math     # math.log, math.exp\n",
        "import random   # random.seed, random.choices, random.gauss, random.shuffle\n",
        "random.seed(42) # Kaos içinde düzen olsun"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP_c5PEigMcj"
      },
      "source": [
        "## Eğitim Verisi\n",
        "Elimizde örnek olarak basit bir veriseti var. Linke tıklayarak içeriğini görebilirsiniz. Her satırda bir insan ismi olan bir liste bu. Aşağıda önce bu listeyi indirip `input.txt` dosyasına kaydediyoruz. Sonra dosyayı okuyup `docs` isimli listeyi oluşturuyoruz. 32033 elemanlı bu isim listesi eğitim için bizim veri setimiz olacak.\n",
        "\n",
        "Gerçek GPT'de bu `docs` listesinin her elemanı bir dökümanı, örneğin bir web sayfasındaki metinleri içerecek. Bu örnekte ise basit bir örnek olarak insan isimleri kullanılmış."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im-k47A1bcXU",
        "outputId": "38f921eb-b99b-4f19-ef57-2abfc28ac6ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "doküman sayısı: 32033\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Bir giriş veri kümesi `docs` olsun: dokümanlardan oluşan liste[str] (ör. isimlerden oluşan bir veri kümesi)\n",
        "if not os.path.exists('input.txt'):\n",
        "    import urllib.request\n",
        "    names_url = 'https://raw.githubusercontent.com/karpathy/makemore/refs/heads/master/names.txt' # isimler listesi\n",
        "    urllib.request.urlretrieve(names_url, 'input.txt')\n",
        "docs = [l.strip() for l in open('input.txt').read().strip().split('\\n') if l.strip()] # dokümanlardan oluşan liste[str]\n",
        "random.shuffle(docs) # listeyi rastgele karıştır\n",
        "print(f\"doküman sayısı: {len(docs)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_yuViHbh75V"
      },
      "source": [
        "# Tokenleştirme\n",
        "Bu veri seti sözcüklerden yani harflerden oluşuyor. Fakat yapay öğrenme modeli için bize sayılar gerekiyor. Girdileri nasıl sayılara dönüştürebiliriz?\n",
        "\n",
        "Basit bir yöntem her harfe bir sayı atamak. İngiliz alfabesinde **26 harf** var. Bir tane de dizinin başlangıcını tanımlayan özel bir sembol (token) tanımlıyoruz. Bu özel sembolünün ismi orijınal kodda `BOS` (Beginning of Sequence, Dizinin Başlangıcı) olarak isimlendirilmiş. Ben bunu başlangıç anlamında `BAS` olarak değiştirdim. Model bu `BAS` tokenini ayraç olarak kullanmayı öğrenecek. Farkli isimleri (dökümanları) bu şekilde birbirinden ayıracağız. Örnek:\n",
        "`\n",
        "[BAS, e, m, m, a, BAS]\n",
        "`\n",
        "\n",
        "Burada **token** kavramına da değinelim. Dokumanı ayırdıgımız bu parçacıklara genelde token adı veriliyor. Biz basitçe her **harf için bir token** gibi bir eşleştirme yaptık. Her tokeni de bir tamsayı ile temsil ettik (**token id**). Gerçek GPT'de daha etkili bir yol olarak harf gruplarını tokena çeviriyorlar. GPT4'ün kullandığı token dönüştürücüsü [tiktoken](https://github.com/openai/tiktoken)'a buradan ulaşabilirsiniz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAjvOwSygK6f",
        "outputId": "c493a359-588b-421a-ab47-b796e2ceba0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sözlük boyutu: 27\n"
          ]
        }
      ],
      "source": [
        "# Dizgileri ayrık sembollere çeviren ve geri dönüştüren bir Tokenizer olsun\n",
        "uchars = sorted(set(''.join(docs))) # veri kümesindeki benzersiz karakterler token id’leri 0..n-1 olur\n",
        "BAS = len(uchars) # özel “Dizinin Başlangıcı” (BAS) token’ı için token id\n",
        "vocab_size = len(uchars) + 1 # toplam benzersiz token sayısı, +1 BAS içindir\n",
        "print(f\"sözlük boyutu: {vocab_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLgtVWSDqup8"
      },
      "source": [
        "## Otomatik Türev (AutoGrad)\n",
        "Geldik matematiksel olarak en yoğun ve belki de asıl işi yapan kısma. Normalde `pytorch`, `JAX` gibi kütüphanelerin en büyük katkısı da bu.\n",
        "\n",
        "Yapay Sinirsel Ağlar günümüzde **Geri Yayılım (Backpropagation)** algoritması ile eğitiliyor. Bütün ağı bir **hesaplama grafiği (computational graph)** olarak tanımlıyoruz. Bu ağ bizim **girdi**lerimizi (bu örnekte tokenlerimizi) ve **eğitilebilir model parametreleri**ni (**ağırlık** ve **bias** parametreleri gibi) alıyor. Model çıktısı ise yine bizim tanımladığımız bir **kayıp fonksiyonu**na (**Loss Function**) girerek tek bir sayıya (**Loss**) indirgeniyor. Eğitim sırasında bizim amacımız bu sayıyı (Loss) düşürmeye çalışmak. Bunu da model parametrelerini ufak ufak artırıp azaltarak yapıyoruz.\n",
        "\n",
        "Peki hangi parametreleri artırıp hangilerini azaltmamız gerektiğini nereden bileceğiz? İşte **türev** bize bu ilişkiyi veriyor. Bir parametreyi \"bir tık\" artırdığımızda diğer bir değerinin ne kadar değişeceğinin ölçüsüne türev diyoruz. **Gradyan** ise türevin çok değişkenli haline verilen isim. Yani modeldeki bütün parametrelerin ne yönde değişmesi gerektiği **Gradyan vektörü** ile tanımlanıyor.\n",
        "\n",
        "Tüm bu türev hesaplamalarını kendimiz yapabilirdik. Neyse ki **Otomatik Türev (AutoGrad)** denilen mucizevi yöntem sayesinde bütün bu türev hesapları otomatik yapılabiliyor. Biz ise sadece modeli tanımlayan o hesaplama grafiğini tanımlıyoruz. `Pytorch` gibi kütüphaneler sayesinde bu model tanımlama işini de bildiğimiz python fonksiyonları yazarak yapabiliyoruz. Autograd arka planda bizim yaptığımız bütün matematiksel **işlemlerin bir listesi**ni tutuyor ve türevlerini hesaplıyor. Matematiğe hiç elimizi bile sürmeden, hatta farkına bile varmadan matematiksel olarak hesaplaması gayet zor olacak şeyleri yapabiliyoruz. İşte Yapay Zekanın son yıllarda bu kadar hızlı ilerlemesinin sebeplerinden biri de bu oldu.\n",
        "\n",
        "Bu tür kütüphaneleri kullananlar bilecektir ki modelin yapacağı işlemleri `forward` adlı bir fonksiyon ile tanımlıyoruz. Bu fonksiyon, modelin (hesaplama grafiğinin) **ileri yönde** (forward) yani girdilerden çıktıya doğru hangi işlemleri yapacağını tanımlıyor.\n",
        "\n",
        "**Geri yayılım algoritması** ise **geri yönde**, yani kayıp değerinden başlayarak girdilere doğru geriye giderek her parametreye göre Lossun türevlerini oluşturuyor. Bu türevleri calculustaki **zincir kuralı**nı kullanarak yapıyor. Biz ise kodda `backward` fonksiyonunu çağırarak hesaplatıyoruz. İşte Autograd bu backward fonksiyonunu bizim için otomatik olarak yaratıyor.\n",
        "\n",
        "**Zincir kuralı** şu şekilde:\n",
        "$$\\frac{\\partial L}{\\partial W}\n",
        "=\n",
        "\\frac{\\partial L}{\\partial a}\n",
        "\\cdot\n",
        "\\frac{\\partial a}{\\partial z}\n",
        "\\cdot\n",
        "\\frac{\\partial z}{\\partial W}$$\n",
        "\n",
        "Kayıp fonksiyonunun ($L$) parametrelere ($W$) göre türevi, ara katmanların geriye doğru yerel türevlerinin çarpımı şeklinde yazılabiliyor.\n",
        "\n",
        "Fakat bu örnekte hazır hiçbir şey kullanmadığımız için **Autograd**'ı da kendimiz yazacağız. Korkmayın, sandığınızdan daha kolay.\n",
        "\n",
        "### Ev Yapımı Autograd kodunun açıklaması\n",
        "\n",
        "Öncelikle hesaplama grafiğimizdeki her bir düğümü temsilen `Value` sınıfı oluşturuyoruz. Bu sınıfın kendi içinde 4 farklı değer tutacak:\n",
        "\n",
        "`data` bu düğümün hesaplanan skaler değeri,\n",
        "\n",
        "`grad` lossun bu düğüme göre türevi,\n",
        "\n",
        "`_children` (çocuklar) bu düğümün hesaplanmasında kullanılan (ondan önceki katmandan gelen) düğümler,\n",
        "`_local_grads` ise bu düğümün çocuklarına göre yerel türevleri.\n",
        "\n",
        "Bu `Value` nesneleri ile yaptığımız her matematiksel işlemde yeni bir `Value` yaratıyoruz. Örneğin `c = a + b` işlemini tanımladığımızda `c` `Value`'sunu yaratıyoruz. `c`'nin çocukları `a` ve `b` Value objeleri. `a` ve `b`'nin `.data` değişkeninin 3 ve 4 olduğunu düşünelim. `c.data` bu durumda 7 olarak hesaplanıyor. Bu hesaplamayı yaptığımız `+` işlemi `Value` sınıfına ait `__add__` fonksiyonunu kullanıyor. Biz bu `__add__` fonksiyonunu kodda kendimiz tanımlıyoruz. Fakat tanımlarken sadece toplama işlemi yapmakla kalmıyoruz. Yeni bir `c` `Value`'su yaratıp onu döndürüyoruz. `c.data` elbette `a + b` toplamı yani 7 oluyor. `c`'nin çocukları olarak `a` ve `b`'yi nüfusa kaydediyoruz. Ama en önemlisi toplama işlemi için `c`'nin `a`'ya ve `b`'ye göre **'yerel' türevleri**ni tanımlayıp onları da c'ye keydediyoruz. Toplama işlemi için her iki türev de 1 (a + b'nin a'ya ve b'ye göre türevleri 1 ve 1). Yapılan işlemin toplama olduğunu ayrıca kaydetmemize gerek yok. `.backward` geçişi için için bize sadece yerel türevler yetecek."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEkvrjTfW0Pp"
      },
      "source": [
        "<img src=\"img/toplama3x.png\" width=\"50%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hZiuvlgWyks"
      },
      "source": [
        "Bu fonksiyon tanımlamasını Value'ları kullanarak için yapmak istediğimiz bütün temel matematiksel işlemler için ayrı ayrı yapmamız gerekiyor. Bunların birleşiminden oluşan daha karmaşık işlemleri tekrar tanımlamamıza gerek yok. Buradaki GPT örneği için tablodaki tanımlar yetiyor:\n",
        "\n",
        "| İşlem | İleri | Yerel Gradyanlar |\n",
        "|-----------|----------|-------------------|\n",
        "| `a + b`   | $$a + b$$ | $$\\frac{\\partial}{\\partial a}=1,\\quad \\frac{\\partial}{\\partial b}=1$$ |\n",
        "| `a * b`   | $$a \\cdot b$$ | $$\\frac{\\partial}{\\partial a}=b,\\quad \\frac{\\partial}{\\partial b}=a$$ |\n",
        "| `a ** n`  | $$a^n$$ | $$\\frac{\\partial}{\\partial a}=n a^{n-1}$$ |\n",
        "| `log(a)`  | $$\\ln(a)$$ | $$\\frac{\\partial}{\\partial a}= \\frac{1}{a}$$ |\n",
        "| `exp(a)`  | $$e^a$$ | $$\\frac{\\partial}{\\partial a}= e^a$$ |\n",
        "| `relu(a)` | $$\\max(0,a)$$ | $$\\frac{\\partial}{\\partial a}= \\mathbf{1}_{a>0}$$ |\n",
        "\n",
        "### `.backward` fonksiyonu:\n",
        "Dikkat ederseniz `Value` nesnelerini yaratırken (`__init__`) `.grad` değerlerini `0` olarak bıraktık. Bu degerleri yani gradyanları hesaplamak için `.backward` fonksiyonunu kullanacağız. Örneğin `loss.backward()` şeklinde çağırdığımızda en sondaki `loss` `Value`'sundan başlayarak, sondan başa doğru, hesaplama grafiğindeki bütün `Value` düğümlerini geziyoruz ve grad değerlerini zincir kuralını kullanarak hesaplıyoruz.\n",
        "\n",
        "`backward` fonksiyonu içinde ilk yaptığımız iş bu tersine gezme sırasını oluşturmak. Buna tür bir sıralamaya tersine **topolojik sıralama** deniyor. Burada **DFS (Depth First Search, Derinlik Öncelikli Arama)** adlı klasik algoritmanın bir versiyonu kullanılarak topolojik sıralama bulunuyor (`topo`). DFS sırasında eğer bir düğümün bütün çocukları gezildiyse `topo` listesine ekliyoruz.\n",
        "\n",
        "Loss'tan başlıyoruz ve onun kendine göre türevi 1. Yani en sonraki düğümün `.grad` değeri `1` oluyor.\n",
        "\n",
        "Sonrasında `v in reversed(topo)` ile sondan başa doğru `v` düğümleri geziliyor. Burada yapılan işlem önemli.\n",
        "\n",
        "`v`'nin `.grad` değeri **yerel gradyan**lar ile çarpılarak çocuklara aktarılıyor.  Burada çocukların mevcut gradyanına `v`'den yeni gelen gradyanlar **ekleniyor** (`+=`). Bunun sebebi ağda dallanmalar olabilmesi ve bir düğüme birden fazla koldan gradyan akabilmesi.\n",
        "\n",
        "`backward` tamamlandığında her düğümün `.grad` değeri hesaplanmış oluyor. Bu `grad` degeri $\\frac{\\partial L}{\\partial v}$'yı, yani v.data'yı bir tık degistirirsek kayip degerinin ne yönde kaç tık değişeceğini gösteriyor.\n",
        "\n",
        "---\n",
        "Daha fazla ayrıntı istiyorsanız Karphathy'nin 2 buçuk saatlik [micrograd](https://www.youtube.com/watch?v=VMj-3S1tku0) videosunu izleyebilirsiniz.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vcFzbLRahqqV"
      },
      "outputs": [],
      "source": [
        "# Hesaplama grafiği üzerinden zincir kuralını özyinelemeli uygulayan Autograd olsun\n",
        "class Value:\n",
        "    __slots__ = ('data', 'grad', '_children', '_local_grads') # bellek kullanımı için Python optimizasyonu\n",
        "\n",
        "    def __init__(self, data, children=(), local_grads=()):\n",
        "        self.data = data                # ileri geçişte (forward) hesaplanan bu düğümün skaler değeri\n",
        "        self.grad = 0                   # geri geçişte (backward) kaybın bu düğüme göre türevi\n",
        "        self._children = children       # hesaplama grafiğinde bu düğümün çocukları\n",
        "        self._local_grads = local_grads # bu düğümün çocuklarına göre yerel türevleri\n",
        "\n",
        "    def __add__(self, other):\n",
        "        other = other if isinstance(other, Value) else Value(other)\n",
        "        return Value(self.data + other.data, (self, other), (1, 1))\n",
        "\n",
        "    def __mul__(self, other):\n",
        "        other = other if isinstance(other, Value) else Value(other)\n",
        "        return Value(self.data * other.data, (self, other), (other.data, self.data))\n",
        "\n",
        "    def __pow__(self, other): return Value(self.data**other, (self,), (other * self.data**(other-1),))\n",
        "    def log(self): return Value(math.log(self.data), (self,), (1/self.data,))\n",
        "    def exp(self): return Value(math.exp(self.data), (self,), (math.exp(self.data),))\n",
        "    def relu(self): return Value(max(0, self.data), (self,), (float(self.data > 0),))\n",
        "    def __neg__(self): return self * -1\n",
        "    def __radd__(self, other): return self + other\n",
        "    def __sub__(self, other): return self + (-other)\n",
        "    def __rsub__(self, other): return other + (-self)\n",
        "    def __rmul__(self, other): return self * other\n",
        "    def __truediv__(self, other): return self * other**-1\n",
        "    def __rtruediv__(self, other): return other * self**-1\n",
        "\n",
        "    def backward(self):\n",
        "        topo = []\n",
        "        visited = set()\n",
        "        def build_topo(v):\n",
        "            if v not in visited:\n",
        "                visited.add(v)\n",
        "                for child in v._children:\n",
        "                    build_topo(child)\n",
        "                topo.append(v) # not: bütün çocuklarını tamamladıktan sonra listeye ekleyebilirsin\n",
        "        build_topo(self)\n",
        "        self.grad = 1\n",
        "        for v in reversed(topo):\n",
        "            for child, local_grad in zip(v._children, v._local_grads):\n",
        "                child.grad += local_grad * v.grad\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4K8QnmnLl-e"
      },
      "source": [
        "## Transformer Hiperparametreleri\n",
        "Yavaş yavaş modelimizi, yani Transformer ağımızı yapmaya başlayabiliriz. Öncelikle modeli oluşturan hiperparametreleri tanımlayalim. `n_emb`, transformer içindeki temsil vektörlerinin (embedding veya gömme vektörü) boyutunu tanımlıyor. Bu örnekte 16 boyutlu vektörlerle çalışacağız. `n_head` attention (dikkat) mekanizmasındaki başlıkların sayısı. Bu tasarıma **Multi-Head Attention (Çok Başlıklı Dikkat)** diyoruz. 4 farklı başlık bize `head_dim = 16 / 4 = 4` boyutlu çıktılar verecek. Sonra bunları birleştirip `n_embd = 16` boyutlu temsil vektörlerimizi oluşturacağız.\n",
        "\n",
        "`n_layer` transformer bloklarının sayısı. Örneğin GPT-2'de bu bloklardan modelin boyutuna göre 12-24 adet, GPT-3'te ise 96 tane var. Bu aslında çok önemli bir fark. Burada hızlı bir deneme için en küçük sayı seçilmiş ama siz bunu artırıp denemeler yapabilirsiniz.\n",
        "\n",
        "`block_size` transformerın aynı anda işleyeceği en uzun dizi boyutunu sınırlandırıyor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "j66pvQz4rQYW"
      },
      "outputs": [],
      "source": [
        "n_embd = 16     # embedding (temsil, gösterim) boyutu\n",
        "n_head = 4      # attention (dikkat) head (başlık) sayısı\n",
        "n_layer = 1     # transformer bloğu (katman) sayısı\n",
        "block_size = 16 # maksimum dizi uzunluğu\n",
        "head_dim = n_embd // n_head # her başlığın boyutu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2fLlRhyHVAn"
      },
      "source": [
        "## Eğitilebilir Parametreler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDyLN3_dKf77"
      },
      "source": [
        "Autograd bölümünde modeldeki eğitilebilir düğümlerden, yani parametrelerden bahsettik. Bunları tanımlamak için `Value` sınıfını kullanacağız. Bu sınıf, ilgili parametrenin (eğitilebilir düğümün) değerini (`.data`) ve model çıktısının (Loss) bu parametreye göre türevini (`.grad`) tuttuyordu. Eğitim sırasında bu tutulan bilgilerden yararlanacağız.\n",
        "\n",
        "Ayrıca yapacağımız matematiksel işlemleri Lineer Cebirden faydalanarak toplu halde yapacağız. Bu yapacağımız işlemleri daha anlaşılır yapacak ve tranformer mimarisiyle uyumlu hale getirecek. Bu amaçla bir `matrix` fonksiyonu tanımlıyoruz. Bu fonksiyon `nout x nin` boyutunda bir matris tanımlıyor. Matrisin her elemanı `Value` objelerinden oluşuyor ve **başlangıç değeri** olarak 0 ortalamalı bir normal (Gauss) dağılımından rastgele sayılar atıyor.\n",
        "\n",
        "Kodun devamında parametrelerimizi, gerekli boyuttaki matrisler şeklinde yaratıyoruz. `state_dict` bu matrisleri tuttuğumuz bir dictionary. Ayrıca bütün matrisleri düzleştirerek, bütün skaler parametreleri toplayan tek bir `parameters` listesi oluşturuyoruz. Bu listede 4192 adet skaler eğitilebilir parametremiz var. Bu parametrelere hesaplama grafiğinde isim verilmiş matrisler halinde ulaşacağız. Ne anlama geldiklerine ise Model Mimarisi bölümünde bakacağız."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUXOXa4iGSmY",
        "outputId": "e50069e6-afef-4d3b-902e-db54a1d0f6ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "parametre sayısı: 4192\n",
            "state_dict içindeki matrisler': [['wte', 'wpe', 'lm_head', 'layer0.attn_wq', 'layer0.attn_wk', 'layer0.attn_wv', 'layer0.attn_wo', 'layer0.mlp_fc1', 'layer0.mlp_fc2']]\n"
          ]
        }
      ],
      "source": [
        "# Model bilgisini tutacak parametreleri başlat.\n",
        "matrix = lambda nout, nin, std=0.08: [[Value(random.gauss(0, std)) for _ in range(nin)] for _ in range(nout)]\n",
        "state_dict = {'wte': matrix(vocab_size, n_embd), 'wpe': matrix(block_size, n_embd), 'lm_head': matrix(vocab_size, n_embd)}\n",
        "for i in range(n_layer):\n",
        "    state_dict[f'layer{i}.attn_wq'] = matrix(n_embd, n_embd)\n",
        "    state_dict[f'layer{i}.attn_wk'] = matrix(n_embd, n_embd)\n",
        "    state_dict[f'layer{i}.attn_wv'] = matrix(n_embd, n_embd)\n",
        "    state_dict[f'layer{i}.attn_wo'] = matrix(n_embd, n_embd)\n",
        "    state_dict[f'layer{i}.mlp_fc1'] = matrix(4 * n_embd, n_embd)\n",
        "    state_dict[f'layer{i}.mlp_fc2'] = matrix(n_embd, 4 * n_embd)\n",
        "params = [p for mat in state_dict.values() for row in mat for p in row] # parametreleri tek bir liste[Value] halinde düzleştir\n",
        "print(f\"parametre sayısı: {len(params)}\")\n",
        "print(f\"state_dict içindeki matrisler': {[list(state_dict.keys())]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqX_VwTfR4rU"
      },
      "source": [
        "## Model Mimarisi\n",
        "\n",
        "**Transformer** mimarisini anlamak adına en önemli bölüme geldik. Çünkü bu bölümde GPT modelimizi oluşturacağız. Bu arada GPT, **Generative Pre-trained Transformer (Üretici Ön-eğitimli Dönüştürücü)** anlamına geliyor. Yani büyük data üzerinde önceden eğitilmiş ve farklı amaçlarla kullanılmaya hazır bir transformer (dönüştürücü) modeli. Biz tabii burada çok basit bir görev için, ufak bir data üzerinde sıfırdan eğiteceğiz. Fakat boyutu dışında GPT-2'ye çok benzer bir mimari kullanacağız.\n",
        "\n",
        "Transformerlar **transformer bloğu** adlı tekrar eden yapılardan oluşurlar. Bunu bir binanın tekrar eden katlarına benzetebilirsiniz. GPT-2 en az 12 katlı bir binayken biz burada tek katlı bir bina yapacağız.\n",
        "\n",
        "Her katta, yani her transformer bloğunda sırayla **2 alt blok** olacak. İlki **dikkat mekanizması**nı oluşturan **attention** ağı. Bu bölümün görevi gelen **embedding vektörleri**ni birbirleriyle **karşılaştırmak ve karıştırmak**. Bu şekilde yapılan dikkat işlemine **self-attention (öz-dikkat)** diyoruz. Eğer farklı bir yerden gelen vektörlerle karşılaştırma ve karıştırma yapıyor olasaydık buna da **Cross Attention (Çapraz Dikkat)** diyecektik.\n",
        "\n",
        "Her kattaki ikinci alt bölüm ise klasik bir **Feed Forward Network (İleri Beslemeli Ağ)**. Bu bölümün görevi ise her vektörü ***kendi içinde*** dönüştürmek. Burada **MLP (Multi-layer Perceptron)** dediğimiz **çok katmanlı perceptron** mimarisini kullanıyoruz.\n",
        "\n",
        "Biraz daha somutlaştıralım. En alt kattan başlayarak binadaki her kata en fazla `block_size = 16` adet `n_embd = 16`'şar boyutlu **temsil vektörü** (not: embedding, temsil, gömme gibi sözcükleri aynı anlamda kullanıyorum) giriyor. Vektörlerin sayısını belirleyen şey girdi olarak verdiğimiz token miktarı. Yani her tokene karşılık bir embedding var. Yalnız ufak bir detay, bu embeddingler direkt tokenlerlara karşılık geliyor diyemeyiz. Çünkü bu temsiller transformer boyunca karışıyor ve dönüştürülüyorlar. Binanın katları arasında artık harfler veya kelimeler yok.\n",
        "\n",
        "İşte transformerın yaptığı şey her blokta bu vektörleri önce kendi aralarında karşılaştırmak ve bu karşılaştırmaya göre ağırlıklandırılmış yeni vektörler yaratmak. Yani bir anlamda vektörleri birbirine karıştırmak. İkinci aşamada (MLP) ise her vektörü kendi içinde dönüştürmek. Tüm bu dönüşüm ve karşılaştırmalar öğrenilmiş bir şekilde, yani parametre matrislerimizce hesaplanarak yapılıyor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yx4VxSlvryhG"
      },
      "source": [
        "<img src=\"img/Transformer Apartmanı.png\" width=\"75%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Şimdi gelin sinirsel ağımızın bileşenleriyle başlayalım.\n",
        "\n",
        "### Yardımcı fonksiyonlar\n",
        "`linear(x, w)` temel bir doğrusal nöron tanımlıyor. bias parametresi kullanılmamış. $y = Wx$ şeklinde bir matris vektör çarpımı yapıp sonucu döndürüyoruz.\n",
        "\n",
        "`softmax(logits)`: softmax fonksiyonu verilen sayıları (logits) toplamları 1 olacak şekilde bir olasılık dağılımına çeviren matematiksel bir fonksiyon. Sayılar ne kadar büyük veya küçük olursa olsun hepsini [0,1] aralığına sıkıştırıyor. Ayrıca daha büyük değerlerin çok daha büyük olasılıklarla temsil edilmesini sağlıyor. $$\\mathrm{softmax}(x_i) = \\frac{e^{x_i}}{\\sum_{j=1}^{n} e^{x_j}}\n",
        "  $$\n",
        "`rmsnorm(x)`: Root Mean Square Normalization (Karekök Ortalama Kare ile Normalizasyon). GPT'deki LayerNorm karmanı yerine tercih edilmiş. Vektörleri, kareleri ortalamasının karekökü 1 olacak şekilde boyutlandırıyor. Bu vektörlerin fazla büyüyüp küçülmesini engelleyerek eğitimi daha kararlı hale getirmeye yarıyor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hE0UXZ-rRsF_"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Model mimarisini tanımla: token dizisi + parametreler -> bir sonraki token için logits.\n",
        "# GPT-2’yi takip et, (GPT’ler arasında kutsanmış), küçük farklarla: layernorm -> rmsnorm, bias yok, GeLU -> ReLU\n",
        "def linear(x, w):\n",
        "    return [sum(wi * xi for wi, xi in zip(wo, x)) for wo in w] # y=Wx\n",
        "\n",
        "def softmax(logits):\n",
        "    max_val = max(val.data for val in logits)        # numerik kararlılık için maksimumu çıkarmak\n",
        "    exps = [(val - max_val).exp() for val in logits] # sonucu etkilemiyor.\n",
        "    total = sum(exps)\n",
        "    return [e / total for e in exps]\n",
        "\n",
        "def rmsnorm(x):\n",
        "    ms = sum(xi * xi for xi in x) / len(x) # x'in elemanlarının karelerini alıp topladık\n",
        "    scale = (ms + 1e-5) ** -0.5            # bunun karekökünü aldık\n",
        "    return [xi * scale for xi in x]        # her elemanı bu hesapladığımız değere bölerek vektörğ normalize ettik\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UZjxx438xWY"
      },
      "source": [
        "## GPT\n",
        "Sonunda gpt modelimizi nasıl yaratacağımızı tanımlamaya geldi sıra. Öncelikle fonksiyonun parametrelerine bakalım:\n",
        "\n",
        "`gpt(token_id, pos_id, keys, values)`: gpt, yani transformer modelimiz her seferinde tek bir yeni token alacak. Bizim örneğimizde bu tek bir harf. `token_id` tokenleri tokenizer ile çevirdiğimiz sayı. `pos_id` bu harfin kaçıncı sırada olduğunun bilgisi. `keys` ve `values` ise KV-cache dediğimiz, önceki tokenlera ait K ve V değerlerini sakladığımız yapı. Bu bize bağlamı (context) veriyor.\n",
        "\n",
        "Şu an bina metaforumuzda giriş katındayız. Elimizde `token_id`, yani sayıya çevrilmiş bir harf ve kaçıncı sırada olduğu bilgisi var. Fakat transformer blokları (katlar) vektörler (embedding, temsil) üzerinde çalışıyordu. İlk iş elimizdeki token ve pozisyon bilgilerini istenen formattaki temsil vektörlerine çeviriyoruz. Nasıl çevireceğiz? Elimizdeki matrislerin boyutlarina bakalım."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYfVp_U-GvRp",
        "outputId": "2d9eaf12-d757-497f-9ffa-6206ea5fead9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wte: 27 x 16\n",
            "wpe: 16 x 16\n",
            "lm_head: 27 x 16\n",
            "layer0.attn_wq: 16 x 16\n",
            "layer0.attn_wk: 16 x 16\n",
            "layer0.attn_wv: 16 x 16\n",
            "layer0.attn_wo: 16 x 16\n",
            "layer0.mlp_fc1: 64 x 16\n",
            "layer0.mlp_fc2: 16 x 64\n"
          ]
        }
      ],
      "source": [
        "for k, m in state_dict.items():\n",
        "    print(f\"{k}: {len(m)} x {len(m[0])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxVo_FT0H9_z"
      },
      "source": [
        "`wte` matrisinde (27 x 16) her token id için bir satır var ve her satırın boyutu embedding boyutu kadar. Basit bir yöntemler her satırı farklı bir token_id'ye atayacağız (`tok_emb`). Peki bu sayıları nereden gelecek? Eğitim sırasında öğrenilen parametreler olduğu için eğitimde kendiliğinden oluşacaklar.\n",
        "\n",
        "Aynısı pozisyon vektörleri için de gerekli. En fazla `block_size = 16` harflik dizilerle çalışacağız demiştik. `wpe` matrisinde her sıra numarası için 16'lık bir vektör var. Dizideki kaçıncı tokendeysek o satırdaki vektörü pozisyon vektörü olarak kullanıyoruz (`pos_emb`).\n",
        "\n",
        "Bloklara aktaracağımız vektör ise bu iki vektörün toplamı. Yani tek bir vektörde hangi harf (token) hangi sırada gibi bir bilgiyi temsil ediyoruz. Bu vektörü `rmsnorm(x)` fonksiyonumuz ile normalize ettikten sonra artık ilk kata aktarabiliriz.\n",
        "\n",
        "### Blok tanımı\n",
        "Bir `for` döngüsü ile `n_layer` adet transformer bloğunu, yani katları tanımlamaya başlayalım. Bu katların her biri birbirinin aynısı olacak. Her katta iki oda olduğunu hayal edelim. İlk oda **Multi-head attention alt bloğu** olarak isimlendirilen bölüm. İkincisi ise **MLP alt bloğu**.\n",
        "\n",
        "Bu alt bloğa girerken yol ikiye ayrılıyor. Bir yol Attention alt bloğuna girerken diğer yol attention'ı pas geçerek yola düz devam ediyor. İşte bu düz devam eden bağlantıya `x_residual` dedik. Attention çıkışında bunlar tekrar birleşecekler. Bu pratikte öğrenmeyi oldukça kolaylaştıran bir teknik. Böylece attentiondan geçen taraf x'i değil x'in üzerine eklenecek farkı (residual) öğreniyor. Yani bu kısım 0 olduğunda bile (yol tıkalı mesela) alt kattan gelen x vektörü bozulmadan yoluna devam edebilecek (identity function, özdeş fonksiyon).\n",
        "\n",
        "#### Dikkat Mekanizması\n",
        "\n",
        "Buradaki dikkat mekanizması Transformerları diğer mimarilerden ayıran en temel şey. Aynı zamanda ilk başka en gizemli görünen ve anlaşılması zaman alan bir yapı. İşin aslı göründüğünden çok daha kolay ve şimdi bunu öğreneceğiz.\n",
        "\n",
        "Buradaki fikir aslında basit. Elimizde bir vektör (`x`) var. Bu vektör giriş katında bir harf ve bunun pozisyon bilgisinden üretilmişti ve her katta değişikliğe uğrayarak (dönüşerek) yoluna devam ediyordu. Diyelim 'emma' kelimesinin 3. harfindeyiz. Bunu kendinden önceki e ve m'den dönüştürülen, yani 1. ve 2. sıradaki vektörlerle karşılaştırıyoruz.\n",
        "\n",
        "Peki nasıl karşılaştıracağız?\n",
        "\n",
        "Matematikte iki vektörü karşılaştırmanın, yani benzerliğini ölçmenin en basit yolu **iç çarpım**dır (**dot product**).\n",
        "\n",
        "Aslında bu vektörleri sırayla alıp birbiriyle iç çarpımlarını alarak karşılaştırabiliriz. Mesela ilk sıradaki vektörle ($x_1$) 3. sıradaki vektörün  ($x_3$) ne kadar benzediğini gösteren bir sayı elde ederiz. Burada yapacağımız şey ise bunun bir adım ilerisi olacak. Doğrudan $x_1$ ve $x_3$'ün iç çarpımını almak yerine, bunları öğrendiğimiz parametrelerden oluşan akıllı matrislerimiz ile çarparak yeni vektörler elde edeceğiz ($k_1$ ve $q_3$) ve yeni vektörleri karşılaştıracağız. Diğer bir ifadeyle öğrenilmiş, akıllı ve girdilere göre değişen bir karşılaştırma yöntemi kullanacağız.\n",
        "\n",
        "**Matris-vektör çarpımı**nı `linear(x, W)` fonksiyonuyla tanımlamıştık. Biz elimizdeki $x$ vektörünü öğrenilmiş $W_{Q_{li}}$ matrisiyle projekt ederek (çarparak) $q$ vektörüne çeviriyoruz. Bu matrisler her blok yani her kat için ayrı ayrı. `li` numaralı blok için `layer{li}.attn_wq` matrisini kullanacağız:\n",
        "\n",
        "```q = linear(x, state_dict[f'layer{li}.attn_wq'])```\n",
        "\n",
        "Karşılaştırma yapılacak diğer (önceki) vektörü ise yine benzer bir matrisle $W_{K_{li}}$ çarparak $k_1$ vektörüne çeviriyoruz. Karşılaştırmayı da $x_1 \\cdot x_3$ yerine daha akıllı $k_1 \\cdot q_3$ şeklinde yapıyoruz. Bu çarpım bize skaler tek bir sayı veriyor. Bu sayıya **dikkat skoru** diyebiliriz. İki vektör arasındaki öğrenilmiş bir tür matematiksel ilişkiyi puanlıyor.\n",
        "\n",
        "Elimizde sadece $x_3$ varsa $k_1$'i nereden bulduk diyebilirsiniz. KV-cache işte tam bu işe yarıyor. gtp fonksiyonuna girdi olarak $x_1$ verildiği zaman $q_1$, $k_1$ ve $v_1$ değerlerini hesaplıyor. $k_1$ ve $v_1$ değerlerini gelecekte kullanılmak üzere KV-cache'e (Anahtar-Değer önbelleği) kaydediyor. Kodda KV-önbelleği `keys` ve `values` adlı dictionaryler ile sağlanmış.\n",
        "\n",
        "#### Multi-head attention (Çok Başlıklı Dikkat) alt bloğu\n",
        "Bu kodda çok başlıklı dikkat normalden biraz farklı görünse de matematiksel olarak aynı. Normalde her başlık kendine ait daha küçük W matrisleri ile kendi 4 boyutlu q, v ve k'larını oluşturabilirdi. Burada ise bunu tek bir büyük matrisle yapıyoruz.\n",
        "\n",
        "Burada her başlığın görevi bu dikkat işlemini farklı bir bakış açısıyla, diğerlerinden bağımsız olarak yapmak. Her biri kendi 4 boyutlu alt uzayında çalışıyor. Daha sonra 4 adet başlığın çıktısı birleştirilerek 16'lık tek bir vektör oluşturuyoruz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR1C3FJMcPAJ"
      },
      "source": [
        "#### Dikkat Fonksiyonu\n",
        "\n",
        "Dikkat'i bir tek bir fonksiyon olarak düşünmek işimizi kolaylaştıracak. Aşağıdaki resimde bu fonksiyonun detaylı açıklamasını göreceksiniz. Burada yukarıda konuştuğumuzdan farklı olark dikkati hedapladığımız k vektörünün boyutunun (head_dim'e eşit) kareköküke bölme işlemi görüyoruz. Bunun sebebi, $q \\cdot k_j$ vektörün varyansının vektör boyutuyla (head_dim) doğru orantılı artması (yaklaşık olarak). Standart sapmayı sabit tutmak için ise bunun kareköküne bölüyoruz (standart sapma varyansın karekökü). Böylece softmaxa girecek olan skor değerleri birbirine daha yakın kalıyor. Bu da eğitimi kolaylaştırıyor.\n",
        "\n",
        "Tekrar özetlemek gerekirse, q'nun, elimizdeki bütün k vektörleriyle iç çarpımını hesaplayarak benzerliklerine baktık. Bu çarpımları vektör boyutunu kareköküne bölerek ölçeklendirdik ki standart sapma sabit kalsın. Bu dikkat skorlarını softmax fonsiyonundan geçirerek dikkat apırlıklarını elde ettik. Hatırlayın, softmax [-sonsuz, + sonsuz] arasindak' sayilari toplamlari 1 olacak şekilde [0, 1] aralığına ölçekliyordu. Bu ağırlıkları kullanarak v vektörlerinin ağırlıklı toplamını alıyoruz. Yani elimizdeki bütün v'leri ağırlıklarla orantılı olarak karıştırıyoruz. Dikkat fonksiyonunun çıktısı işte bu yeni yarattığımız karışmış vektör oluyor.\n",
        "\n",
        "Dikkat fonksiyonunun diğer kaynaklarda bulabileceğiniz matematiksel ifadesini ve kodla ilişkisin aşağıda görselleştirdim. Bu mekanizmayı tek bir işlem bloğu gibi düşünüp başka modeller yaparken de kullanabiliriz. Transformer'ın özelliği dikkat dışında neredeyse hiçbir şey kullanmaması. İlk kez tanıtıldığı meşhur makalenin isminin **Tek İhtiyacınız Dikkat** (**Attention is All You Need**, 2017) olması boşuna değil."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGJG5xEjYFRb"
      },
      "source": [
        "<img src=\"img/dikkat3x.png\" width=\"100%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VwXau7bg1cd"
      },
      "source": [
        "#### MLP Alt Bloğu\n",
        "Dikkat bölümünde farklı tokenlardan türettiğimiz vektörleri birbirine karıştırdık. Bu alt blokta ise bulunduğumuz tokena ait vektörü kendi içinde işleyeceğiz. Bunun için de tek gizli katmanı olan, tam bağlantılı katmanlardan oluşan basit bir sinirsel ağ kullanıyoruz. Aktivasyon fonksiyonu olarak yukarıda tanımladığımız `relu(x)` fonksiyonunu kullanacağız. Relu negatif değerleri 0 yapan, pozitif değerleri ise olduğu gibi bırakan basit bir fonksiyon. Ancak yaptığımız işlemleri doğrusal olmaktan çıkardığı için işlevi büyük. Eğer bu olmasaydı iki lineer katmanı matris çarpımıyla tek bir matriste birleştirebilecektik. Bu da sadece lineer fonksiyonları modelleyebileceğimiz anlamına gelecekti.\n",
        "\n",
        "`x_residual` numarasını burada da kullanacağız. Yani bu bloğun çıkışına bağlanan kestirme bir yol ekleyeceğiz. Gradyanlar bu yollardan da aktığı için çok daha derin modelleri eğitebilmemize yardımcı oluyor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8y4n-7FlOvf"
      },
      "source": [
        "#### Çatı Katı - Model Çıktısı\n",
        "Bütün katları yani transformer bloklarını tanımladık. Şimdi modelimizin çıktısını tasarlamaya geldi sıra. Burada da aslında serbestiz ama basit bir şekilde `lm_head` matrisinin tanımladığı doğrusal katmanla tek bir başlık ekleyeceğiz. Bu 16 boyutlu x vektörümüzü 27 boyutlu logitlere çevirecek. Hatırlayalım, sözlük boyutumuz 27'ydi (26 harf + BAS). `lm_head` matrisinin boyutu 27x16. Oluşan 27 boyutlu `logits` vektörü bize her karakterin olasılığıyla orantılı bir sayı verecek."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MzQibeJG8nNU"
      },
      "outputs": [],
      "source": [
        "\n",
        "def gpt(token_id, pos_id, keys, values):\n",
        "    # Giriş katı\n",
        "    tok_emb = state_dict['wte'][token_id] # token embedding’i\n",
        "    pos_emb = state_dict['wpe'][pos_id] # pozisyon embedding’i\n",
        "    x = [t + p for t, p in zip(tok_emb, pos_emb)] # token + pozisyon embedding’i\n",
        "    x = rmsnorm(x) # normalize et\n",
        "\n",
        "    for li in range(n_layer): # n_layer tane transformer bloğu\n",
        "        # 1) Multi-head attention alt bloğu\n",
        "        x_residual = x # yol ayrımı. x_residual değişmeden doğrudan dikkat çıktısına bağlanacak\n",
        "        x = rmsnorm(x) # LayerNorm alternatifi rms normalizasyonu\n",
        "\n",
        "        # q (sorgu), k (anahtar) ve v (değer) vektörlerini x'ten türet\n",
        "        q = linear(x, state_dict[f'layer{li}.attn_wq']) # W_Q x\n",
        "        k = linear(x, state_dict[f'layer{li}.attn_wk']) # W_K x\n",
        "        v = linear(x, state_dict[f'layer{li}.attn_wv']) # W_V x\n",
        "\n",
        "        # KV-cache: Anahtar-Değer önbelleği\n",
        "        keys[li].append(k)   # k_li anahtarını listede sakla\n",
        "        values[li].append(v) # v_li anahtarını listede sakla\n",
        "\n",
        "        # Çok Başlıklı Dikkat\n",
        "        x_attn = [] # dikkat alt bloğunun çıktısı. (n_head = 4) başlığın her biri (head_dim = 16 / 4) vektörden sorumlu.\n",
        "        for h in range(n_head): # her başlık için\n",
        "            hs = h * head_dim   # n'inci head için başlangıç indeksi\n",
        "            q_h = q[hs:hs+head_dim]                        # h numaralı başlığa ait head_dim boyutlu q\n",
        "            k_h = [ki[hs:hs+head_dim] for ki in keys[li]]  # h numaralı başlığa ait head_dim boyutlu k\n",
        "            v_h = [vi[hs:hs+head_dim] for vi in values[li]] # h numaralı başlığa ait head_dim boyutlu v\n",
        "            attn_logits = [sum(q_h[j] * k_h[t][j] for j in range(head_dim)) / head_dim**0.5 for t in range(len(k_h))] # dikkat skorları (logitler)\n",
        "            attn_weights = softmax(attn_logits) # normalize edilmiş dikkat ağırlıkları\n",
        "            head_out = [sum(attn_weights[t] * v_h[t][j] for t in range(len(v_h))) for j in range(head_dim)] # v vektörlerinin dikkat ağırlıklarıyla ağırlıklı ortalaması alındı.\n",
        "            x_attn.extend(head_out) # bu head için dikat çıktısını (karıştırılmış v vektörlerini) ortak dikkat çıktısına ekle\n",
        "        x = linear(x_attn, state_dict[f'layer{li}.attn_wo']) # çıktıyı bir lineer katmandan geçir (W_o)\n",
        "        x = [a + b for a, b in zip(x, x_residual)]           # yol birleşimi. x + x_residual şeklinde toplama ile birleşiyor.\n",
        "\n",
        "        # 2) MLP alt bloğu\n",
        "        x_residual = x # tekrar yol ayrımı. x_residual değişmeden devam edip MLP alt bloğu çıktısı ile bileşecek\n",
        "        x = rmsnorm(x) # LayerNorm alternatifi rms normalizasyonu\n",
        "        x = linear(x, state_dict[f'layer{li}.mlp_fc1']) # ilk MLP katmanı. Fully Connected (FC, Tam Bağlantılı) bir doğrusal katman ve\n",
        "        x = [xi.relu() for xi in x]                     # doğrusal olmayan aktivasyon fonksiyonu olarak (Non-Linear Activation) olarak ReLU\n",
        "        x = linear(x, state_dict[f'layer{li}.mlp_fc2']) # aynısından bir FC katman daha. Bu sefer aktivasyon yok.\n",
        "        x = [a + b for a, b in zip(x, x_residual)] # yol birleşimi aynı şekilde toplama ile\n",
        "\n",
        "    # Bütün blokları gezdik.\n",
        "    # Çatı Katı: Son katta oluşan vektörü çıktı olarak kullanılacak logitlere dönüştürmek için bir doğrusal katman daha.\n",
        "    logits = linear(x, state_dict['lm_head']) # 16 boyutlu gömülü vektörü 27 boyutlu (her token çeşidi için bir sayı) çıktıya çevir.\n",
        "    return logits # normalize edildiğinde olasılık yerine kullanılabilecek 27 adet skor dönüyoruz.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rTgYYOJSE2o"
      },
      "source": [
        "## Eğitim\n",
        "Eğitim'e başlamak için neredeyse her şey hazır. Optimizasyon için popüler **ADAM (Adaptive Moment Estimation, Uyarlamalı Momement Tahmini)** yöntemini kullanacağız. Eğitim sırasında **Kayıp** değerini (**Loss**) azaltacak şekilde parametreleri değiştireceğimizi söylemiştik. Bunu da **gradyan**ları kullanarak yapacaktık. **Gradyan vektörü** bize **Kaybı artıran doğrultu**yu gösteriyor. Bu vektörün tersi yönde ufak adımlar atarak Kayıp değerini düşürmeye çalışacağız.\n",
        "\n",
        "Bunu sisli bir havada dağdan aşağı inmeye çalışan bir dağcı olarak hayal edebilirsiniz. Görebildiği yakın çevresindeki zeminin eğimine bakarak en çok aşağı yönde eğim olan tarafa doğru bir adım atsın. Her adımda eğini kontrol ederek en dik aşağı eğim olan yöne dönsün. Eğer dağda içine düşebileceği çukurlar yoksa bir şekilde aşağıya inecektir. Bu örnek kabaca **SGD**'ye (**Stochastic Gradient Descent, Rastgele Gradyan İnişi**) benzer.\n",
        "\n",
        "### ADAM Optimizasyonu\n",
        "**ADAM** ise bunun biraz daha akıllısı. Dağcımız her adımda ani yön değişikliği yapmak yerine önceki yönünü de biraz koruyor. Bunun için iki tane vektörü (moment) hafızada tutacağız. İlki momentum (m) vektörü. Bu önceki gradyanların üstel hareketli ortalaması. Yani eski değerler giderek daha az katkı sağlıyor. `beta1` hiperparametresi burada 0.85 olarak seçilmiş ve bu azalma miktarını belirliyor:\n",
        "\n",
        "```python\n",
        "m[i] = beta1 * m[i] + (1 - beta1) * p.grad\n",
        "```\n",
        "Bu momemntum yöntemi tek başına da kullanılabilir. Ancak ADAM yönteminde bu momentumun yanına  RMSprop yönteminden gelen ve gradyanın karesine bağlı ikinci bir moment daha ekliyoruz:\n",
        "```\n",
        "v[i] = beta2 * v[i] + (1 - beta2) * p.grad ** 2\n",
        "```\n",
        "Bu iki değer ilk adımlarda 0 gelecek. Bunu düzeltmek için **Sapma Düzeltmesi** (**Bias Correction**) denen bir iyileştirme yapıyoruz.\n",
        "$$\\hat{m}_t\n",
        "=\n",
        "\\frac{m_t}{1 - \\beta_1^t}$$\n",
        "$$\\hat{v}_t\n",
        "=\n",
        "\\frac{v_t}{1 - \\beta_2^t}$$\n",
        "\n",
        "Parametreyi bunları kullanarak şu şekilde güncelleyeceğiz:\n",
        "$$\\theta_{t+1}\n",
        "=\n",
        "\\theta_t\n",
        "-\n",
        "\\eta\n",
        "\\frac{\\hat{m}_t}\n",
        "{\\sqrt{\\hat{v}_t} + \\epsilon}$$\n",
        "Burada $\\theta_t$ güncellenecek parametre, $\\eta$ bizim belirlediğimiz öğrenme oranı (`learning_rate`), $\\epsilon$ sıfıra bölmeyi engellemek için çok küçük bir değer. Koddaki satır bunun aynısı:\n",
        "\n",
        "```p.data -= lr_t * m_hat / (v_hat ** 0.5 + eps_adam)```\n",
        "\n",
        "### Eğitim Hedefi\n",
        "\n",
        "Bildiğiniz gibi, şu ana kadar üretilen tokenleri girdi olarak verip sıradaki tokeni tahmin etmek istiyoruz. Bir dizideki değerleri geçmişte çıkmış değerlere bakarak üretme yöntemine teknik olarak **Otoregresyon (Autoregression)**, bu tür bir modele de **Otoregresif (Autoregressive)** model diyoruz. **Üretken (Generative)** Modellerde kullanılan yöntemlerden biri bu, ama elbette başka yöntemler de var. Dil modelleri ve gpt bağlamında buna **Next Token Prediction (Sonraki Token Tahmini)** deniyor.\n",
        "\n",
        "`gpt()` fonsiyonumuz en son üretilen tokeni (harfi), bunun dizi içindeki sırasını ve geşmişte çıkan harfleri KV-önbelleğini alıyordu. Çıktı olarak ise bir sonraki tokenin hangisi olduğunun olasılığıyla orantılı sayılar dönüyordu (`logits`). Eğitim veri setinde doğru cevabı, yani sonraki harfin ne olması gerektiğini biliyoruz. Kodda bu do[ru cevaba  `target_id` diyeceğiz. Örneğin 'emma' ismi için 'emm' girdisi verildiğinde  modelin a'ya en yüksek logiti dönmesini istiyoruz (`target_id` = 'a'nin token id'si).\n",
        "\n",
        "### Kayıp Fonksiyonu\n",
        "En kritik noktalardan birine geldik. Meşhur kayıp fonksiyonumuzu tanımlayacağız. Bu bize hangi ölçüye göre parametreleri optimize edeceğimizi gösterecek. Yani modelimize neyi öğrenmesini istediğimizi söyleyeceğiz.  `target_id`'yi yukarıda tanımlamıştık. Modelimizin bu hedefe ne kadar ulaştığını kayıp fonksiyonumuz ölçecek.\n",
        "\n",
        "Öncelikle `gpt()`'nin döndüğü `logit`leri **olasılık**lara (toplamları 1 olacak şekilde [0, 1] arası sayılar) çevirmek için yine `softmax` fonksiyonumuzu kullanıyoruz.\n",
        "\n",
        "Burada kullanacağımız kayıp fonksiyonu **Cross Entropy Loss (Çapraz Entropi Kaybı)** diye geçiyor ve **çoklu sınıflandırma** görevlerinde sık kullanılıyor.\n",
        "$$L =\n",
        "- \\sum_{i=1}^{C}\n",
        "y_i \\log(\\hat{y}_i)$$\n",
        "\n",
        "(Alfabedeki C farklı token için; $y_i$ bir tokenin gerçek olasılığını, $\\hat{y}$ ise aynı tokene modelin atadığı olasılığı gösteriyor.\n",
        "\n",
        "İdeal durumda modelimiz doğru cevap için, yani `target_id` için 1.0 olasılığı, diğer bütün tokenler için ise 0.0 olasılığını dönmeli. Bu durumda Çapraz Entropi sadeleşerek **log-loss**'a (**logaritmik kayıp**) dönüşüyor.\n",
        "\n",
        "$$L = -\\log(\\hat{y}_{k})$$\n",
        "\n",
        "Veya kod olarak:\n",
        "```loss_t = -probs[target_id].log()```\n",
        "\n",
        "Bunun ne yaptığını anlamaya çalışalım. Eğer modelimiz mükemmel çalışır ve `target_id` için `1.0` olasılığı dönerse, $log(1) = 0$ olduğu için kayıp sıfır olacak.\n",
        "\n",
        "Tersine modelimiz kötü çalışır ve 1.0 yerine 0 a yakın bir olasılık dönerse log(p) eksi sonsuza, -log(p) ise artı sonsuza yaklaşacak (log(0) tanımsız).\n",
        "\n",
        "Pratikte yanlış cevaplar için kayıp yüksek bir sayı vererek modeli uyarıyor, doğruya yaklaşan cevaplarda da 0'a yakın kayıp hesaplıyoruz. Yapmak istediğimiz şey de buydu.\n",
        "\n",
        "Modelin hiçbir şey öğrenmeden rastgele tahminde bulunduğunu düşünelim. 27 seçenek olduğu için doğru tutturma olasılığı 1/27. `-log(1/27) = 3.3` (log $e$ tabanlı doğal logaritma). Yani rastgele sallayan bir modelin kayıp değeri 3.3 olmalı ve öğrendikçe bu değer azalmalı. Bunu aşağıdaki eğitimi çalıştırdığınızda kendiniz kontrol etmeyi unutmayın.\n",
        "\n",
        "Son olarak, isimdeki her token için sırayla hesapladığımız kayıp değerlerinin ortalamasını alıyoruz. Bu değer bizim asıl kayıp değerimiz oluyor. `loss.backward()` ile model boyunca geriye giderek bu kayba göre gradyanları hesaplatıyoruz. Loss da dahil olmak üzere gpt'nin yarattığı ve döndürdüğü  `Value` nesneleri ile yaptığımız bütün matematik işlemlerinin yerel türevleri **Hesaplama Grafiğine (Computational Graph)** otomatik olarak kaydedildi. `loss` bu grafiğin en sonundaki `Value` nesnesi olduğu için bunun üzerinden çağrılan `loss.backward()`, bütün `.grad` değerlerini lossa göre hesaplayacak.\n",
        "\n",
        " Sonrasında **ADAM** bu hesaplanan gradyanlara bakarak parametreleri kaybı düşürecek yönde güncelliyor. Ve sonraki eğitim **adım**ına geçip **kayıp hesaplama** ve **parametre güncelleme** işlemlerini tekrar ediyoruz. Bu örnekte her adımda farklı 1 isim için kayıp hesaplandığından her adımda kayıp düşüyor gibi görünmese bile, eğitim ilerledikçe kaybın azaldığını göreceksiniz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLnG0VafR1g_",
        "outputId": "45041076-ed41-4885-c9e5-54e2849a307f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "adım    1 / 1000 | kayıp 3.3660, tokenler: [26, 24, 20, 7, 4, 13, 6, 26]\n",
            "adım    2 / 1000 | kayıp 3.4243, tokenler: [26, 3, 8, 14, 13, 3, 17, 4, 26]\n",
            "adım    3 / 1000 | kayıp 3.1778, tokenler: [26, 23, 0, 21, 8, 4, 13, 26]\n",
            "adım    4 / 1000 | kayıp 3.0664, tokenler: [26, 9, 14, 17, 8, 26]\n",
            "adım    5 / 1000 | kayıp 3.2209, tokenler: [26, 9, 20, 0, 13, 11, 20, 8, 18, 26]\n",
            "adım    6 / 1000 | kayıp 2.9452, tokenler: [26, 4, 17, 0, 13, 3, 8, 26]\n",
            "adım    7 / 1000 | kayıp 3.2894, tokenler: [26, 15, 7, 8, 0, 26]\n",
            "adım    8 / 1000 | kayıp 3.3245, tokenler: [26, 18, 0, 12, 0, 19, 7, 0, 26]\n",
            "adım    9 / 1000 | kayıp 2.8990, tokenler: [26, 15, 7, 14, 4, 13, 8, 23, 26]\n",
            "adım   10 / 1000 | kayıp 3.2229, tokenler: [26, 4, 12, 12, 4, 11, 24, 13, 13, 26]\n",
            "adım   11 / 1000 | kayıp 2.7964, tokenler: [26, 7, 14, 11, 11, 0, 13, 26]\n",
            "adım   12 / 1000 | kayıp 2.9345, tokenler: [26, 7, 14, 11, 11, 8, 18, 26]\n",
            "adım   13 / 1000 | kayıp 3.0544, tokenler: [26, 2, 0, 11, 11, 0, 11, 8, 11, 24, 26]\n",
            "adım   14 / 1000 | kayıp 3.0905, tokenler: [26, 0, 3, 4, 11, 0, 24, 3, 4, 26]\n",
            "adım   15 / 1000 | kayıp 3.0651, tokenler: [26, 9, 14, 18, 4, 15, 7, 24, 13, 4, 26]\n",
            "adım   16 / 1000 | kayıp 2.7337, tokenler: [26, 22, 4, 11, 3, 14, 13, 26]\n",
            "adım   17 / 1000 | kayıp 2.8839, tokenler: [26, 10, 0, 24, 11, 4, 26]\n",
            "adım   18 / 1000 | kayıp 2.8977, tokenler: [26, 17, 0, 6, 13, 0, 17, 26]\n",
            "adım   19 / 1000 | kayıp 2.7073, tokenler: [26, 2, 14, 11, 1, 8, 4, 26]\n",
            "adım   20 / 1000 | kayıp 2.7453, tokenler: [26, 19, 0, 21, 4, 14, 13, 26]\n",
            "adım   21 / 1000 | kayıp 3.7212, tokenler: [26, 0, 10, 8, 26]\n",
            "adım   22 / 1000 | kayıp 2.8026, tokenler: [26, 15, 4, 24, 19, 4, 13, 26]\n",
            "adım   23 / 1000 | kayıp 2.8241, tokenler: [26, 10, 4, 21, 0, 17, 8, 26]\n",
            "adım   24 / 1000 | kayıp 2.0374, tokenler: [26, 9, 14, 4, 11, 11, 0, 26]\n",
            "adım   25 / 1000 | kayıp 3.3698, tokenler: [26, 12, 4, 2, 2, 0, 26]\n",
            "adım   26 / 1000 | kayıp 2.9154, tokenler: [26, 4, 6, 0, 13, 26]\n",
            "adım   27 / 1000 | kayıp 3.2795, tokenler: [26, 9, 20, 18, 19, 24, 2, 4, 26]\n",
            "adım   28 / 1000 | kayıp 2.9195, tokenler: [26, 19, 0, 11, 8, 24, 0, 7, 26]\n",
            "adım   29 / 1000 | kayıp 2.3027, tokenler: [26, 7, 0, 24, 11, 4, 24, 26]\n",
            "adım   30 / 1000 | kayıp 2.2691, tokenler: [26, 0, 11, 11, 4, 0, 7, 26]\n",
            "adım   31 / 1000 | kayıp 2.8957, tokenler: [26, 10, 24, 12, 1, 4, 17, 11, 24, 13, 13, 26]\n",
            "adım   32 / 1000 | kayıp 2.9539, tokenler: [26, 15, 0, 17, 17, 8, 18, 7, 26]\n",
            "adım   33 / 1000 | kayıp 2.6819, tokenler: [26, 7, 14, 20, 18, 19, 24, 13, 26]\n",
            "adım   34 / 1000 | kayıp 2.1899, tokenler: [26, 9, 0, 12, 0, 24, 0, 26]\n",
            "adım   35 / 1000 | kayıp 3.1121, tokenler: [26, 0, 7, 12, 14, 3, 26]\n",
            "adım   36 / 1000 | kayıp 2.7269, tokenler: [26, 13, 8, 21, 8, 13, 26]\n",
            "adım   37 / 1000 | kayıp 2.4928, tokenler: [26, 12, 8, 11, 11, 8, 26]\n",
            "adım   38 / 1000 | kayıp 2.9746, tokenler: [26, 2, 17, 8, 18, 19, 8, 0, 13, 0, 26]\n",
            "adım   39 / 1000 | kayıp 2.2992, tokenler: [26, 9, 0, 8, 12, 4, 4, 26]\n",
            "adım   40 / 1000 | kayıp 2.8604, tokenler: [26, 12, 8, 19, 2, 7, 4, 11, 11, 26]\n",
            "adım   41 / 1000 | kayıp 2.3052, tokenler: [26, 13, 0, 8, 17, 0, 7, 26]\n",
            "adım   42 / 1000 | kayıp 2.5615, tokenler: [26, 11, 14, 17, 4, 13, 0, 26]\n",
            "adım   43 / 1000 | kayıp 2.9018, tokenler: [26, 6, 4, 13, 19, 17, 8, 4, 26]\n",
            "adım   44 / 1000 | kayıp 2.4472, tokenler: [26, 19, 14, 17, 17, 8, 14, 13, 26]\n",
            "adım   45 / 1000 | kayıp 2.1513, tokenler: [26, 18, 0, 21, 8, 0, 13, 26]\n",
            "adım   46 / 1000 | kayıp 3.0613, tokenler: [26, 1, 4, 13, 9, 0, 12, 8, 13, 4, 26]\n",
            "adım   47 / 1000 | kayıp 2.5581, tokenler: [26, 0, 8, 17, 4, 18, 18, 26]\n",
            "adım   48 / 1000 | kayıp 3.0171, tokenler: [26, 10, 13, 20, 19, 4, 26]\n",
            "adım   49 / 1000 | kayıp 2.6902, tokenler: [26, 18, 20, 11, 19, 0, 13, 0, 26]\n",
            "adım   50 / 1000 | kayıp 2.4050, tokenler: [26, 3, 0, 13, 0, 8, 26]\n",
            "adım   51 / 1000 | kayıp 3.6813, tokenler: [26, 0, 25, 25, 0, 13, 26]\n",
            "adım   52 / 1000 | kayıp 2.8990, tokenler: [26, 8, 18, 18, 0, 1, 4, 11, 11, 4, 26]\n",
            "adım   53 / 1000 | kayıp 3.0358, tokenler: [26, 0, 1, 17, 0, 7, 8, 12, 26]\n",
            "adım   54 / 1000 | kayıp 2.2217, tokenler: [26, 0, 8, 18, 11, 24, 13, 26]\n",
            "adım   55 / 1000 | kayıp 2.7366, tokenler: [26, 0, 4, 17, 24, 18, 26]\n",
            "adım   56 / 1000 | kayıp 2.2113, tokenler: [26, 12, 0, 11, 0, 8, 24, 0, 26]\n",
            "adım   57 / 1000 | kayıp 2.6736, tokenler: [26, 10, 8, 4, 14, 13, 26]\n",
            "adım   58 / 1000 | kayıp 2.4947, tokenler: [26, 0, 24, 0, 13, 18, 7, 26]\n",
            "adım   59 / 1000 | kayıp 2.6330, tokenler: [26, 1, 4, 17, 10, 11, 4, 4, 26]\n",
            "adım   60 / 1000 | kayıp 2.9024, tokenler: [26, 4, 12, 12, 0, 10, 0, 19, 4, 26]\n",
            "adım   61 / 1000 | kayıp 2.6594, tokenler: [26, 0, 21, 0, 13, 4, 4, 18, 7, 26]\n",
            "adım   62 / 1000 | kayıp 2.4527, tokenler: [26, 0, 12, 4, 13, 0, 3, 8, 4, 11, 26]\n",
            "adım   63 / 1000 | kayıp 2.7178, tokenler: [26, 17, 4, 13, 0, 17, 3, 14, 26]\n",
            "adım   64 / 1000 | kayıp 2.8619, tokenler: [26, 1, 17, 4, 10, 10, 4, 13, 26]\n",
            "adım   65 / 1000 | kayıp 2.8474, tokenler: [26, 10, 0, 12, 17, 24, 26]\n",
            "adım   66 / 1000 | kayıp 2.8673, tokenler: [26, 22, 24, 11, 8, 13, 26]\n",
            "adım   67 / 1000 | kayıp 2.7473, tokenler: [26, 19, 17, 8, 23, 8, 4, 26]\n",
            "adım   68 / 1000 | kayıp 2.5459, tokenler: [26, 1, 17, 4, 18, 11, 24, 13, 13, 26]\n",
            "adım   69 / 1000 | kayıp 2.5597, tokenler: [26, 1, 8, 0, 13, 10, 0, 26]\n",
            "adım   70 / 1000 | kayıp 2.8365, tokenler: [26, 12, 14, 17, 3, 2, 7, 0, 8, 26]\n",
            "adım   71 / 1000 | kayıp 3.4163, tokenler: [26, 7, 0, 14, 24, 20, 26]\n",
            "adım   72 / 1000 | kayıp 2.5205, tokenler: [26, 5, 17, 0, 13, 10, 8, 4, 26]\n",
            "adım   73 / 1000 | kayıp 2.5853, tokenler: [26, 9, 14, 18, 18, 4, 11, 8, 13, 26]\n",
            "adım   74 / 1000 | kayıp 2.4236, tokenler: [26, 18, 0, 8, 11, 0, 26]\n",
            "adım   75 / 1000 | kayıp 2.4053, tokenler: [26, 10, 8, 14, 13, 13, 0, 26]\n",
            "adım   76 / 1000 | kayıp 2.7836, tokenler: [26, 9, 4, 13, 13, 8, 13, 6, 18, 26]\n",
            "adım   77 / 1000 | kayıp 2.8438, tokenler: [26, 0, 17, 11, 8, 13, 6, 19, 14, 13, 26]\n",
            "adım   78 / 1000 | kayıp 3.0302, tokenler: [26, 9, 20, 15, 8, 19, 4, 17, 26]\n",
            "adım   79 / 1000 | kayıp 2.3869, tokenler: [26, 0, 11, 4, 8, 18, 7, 0, 26]\n",
            "adım   80 / 1000 | kayıp 2.3910, tokenler: [26, 10, 4, 12, 14, 17, 0, 7, 26]\n",
            "adım   81 / 1000 | kayıp 2.3688, tokenler: [26, 3, 4, 13, 8, 18, 18, 4, 26]\n",
            "adım   82 / 1000 | kayıp 3.1079, tokenler: [26, 25, 0, 3, 0, 26]\n",
            "adım   83 / 1000 | kayıp 2.5942, tokenler: [26, 10, 0, 24, 3, 24, 13, 2, 4, 26]\n",
            "adım   84 / 1000 | kayıp 2.1857, tokenler: [26, 1, 0, 17, 8, 26]\n",
            "adım   85 / 1000 | kayıp 2.1898, tokenler: [26, 3, 0, 17, 24, 0, 26]\n",
            "adım   86 / 1000 | kayıp 2.4624, tokenler: [26, 4, 11, 11, 8, 4, 0, 13, 13, 4, 26]\n",
            "adım   87 / 1000 | kayıp 2.9832, tokenler: [26, 6, 17, 4, 19, 4, 11, 26]\n",
            "adım   88 / 1000 | kayıp 2.7304, tokenler: [26, 12, 0, 7, 13, 14, 14, 17, 26]\n",
            "adım   89 / 1000 | kayıp 2.6506, tokenler: [26, 0, 17, 24, 14, 26]\n",
            "adım   90 / 1000 | kayıp 2.5744, tokenler: [26, 12, 8, 11, 4, 18, 26]\n",
            "adım   91 / 1000 | kayıp 2.5922, tokenler: [26, 4, 21, 0, 11, 8, 18, 4, 26]\n",
            "adım   92 / 1000 | kayıp 3.1646, tokenler: [26, 8, 6, 14, 17, 26]\n",
            "adım   93 / 1000 | kayıp 2.9175, tokenler: [26, 19, 7, 14, 17, 4, 13, 26]\n",
            "adım   94 / 1000 | kayıp 2.9945, tokenler: [26, 7, 4, 2, 19, 14, 17, 26]\n",
            "adım   95 / 1000 | kayıp 2.3016, tokenler: [26, 0, 13, 20, 4, 11, 26]\n",
            "adım   96 / 1000 | kayıp 2.4319, tokenler: [26, 4, 12, 12, 4, 17, 8, 4, 26]\n",
            "adım   97 / 1000 | kayıp 2.0333, tokenler: [26, 4, 17, 8, 0, 13, 26]\n",
            "adım   98 / 1000 | kayıp 3.3962, tokenler: [26, 1, 11, 0, 10, 4, 11, 4, 8, 6, 7, 26]\n",
            "adım   99 / 1000 | kayıp 2.2613, tokenler: [26, 12, 0, 3, 8, 13, 0, 26]\n",
            "adım  100 / 1000 | kayıp 3.3669, tokenler: [26, 5, 0, 19, 20, 12, 0, 19, 0, 26]\n",
            "adım  101 / 1000 | kayıp 2.4483, tokenler: [26, 0, 12, 1, 4, 17, 11, 4, 26]\n",
            "adım  102 / 1000 | kayıp 2.2889, tokenler: [26, 10, 4, 18, 18, 0, 26]\n",
            "adım  103 / 1000 | kayıp 2.7991, tokenler: [26, 17, 20, 10, 0, 24, 0, 26]\n",
            "adım  104 / 1000 | kayıp 2.6872, tokenler: [26, 3, 8, 12, 8, 19, 17, 24, 26]\n",
            "adım  105 / 1000 | kayıp 2.6311, tokenler: [26, 2, 14, 13, 11, 8, 13, 26]\n",
            "adım  106 / 1000 | kayıp 2.4243, tokenler: [26, 3, 8, 0, 17, 24, 26]\n",
            "adım  107 / 1000 | kayıp 2.8984, tokenler: [26, 6, 8, 0, 21, 14, 13, 13, 8, 26]\n",
            "adım  108 / 1000 | kayıp 2.2613, tokenler: [26, 10, 24, 17, 8, 13, 26]\n",
            "adım  109 / 1000 | kayıp 2.2090, tokenler: [26, 10, 4, 18, 4, 0, 13, 26]\n",
            "adım  110 / 1000 | kayıp 2.5113, tokenler: [26, 0, 3, 3, 8, 4, 26]\n",
            "adım  111 / 1000 | kayıp 2.6165, tokenler: [26, 8, 12, 12, 0, 13, 20, 4, 11, 26]\n",
            "adım  112 / 1000 | kayıp 2.6483, tokenler: [26, 2, 0, 4, 3, 24, 13, 26]\n",
            "adım  113 / 1000 | kayıp 2.6772, tokenler: [26, 19, 24, 17, 4, 8, 10, 26]\n",
            "adım  114 / 1000 | kayıp 2.2588, tokenler: [26, 12, 0, 17, 19, 24, 26]\n",
            "adım  115 / 1000 | kayıp 2.2152, tokenler: [26, 12, 0, 10, 4, 11, 11, 4, 26]\n",
            "adım  116 / 1000 | kayıp 2.8152, tokenler: [26, 13, 0, 7, 18, 7, 14, 13, 26]\n",
            "adım  117 / 1000 | kayıp 2.6372, tokenler: [26, 1, 17, 0, 13, 19, 11, 4, 24, 26]\n",
            "adım  118 / 1000 | kayıp 2.0875, tokenler: [26, 1, 17, 24, 11, 8, 26]\n",
            "adım  119 / 1000 | kayıp 2.5167, tokenler: [26, 4, 21, 4, 11, 11, 0, 26]\n",
            "adım  120 / 1000 | kayıp 2.6920, tokenler: [26, 22, 4, 18, 19, 11, 4, 24, 26]\n",
            "adım  121 / 1000 | kayıp 2.3495, tokenler: [26, 12, 0, 2, 8, 0, 7, 26]\n",
            "adım  122 / 1000 | kayıp 2.2998, tokenler: [26, 17, 0, 24, 0, 13, 13, 26]\n",
            "adım  123 / 1000 | kayıp 2.7507, tokenler: [26, 0, 8, 25, 0, 7, 26]\n",
            "adım  124 / 1000 | kayıp 2.5124, tokenler: [26, 18, 11, 14, 0, 13, 4, 26]\n",
            "adım  125 / 1000 | kayıp 3.0075, tokenler: [26, 5, 20, 19, 20, 17, 4, 26]\n",
            "adım  126 / 1000 | kayıp 2.2402, tokenler: [26, 0, 8, 3, 4, 13, 26]\n",
            "adım  127 / 1000 | kayıp 2.6489, tokenler: [26, 9, 0, 7, 13, 8, 24, 0, 26]\n",
            "adım  128 / 1000 | kayıp 2.2248, tokenler: [26, 10, 0, 17, 3, 4, 17, 26]\n",
            "adım  129 / 1000 | kayıp 2.1412, tokenler: [26, 4, 12, 4, 17, 11, 4, 4, 26]\n",
            "adım  130 / 1000 | kayıp 3.0851, tokenler: [26, 10, 22, 0, 1, 4, 13, 0, 26]\n",
            "adım  131 / 1000 | kayıp 2.8208, tokenler: [26, 7, 0, 17, 5, 0, 19, 4, 7, 26]\n",
            "adım  132 / 1000 | kayıp 2.0810, tokenler: [26, 2, 0, 12, 17, 4, 13, 26]\n",
            "adım  133 / 1000 | kayıp 2.8060, tokenler: [26, 4, 13, 17, 8, 2, 14, 26]\n",
            "adım  134 / 1000 | kayıp 2.7096, tokenler: [26, 12, 8, 10, 8, 24, 0, 18, 26]\n",
            "adım  135 / 1000 | kayıp 2.6401, tokenler: [26, 19, 17, 4, 0, 18, 20, 17, 4, 26]\n",
            "adım  136 / 1000 | kayıp 3.1040, tokenler: [26, 5, 11, 4, 20, 17, 26]\n",
            "adım  137 / 1000 | kayıp 2.1829, tokenler: [26, 9, 8, 13, 0, 13, 26]\n",
            "adım  138 / 1000 | kayıp 2.2031, tokenler: [26, 18, 20, 10, 0, 24, 13, 0, 26]\n",
            "adım  139 / 1000 | kayıp 2.7783, tokenler: [26, 1, 17, 4, 13, 13, 14, 23, 26]\n",
            "adım  140 / 1000 | kayıp 2.5121, tokenler: [26, 1, 17, 0, 13, 19, 26]\n",
            "adım  141 / 1000 | kayıp 3.2092, tokenler: [26, 14, 18, 1, 0, 11, 3, 14, 26]\n",
            "adım  142 / 1000 | kayıp 2.3187, tokenler: [26, 10, 0, 18, 15, 8, 0, 13, 26]\n",
            "adım  143 / 1000 | kayıp 3.1077, tokenler: [26, 24, 4, 7, 20, 3, 8, 19, 26]\n",
            "adım  144 / 1000 | kayıp 2.2708, tokenler: [26, 19, 0, 15, 0, 13, 6, 0, 26]\n",
            "adım  145 / 1000 | kayıp 2.6134, tokenler: [26, 25, 24, 0, 8, 17, 4, 26]\n",
            "adım  146 / 1000 | kayıp 2.5703, tokenler: [26, 9, 0, 25, 11, 24, 26]\n",
            "adım  147 / 1000 | kayıp 2.2524, tokenler: [26, 19, 0, 24, 17, 14, 13, 26]\n",
            "adım  148 / 1000 | kayıp 2.3684, tokenler: [26, 9, 4, 13, 14, 21, 0, 26]\n",
            "adım  149 / 1000 | kayıp 2.1724, tokenler: [26, 2, 8, 0, 17, 17, 0, 26]\n",
            "adım  150 / 1000 | kayıp 2.5351, tokenler: [26, 1, 4, 11, 11, 0, 13, 14, 21, 0, 26]\n",
            "adım  151 / 1000 | kayıp 2.9063, tokenler: [26, 3, 14, 12, 8, 13, 8, 2, 26]\n",
            "adım  152 / 1000 | kayıp 2.4862, tokenler: [26, 11, 0, 25, 8, 24, 0, 7, 26]\n",
            "adım  153 / 1000 | kayıp 2.8622, tokenler: [26, 0, 10, 8, 13, 26]\n",
            "adım  154 / 1000 | kayıp 3.1861, tokenler: [26, 0, 3, 0, 12, 26]\n",
            "adım  155 / 1000 | kayıp 2.5595, tokenler: [26, 21, 4, 13, 0, 13, 2, 8, 14, 26]\n",
            "adım  156 / 1000 | kayıp 2.8595, tokenler: [26, 10, 17, 8, 18, 19, 0, 1, 4, 11, 11, 4, 26]\n",
            "adım  157 / 1000 | kayıp 3.2600, tokenler: [26, 15, 14, 11, 14, 26]\n",
            "adım  158 / 1000 | kayıp 2.0037, tokenler: [26, 10, 0, 11, 11, 0, 13, 26]\n",
            "adım  159 / 1000 | kayıp 3.3867, tokenler: [26, 0, 1, 1, 24, 26]\n",
            "adım  160 / 1000 | kayıp 2.1104, tokenler: [26, 11, 8, 11, 8, 0, 13, 26]\n",
            "adım  161 / 1000 | kayıp 2.2022, tokenler: [26, 1, 17, 0, 3, 24, 13, 26]\n",
            "adım  162 / 1000 | kayıp 2.6278, tokenler: [26, 20, 12, 0, 24, 12, 0, 26]\n",
            "adım  163 / 1000 | kayıp 2.5539, tokenler: [26, 18, 4, 21, 0, 18, 19, 8, 0, 13, 26]\n",
            "adım  164 / 1000 | kayıp 2.4285, tokenler: [26, 4, 12, 12, 0, 13, 20, 4, 11, 11, 4, 26]\n",
            "adım  165 / 1000 | kayıp 2.3338, tokenler: [26, 18, 20, 0, 13, 26]\n",
            "adım  166 / 1000 | kayıp 2.6923, tokenler: [26, 9, 20, 13, 8, 20, 18, 26]\n",
            "adım  167 / 1000 | kayıp 2.1427, tokenler: [26, 0, 12, 4, 13, 0, 26]\n",
            "adım  168 / 1000 | kayıp 2.5276, tokenler: [26, 18, 7, 4, 11, 3, 14, 13, 26]\n",
            "adım  169 / 1000 | kayıp 3.1430, tokenler: [26, 5, 17, 4, 3, 17, 8, 2, 10, 26]\n",
            "adım  170 / 1000 | kayıp 2.5338, tokenler: [26, 5, 8, 13, 13, 26]\n",
            "adım  171 / 1000 | kayıp 2.6454, tokenler: [26, 7, 0, 21, 8, 10, 26]\n",
            "adım  172 / 1000 | kayıp 2.3900, tokenler: [26, 7, 4, 0, 11, 0, 13, 8, 26]\n",
            "adım  173 / 1000 | kayıp 2.2324, tokenler: [26, 4, 11, 8, 17, 0, 26]\n",
            "adım  174 / 1000 | kayıp 3.0033, tokenler: [26, 0, 25, 25, 0, 12, 26]\n",
            "adım  175 / 1000 | kayıp 2.6798, tokenler: [26, 9, 4, 0, 13, 2, 0, 17, 11, 14, 18, 26]\n",
            "adım  176 / 1000 | kayıp 2.5880, tokenler: [26, 19, 0, 11, 0, 24, 4, 7, 26]\n",
            "adım  177 / 1000 | kayıp 3.1046, tokenler: [26, 18, 15, 20, 17, 6, 4, 14, 13, 26]\n",
            "adım  178 / 1000 | kayıp 2.3841, tokenler: [26, 9, 4, 17, 12, 0, 13, 24, 26]\n",
            "adım  179 / 1000 | kayıp 1.9982, tokenler: [26, 12, 8, 0, 11, 0, 13, 8, 26]\n",
            "adım  180 / 1000 | kayıp 2.3556, tokenler: [26, 0, 12, 0, 20, 17, 24, 26]\n",
            "adım  181 / 1000 | kayıp 2.1472, tokenler: [26, 4, 11, 12, 8, 13, 0, 26]\n",
            "adım  182 / 1000 | kayıp 2.0537, tokenler: [26, 10, 14, 17, 17, 8, 13, 26]\n",
            "adım  183 / 1000 | kayıp 1.9403, tokenler: [26, 9, 0, 3, 4, 13, 26]\n",
            "adım  184 / 1000 | kayıp 3.3390, tokenler: [26, 11, 14, 26]\n",
            "adım  185 / 1000 | kayıp 2.1482, tokenler: [26, 0, 12, 0, 7, 24, 0, 26]\n",
            "adım  186 / 1000 | kayıp 2.4919, tokenler: [26, 25, 0, 13, 0, 8, 24, 0, 7, 26]\n",
            "adım  187 / 1000 | kayıp 2.4610, tokenler: [26, 22, 0, 11, 19, 14, 13, 26]\n",
            "adım  188 / 1000 | kayıp 2.4055, tokenler: [26, 10, 11, 0, 17, 8, 19, 24, 26]\n",
            "adım  189 / 1000 | kayıp 1.9792, tokenler: [26, 9, 4, 13, 0, 26]\n",
            "adım  190 / 1000 | kayıp 2.6377, tokenler: [26, 1, 17, 4, 10, 11, 24, 13, 13, 26]\n",
            "adım  191 / 1000 | kayıp 1.7000, tokenler: [26, 2, 0, 17, 8, 0, 13, 0, 26]\n",
            "adım  192 / 1000 | kayıp 2.4035, tokenler: [26, 10, 17, 8, 18, 7, 13, 0, 26]\n",
            "adım  193 / 1000 | kayıp 2.2961, tokenler: [26, 0, 13, 8, 18, 19, 4, 13, 26]\n",
            "adım  194 / 1000 | kayıp 2.8886, tokenler: [26, 11, 4, 13, 25, 8, 4, 26]\n",
            "adım  195 / 1000 | kayıp 2.8026, tokenler: [26, 4, 12, 8, 11, 24, 17, 14, 18, 4, 26]\n",
            "adım  196 / 1000 | kayıp 2.4264, tokenler: [26, 5, 17, 0, 13, 10, 11, 24, 13, 26]\n",
            "adım  197 / 1000 | kayıp 2.3991, tokenler: [26, 18, 7, 8, 17, 4, 4, 13, 26]\n",
            "adım  198 / 1000 | kayıp 3.0697, tokenler: [26, 21, 8, 10, 19, 14, 17, 26]\n",
            "adım  199 / 1000 | kayıp 2.5300, tokenler: [26, 10, 4, 8, 11, 4, 4, 26]\n",
            "adım  200 / 1000 | kayıp 2.3097, tokenler: [26, 0, 12, 4, 11, 8, 0, 17, 14, 18, 4, 26]\n",
            "adım  201 / 1000 | kayıp 2.4874, tokenler: [26, 21, 0, 11, 11, 8, 4, 26]\n",
            "adım  202 / 1000 | kayıp 2.5649, tokenler: [26, 0, 0, 17, 8, 19, 26]\n",
            "adım  203 / 1000 | kayıp 2.1233, tokenler: [26, 10, 4, 13, 3, 0, 11, 4, 26]\n",
            "adım  204 / 1000 | kayıp 1.8898, tokenler: [26, 12, 0, 11, 4, 17, 8, 4, 26]\n",
            "adım  205 / 1000 | kayıp 2.6302, tokenler: [26, 12, 0, 2, 10, 8, 13, 11, 4, 24, 26]\n",
            "adım  206 / 1000 | kayıp 3.1559, tokenler: [26, 17, 0, 12, 25, 8, 26]\n",
            "adım  207 / 1000 | kayıp 2.8998, tokenler: [26, 7, 20, 19, 19, 14, 13, 26]\n",
            "adım  208 / 1000 | kayıp 2.1443, tokenler: [26, 4, 21, 0, 12, 0, 17, 8, 0, 26]\n",
            "adım  209 / 1000 | kayıp 2.2206, tokenler: [26, 12, 14, 12, 4, 13, 26]\n",
            "adım  210 / 1000 | kayıp 2.5670, tokenler: [26, 23, 0, 13, 3, 17, 8, 0, 26]\n",
            "adım  211 / 1000 | kayıp 2.0186, tokenler: [26, 3, 4, 12, 4, 17, 4, 26]\n",
            "adım  212 / 1000 | kayıp 2.3012, tokenler: [26, 10, 0, 24, 11, 14, 13, 13, 8, 4, 26]\n",
            "adım  213 / 1000 | kayıp 3.8427, tokenler: [26, 3, 17, 20, 21, 26]\n",
            "adım  214 / 1000 | kayıp 2.2129, tokenler: [26, 9, 0, 13, 8, 26]\n",
            "adım  215 / 1000 | kayıp 2.4124, tokenler: [26, 10, 0, 8, 3, 4, 13, 2, 4, 26]\n",
            "adım  216 / 1000 | kayıp 2.5136, tokenler: [26, 25, 0, 17, 4, 3, 26]\n",
            "adım  217 / 1000 | kayıp 2.3378, tokenler: [26, 9, 17, 0, 10, 4, 26]\n",
            "adım  218 / 1000 | kayıp 2.5365, tokenler: [26, 3, 0, 17, 24, 20, 18, 26]\n",
            "adım  219 / 1000 | kayıp 2.3739, tokenler: [26, 0, 20, 18, 19, 14, 13, 26]\n",
            "adım  220 / 1000 | kayıp 2.4205, tokenler: [26, 17, 0, 24, 11, 4, 8, 26]\n",
            "adım  221 / 1000 | kayıp 3.0695, tokenler: [26, 11, 0, 19, 8, 5, 26]\n",
            "adım  222 / 1000 | kayıp 2.3135, tokenler: [26, 17, 0, 3, 11, 4, 24, 26]\n",
            "adım  223 / 1000 | kayıp 2.1625, tokenler: [26, 0, 21, 4, 17, 4, 24, 26]\n",
            "adım  224 / 1000 | kayıp 2.3273, tokenler: [26, 18, 0, 0, 13, 24, 0, 26]\n",
            "adım  225 / 1000 | kayıp 2.2527, tokenler: [26, 9, 0, 24, 2, 4, 4, 26]\n",
            "adım  226 / 1000 | kayıp 2.4193, tokenler: [26, 0, 11, 11, 8, 18, 14, 13, 26]\n",
            "adım  227 / 1000 | kayıp 2.4528, tokenler: [26, 2, 7, 4, 17, 8, 4, 26]\n",
            "adım  228 / 1000 | kayıp 2.5524, tokenler: [26, 3, 4, 22, 0, 24, 13, 4, 26]\n",
            "adım  229 / 1000 | kayıp 3.0859, tokenler: [26, 10, 14, 11, 26]\n",
            "adım  230 / 1000 | kayıp 1.7900, tokenler: [26, 0, 24, 0, 17, 8, 4, 26]\n",
            "adım  231 / 1000 | kayıp 3.1017, tokenler: [26, 2, 0, 19, 7, 0, 11, 8, 13, 0, 26]\n",
            "adım  232 / 1000 | kayıp 2.4001, tokenler: [26, 0, 8, 3, 24, 13, 26]\n",
            "adım  233 / 1000 | kayıp 2.3035, tokenler: [26, 0, 13, 18, 4, 13, 26]\n",
            "adım  234 / 1000 | kayıp 2.7662, tokenler: [26, 25, 0, 24, 11, 4, 8, 6, 7, 26]\n",
            "adım  235 / 1000 | kayıp 2.0570, tokenler: [26, 0, 3, 11, 4, 24, 26]\n",
            "adım  236 / 1000 | kayıp 2.7383, tokenler: [26, 13, 14, 21, 0, 7, 26]\n",
            "adım  237 / 1000 | kayıp 2.2569, tokenler: [26, 18, 10, 24, 11, 4, 24, 26]\n",
            "adım  238 / 1000 | kayıp 2.6960, tokenler: [26, 10, 7, 0, 12, 8, 11, 26]\n",
            "adım  239 / 1000 | kayıp 2.4001, tokenler: [26, 1, 17, 8, 14, 13, 26]\n",
            "adım  240 / 1000 | kayıp 3.6365, tokenler: [26, 18, 7, 4, 15, 15, 0, 17, 3, 26]\n",
            "adım  241 / 1000 | kayıp 2.8041, tokenler: [26, 10, 4, 8, 18, 7, 0, 22, 13, 26]\n",
            "adım  242 / 1000 | kayıp 2.5392, tokenler: [26, 21, 8, 13, 13, 24, 26]\n",
            "adım  243 / 1000 | kayıp 2.3092, tokenler: [26, 10, 0, 2, 4, 18, 14, 13, 26]\n",
            "adım  244 / 1000 | kayıp 2.6435, tokenler: [26, 1, 11, 0, 25, 4, 26]\n",
            "adım  245 / 1000 | kayıp 2.2066, tokenler: [26, 2, 0, 17, 0, 26]\n",
            "adım  246 / 1000 | kayıp 2.7219, tokenler: [26, 0, 1, 8, 14, 11, 0, 26]\n",
            "adım  247 / 1000 | kayıp 2.4871, tokenler: [26, 6, 4, 17, 8, 4, 11, 26]\n",
            "adım  248 / 1000 | kayıp 2.7047, tokenler: [26, 18, 25, 24, 12, 14, 13, 26]\n",
            "adım  249 / 1000 | kayıp 2.0570, tokenler: [26, 10, 0, 8, 11, 0, 13, 0, 26]\n",
            "adım  250 / 1000 | kayıp 2.1581, tokenler: [26, 0, 17, 0, 2, 4, 11, 8, 18, 26]\n",
            "adım  251 / 1000 | kayıp 1.9875, tokenler: [26, 0, 12, 4, 11, 8, 26]\n",
            "adım  252 / 1000 | kayıp 2.4351, tokenler: [26, 17, 0, 13, 3, 4, 11, 11, 26]\n",
            "adım  253 / 1000 | kayıp 2.7340, tokenler: [26, 3, 0, 9, 0, 26]\n",
            "adım  254 / 1000 | kayıp 1.9832, tokenler: [26, 1, 17, 0, 8, 11, 4, 24, 26]\n",
            "adım  255 / 1000 | kayıp 2.4915, tokenler: [26, 21, 8, 0, 13, 2, 0, 26]\n",
            "adım  256 / 1000 | kayıp 3.5044, tokenler: [26, 9, 4, 15, 26]\n",
            "adım  257 / 1000 | kayıp 2.3991, tokenler: [26, 14, 11, 8, 13, 0, 26]\n",
            "adım  258 / 1000 | kayıp 1.8618, tokenler: [26, 1, 17, 0, 24, 0, 26]\n",
            "adım  259 / 1000 | kayıp 1.9200, tokenler: [26, 3, 0, 17, 11, 4, 13, 24, 26]\n",
            "adım  260 / 1000 | kayıp 1.7671, tokenler: [26, 1, 0, 24, 11, 8, 13, 26]\n",
            "adım  261 / 1000 | kayıp 2.6093, tokenler: [26, 9, 0, 23, 8, 26]\n",
            "adım  262 / 1000 | kayıp 2.2438, tokenler: [26, 10, 14, 11, 24, 13, 26]\n",
            "adım  263 / 1000 | kayıp 2.9581, tokenler: [26, 22, 7, 8, 19, 19, 4, 13, 26]\n",
            "adım  264 / 1000 | kayıp 3.0106, tokenler: [26, 6, 20, 11, 4, 3, 26]\n",
            "adım  265 / 1000 | kayıp 1.8756, tokenler: [26, 0, 10, 8, 11, 0, 13, 26]\n",
            "adım  266 / 1000 | kayıp 2.7724, tokenler: [26, 13, 14, 17, 12, 0, 13, 8, 26]\n",
            "adım  267 / 1000 | kayıp 1.9729, tokenler: [26, 4, 11, 8, 0, 13, 13, 26]\n",
            "adım  268 / 1000 | kayıp 2.1480, tokenler: [26, 7, 0, 17, 11, 4, 0, 26]\n",
            "adım  269 / 1000 | kayıp 2.1096, tokenler: [26, 4, 3, 4, 11, 8, 13, 4, 26]\n",
            "adım  270 / 1000 | kayıp 2.8207, tokenler: [26, 3, 14, 12, 14, 13, 8, 2, 26]\n",
            "adım  271 / 1000 | kayıp 2.2624, tokenler: [26, 3, 4, 21, 14, 13, 13, 4, 26]\n",
            "adım  272 / 1000 | kayıp 1.9211, tokenler: [26, 18, 4, 17, 0, 13, 26]\n",
            "adım  273 / 1000 | kayıp 2.6192, tokenler: [26, 12, 0, 19, 21, 8, 24, 26]\n",
            "adım  274 / 1000 | kayıp 3.0047, tokenler: [26, 15, 4, 0, 17, 18, 4, 26]\n",
            "adım  275 / 1000 | kayıp 2.0174, tokenler: [26, 1, 17, 0, 4, 11, 4, 24, 26]\n",
            "adım  276 / 1000 | kayıp 2.5915, tokenler: [26, 0, 8, 21, 0, 7, 26]\n",
            "adım  277 / 1000 | kayıp 3.1114, tokenler: [26, 25, 24, 0, 8, 17, 26]\n",
            "adım  278 / 1000 | kayıp 2.3490, tokenler: [26, 10, 0, 12, 17, 24, 26]\n",
            "adım  279 / 1000 | kayıp 2.3004, tokenler: [26, 10, 0, 17, 12, 0, 7, 26]\n",
            "adım  280 / 1000 | kayıp 1.9486, tokenler: [26, 18, 0, 11, 4, 4, 13, 26]\n",
            "adım  281 / 1000 | kayıp 3.1744, tokenler: [26, 15, 14, 14, 9, 0, 26]\n",
            "adım  282 / 1000 | kayıp 1.9351, tokenler: [26, 3, 0, 12, 0, 17, 8, 0, 26]\n",
            "adım  283 / 1000 | kayıp 2.4215, tokenler: [26, 9, 0, 7, 12, 0, 11, 26]\n",
            "adım  284 / 1000 | kayıp 2.7351, tokenler: [26, 10, 14, 13, 18, 19, 0, 13, 19, 8, 13, 26]\n",
            "adım  285 / 1000 | kayıp 3.3271, tokenler: [26, 16, 20, 4, 13, 2, 24, 26]\n",
            "adım  286 / 1000 | kayıp 2.1280, tokenler: [26, 10, 4, 14, 13, 0, 26]\n",
            "adım  287 / 1000 | kayıp 2.3728, tokenler: [26, 12, 0, 2, 4, 4, 26]\n",
            "adım  288 / 1000 | kayıp 2.5311, tokenler: [26, 13, 14, 7, 4, 11, 24, 26]\n",
            "adım  289 / 1000 | kayıp 2.4675, tokenler: [26, 18, 11, 0, 24, 3, 4, 26]\n",
            "adım  290 / 1000 | kayıp 2.1163, tokenler: [26, 5, 0, 24, 17, 4, 26]\n",
            "adım  291 / 1000 | kayıp 3.0499, tokenler: [26, 12, 14, 20, 18, 19, 0, 15, 7, 0, 26]\n",
            "adım  292 / 1000 | kayıp 2.3976, tokenler: [26, 9, 0, 13, 13, 4, 19, 7, 26]\n",
            "adım  293 / 1000 | kayıp 1.9984, tokenler: [26, 10, 0, 3, 4, 13, 2, 4, 26]\n",
            "adım  294 / 1000 | kayıp 2.5432, tokenler: [26, 12, 24, 11, 8, 4, 26]\n",
            "adım  295 / 1000 | kayıp 2.7180, tokenler: [26, 11, 0, 13, 8, 0, 10, 4, 0, 26]\n",
            "adım  296 / 1000 | kayıp 2.1555, tokenler: [26, 0, 17, 12, 0, 13, 26]\n",
            "adım  297 / 1000 | kayıp 2.3680, tokenler: [26, 0, 13, 0, 1, 8, 0, 26]\n",
            "adım  298 / 1000 | kayıp 2.6502, tokenler: [26, 11, 14, 22, 4, 13, 26]\n",
            "adım  299 / 1000 | kayıp 2.1947, tokenler: [26, 9, 14, 18, 0, 11, 4, 4, 26]\n",
            "adım  300 / 1000 | kayıp 2.3178, tokenler: [26, 3, 12, 0, 13, 8, 26]\n",
            "adım  301 / 1000 | kayıp 2.6931, tokenler: [26, 11, 8, 13, 3, 4, 11, 11, 26]\n",
            "adım  302 / 1000 | kayıp 2.1736, tokenler: [26, 12, 0, 17, 2, 4, 11, 8, 13, 4, 26]\n",
            "adım  303 / 1000 | kayıp 2.6196, tokenler: [26, 16, 20, 4, 13, 19, 14, 13, 26]\n",
            "adım  304 / 1000 | kayıp 2.3674, tokenler: [26, 12, 0, 4, 21, 24, 13, 26]\n",
            "adım  305 / 1000 | kayıp 2.8884, tokenler: [26, 0, 18, 7, 0, 25, 26]\n",
            "adım  306 / 1000 | kayıp 2.5560, tokenler: [26, 4, 11, 0, 3, 26]\n",
            "adım  307 / 1000 | kayıp 1.9077, tokenler: [26, 10, 0, 12, 8, 0, 26]\n",
            "adım  308 / 1000 | kayıp 2.5663, tokenler: [26, 0, 6, 0, 19, 7, 4, 26]\n",
            "adım  309 / 1000 | kayıp 2.0727, tokenler: [26, 7, 0, 11, 0, 8, 13, 0, 26]\n",
            "adım  310 / 1000 | kayıp 2.3818, tokenler: [26, 24, 0, 13, 13, 8, 18, 26]\n",
            "adım  311 / 1000 | kayıp 3.0383, tokenler: [26, 17, 14, 1, 4, 17, 19, 26]\n",
            "adım  312 / 1000 | kayıp 2.0074, tokenler: [26, 10, 4, 4, 11, 24, 13, 26]\n",
            "adım  313 / 1000 | kayıp 1.7555, tokenler: [26, 11, 0, 13, 13, 8, 4, 26]\n",
            "adım  314 / 1000 | kayıp 2.3456, tokenler: [26, 0, 17, 25, 0, 0, 13, 26]\n",
            "adım  315 / 1000 | kayıp 2.6081, tokenler: [26, 11, 14, 2, 7, 11, 0, 13, 13, 26]\n",
            "adım  316 / 1000 | kayıp 2.0439, tokenler: [26, 12, 0, 13, 0, 12, 8, 26]\n",
            "adım  317 / 1000 | kayıp 2.0600, tokenler: [26, 9, 4, 24, 11, 8, 13, 26]\n",
            "adım  318 / 1000 | kayıp 1.8657, tokenler: [26, 0, 3, 14, 13, 8, 0, 26]\n",
            "adım  319 / 1000 | kayıp 1.9699, tokenler: [26, 12, 8, 0, 13, 13, 0, 26]\n",
            "adım  320 / 1000 | kayıp 1.7969, tokenler: [26, 3, 0, 18, 19, 0, 13, 26]\n",
            "adım  321 / 1000 | kayıp 2.5492, tokenler: [26, 13, 24, 11, 0, 26]\n",
            "adım  322 / 1000 | kayıp 2.4804, tokenler: [26, 4, 21, 0, 13, 3, 4, 17, 26]\n",
            "adım  323 / 1000 | kayıp 2.7345, tokenler: [26, 24, 0, 18, 18, 8, 17, 26]\n",
            "adım  324 / 1000 | kayıp 3.1487, tokenler: [26, 4, 3, 4, 11, 22, 4, 8, 18, 18, 26]\n",
            "adım  325 / 1000 | kayıp 2.4556, tokenler: [26, 3, 0, 18, 7, 8, 4, 11, 11, 26]\n",
            "adım  326 / 1000 | kayıp 2.0597, tokenler: [26, 7, 0, 0, 10, 4, 13, 26]\n",
            "adım  327 / 1000 | kayıp 2.3248, tokenler: [26, 0, 3, 0, 8, 17, 26]\n",
            "adım  328 / 1000 | kayıp 1.9027, tokenler: [26, 0, 12, 17, 0, 13, 26]\n",
            "adım  329 / 1000 | kayıp 2.1499, tokenler: [26, 0, 12, 0, 25, 8, 0, 7, 26]\n",
            "adım  330 / 1000 | kayıp 2.3627, tokenler: [26, 10, 4, 13, 13, 4, 3, 8, 4, 26]\n",
            "adım  331 / 1000 | kayıp 2.1251, tokenler: [26, 17, 4, 13, 0, 19, 0, 26]\n",
            "adım  332 / 1000 | kayıp 2.4151, tokenler: [26, 10, 4, 11, 18, 8, 4, 26]\n",
            "adım  333 / 1000 | kayıp 1.9030, tokenler: [26, 9, 0, 4, 11, 4, 4, 13, 26]\n",
            "adım  334 / 1000 | kayıp 2.8525, tokenler: [26, 10, 24, 12, 1, 17, 8, 4, 26]\n",
            "adım  335 / 1000 | kayıp 3.9066, tokenler: [26, 10, 14, 18, 8, 18, 14, 2, 7, 20, 10, 22, 20, 26]\n",
            "adım  336 / 1000 | kayıp 3.3516, tokenler: [26, 2, 0, 11, 24, 15, 18, 14, 26]\n",
            "adım  337 / 1000 | kayıp 2.6985, tokenler: [26, 15, 7, 8, 13, 11, 4, 24, 26]\n",
            "adım  338 / 1000 | kayıp 2.5921, tokenler: [26, 1, 4, 0, 18, 11, 4, 24, 26]\n",
            "adım  339 / 1000 | kayıp 2.2606, tokenler: [26, 0, 18, 7, 19, 24, 13, 26]\n",
            "adım  340 / 1000 | kayıp 2.1589, tokenler: [26, 12, 0, 2, 11, 24, 13, 26]\n",
            "adım  341 / 1000 | kayıp 3.0280, tokenler: [26, 19, 8, 6, 4, 17, 26]\n",
            "adım  342 / 1000 | kayıp 2.8235, tokenler: [26, 15, 7, 4, 14, 1, 4, 26]\n",
            "adım  343 / 1000 | kayıp 1.8070, tokenler: [26, 10, 0, 8, 13, 0, 13, 26]\n",
            "adım  344 / 1000 | kayıp 2.5350, tokenler: [26, 12, 4, 10, 0, 8, 26]\n",
            "adım  345 / 1000 | kayıp 2.4687, tokenler: [26, 2, 7, 0, 17, 11, 8, 13, 4, 26]\n",
            "adım  346 / 1000 | kayıp 2.4156, tokenler: [26, 0, 13, 6, 4, 11, 14, 26]\n",
            "adım  347 / 1000 | kayıp 2.9995, tokenler: [26, 18, 2, 7, 20, 24, 11, 4, 17, 26]\n",
            "adım  348 / 1000 | kayıp 2.4981, tokenler: [26, 18, 14, 11, 18, 19, 8, 2, 4, 26]\n",
            "adım  349 / 1000 | kayıp 2.6259, tokenler: [26, 12, 0, 19, 19, 26]\n",
            "adım  350 / 1000 | kayıp 2.2592, tokenler: [26, 10, 8, 24, 0, 13, 8, 26]\n",
            "adım  351 / 1000 | kayıp 3.1636, tokenler: [26, 13, 14, 2, 7, 20, 12, 26]\n",
            "adım  352 / 1000 | kayıp 1.9862, tokenler: [26, 4, 11, 4, 13, 0, 7, 26]\n",
            "adım  353 / 1000 | kayıp 2.3807, tokenler: [26, 10, 20, 12, 0, 17, 26]\n",
            "adım  354 / 1000 | kayıp 2.8480, tokenler: [26, 18, 22, 0, 24, 25, 4, 26]\n",
            "adım  355 / 1000 | kayıp 2.5412, tokenler: [26, 24, 0, 1, 3, 8, 4, 11, 26]\n",
            "adım  356 / 1000 | kayıp 2.1290, tokenler: [26, 0, 17, 0, 8, 13, 0, 26]\n",
            "adım  357 / 1000 | kayıp 2.7031, tokenler: [26, 9, 0, 2, 10, 18, 26]\n",
            "adım  358 / 1000 | kayıp 2.0749, tokenler: [26, 10, 8, 4, 17, 2, 4, 26]\n",
            "adım  359 / 1000 | kayıp 1.9376, tokenler: [26, 5, 0, 13, 13, 8, 4, 26]\n",
            "adım  360 / 1000 | kayıp 2.4932, tokenler: [26, 7, 0, 17, 11, 14, 22, 4, 26]\n",
            "adım  361 / 1000 | kayıp 2.5539, tokenler: [26, 9, 20, 11, 4, 18, 26]\n",
            "adım  362 / 1000 | kayıp 2.4702, tokenler: [26, 0, 10, 4, 4, 12, 26]\n",
            "adım  363 / 1000 | kayıp 1.8193, tokenler: [26, 7, 4, 11, 11, 4, 13, 26]\n",
            "adım  364 / 1000 | kayıp 1.9877, tokenler: [26, 0, 19, 0, 11, 8, 0, 26]\n",
            "adım  365 / 1000 | kayıp 2.6337, tokenler: [26, 17, 14, 18, 8, 11, 24, 13, 26]\n",
            "adım  366 / 1000 | kayıp 1.9184, tokenler: [26, 10, 14, 17, 8, 4, 26]\n",
            "adım  367 / 1000 | kayıp 3.0730, tokenler: [26, 6, 4, 14, 17, 6, 8, 14, 26]\n",
            "adım  368 / 1000 | kayıp 2.5106, tokenler: [26, 15, 4, 13, 13, 26]\n",
            "adım  369 / 1000 | kayıp 2.8109, tokenler: [26, 3, 0, 4, 18, 7, 0, 22, 13, 26]\n",
            "adım  370 / 1000 | kayıp 2.0459, tokenler: [26, 19, 0, 12, 0, 17, 8, 26]\n",
            "adım  371 / 1000 | kayıp 2.9865, tokenler: [26, 25, 4, 4, 26]\n",
            "adım  372 / 1000 | kayıp 2.1616, tokenler: [26, 17, 0, 8, 13, 13, 26]\n",
            "adım  373 / 1000 | kayıp 2.7536, tokenler: [26, 4, 10, 0, 12, 26]\n",
            "adım  374 / 1000 | kayıp 2.1206, tokenler: [26, 18, 8, 12, 0, 13, 26]\n",
            "adım  375 / 1000 | kayıp 1.9970, tokenler: [26, 12, 0, 7, 0, 11, 8, 0, 26]\n",
            "adım  376 / 1000 | kayıp 2.4778, tokenler: [26, 0, 7, 12, 4, 4, 17, 26]\n",
            "adım  377 / 1000 | kayıp 2.3444, tokenler: [26, 15, 0, 13, 19, 4, 11, 8, 18, 26]\n",
            "adım  378 / 1000 | kayıp 2.2609, tokenler: [26, 10, 14, 1, 8, 4, 26]\n",
            "adım  379 / 1000 | kayıp 2.4662, tokenler: [26, 25, 0, 25, 8, 11, 26]\n",
            "adım  380 / 1000 | kayıp 2.2087, tokenler: [26, 4, 12, 12, 0, 17, 8, 4, 26]\n",
            "adım  381 / 1000 | kayıp 2.4502, tokenler: [26, 12, 0, 13, 4, 18, 18, 0, 26]\n",
            "adım  382 / 1000 | kayıp 2.7536, tokenler: [26, 13, 8, 11, 8, 26]\n",
            "adım  383 / 1000 | kayıp 2.3231, tokenler: [26, 9, 4, 13, 0, 21, 8, 26]\n",
            "adım  384 / 1000 | kayıp 3.2495, tokenler: [26, 2, 11, 14, 4, 26]\n",
            "adım  385 / 1000 | kayıp 2.9181, tokenler: [26, 18, 2, 7, 20, 24, 11, 4, 17, 26]\n",
            "adım  386 / 1000 | kayıp 2.3336, tokenler: [26, 12, 4, 8, 11, 0, 13, 24, 26]\n",
            "adım  387 / 1000 | kayıp 3.6985, tokenler: [26, 6, 17, 8, 5, 5, 14, 13, 26]\n",
            "adım  388 / 1000 | kayıp 2.2499, tokenler: [26, 17, 14, 18, 4, 11, 8, 13, 0, 26]\n",
            "adım  389 / 1000 | kayıp 2.3085, tokenler: [26, 0, 25, 0, 11, 0, 24, 0, 26]\n",
            "adım  390 / 1000 | kayıp 3.1236, tokenler: [26, 2, 7, 8, 0, 6, 14, 25, 8, 4, 12, 26]\n",
            "adım  391 / 1000 | kayıp 2.4739, tokenler: [26, 12, 0, 17, 24, 9, 4, 0, 13, 26]\n",
            "adım  392 / 1000 | kayıp 2.1051, tokenler: [26, 9, 20, 11, 8, 13, 0, 26]\n",
            "adım  393 / 1000 | kayıp 2.1702, tokenler: [26, 3, 0, 12, 4, 8, 17, 26]\n",
            "adım  394 / 1000 | kayıp 2.2743, tokenler: [26, 0, 12, 8, 17, 17, 0, 26]\n",
            "adım  395 / 1000 | kayıp 2.6582, tokenler: [26, 0, 8, 17, 4, 18, 26]\n",
            "adım  396 / 1000 | kayıp 1.8241, tokenler: [26, 7, 0, 17, 11, 8, 4, 4, 26]\n",
            "adım  397 / 1000 | kayıp 2.0875, tokenler: [26, 4, 12, 8, 11, 8, 0, 13, 14, 26]\n",
            "adım  398 / 1000 | kayıp 2.8767, tokenler: [26, 9, 14, 4, 24, 26]\n",
            "adım  399 / 1000 | kayıp 2.7444, tokenler: [26, 0, 17, 0, 5, 0, 19, 26]\n",
            "adım  400 / 1000 | kayıp 2.3428, tokenler: [26, 1, 17, 24, 11, 4, 17, 26]\n",
            "adım  401 / 1000 | kayıp 2.6035, tokenler: [26, 12, 14, 12, 14, 26]\n",
            "adım  402 / 1000 | kayıp 2.7292, tokenler: [26, 18, 8, 13, 4, 0, 3, 26]\n",
            "adım  403 / 1000 | kayıp 1.9550, tokenler: [26, 0, 12, 4, 17, 0, 26]\n",
            "adım  404 / 1000 | kayıp 2.2429, tokenler: [26, 1, 17, 0, 13, 18, 14, 13, 26]\n",
            "adım  405 / 1000 | kayıp 2.7119, tokenler: [26, 2, 0, 11, 20, 12, 26]\n",
            "adım  406 / 1000 | kayıp 2.5498, tokenler: [26, 13, 0, 9, 4, 4, 26]\n",
            "adım  407 / 1000 | kayıp 2.2875, tokenler: [26, 17, 24, 11, 8, 4, 0, 13, 13, 26]\n",
            "adım  408 / 1000 | kayıp 2.6208, tokenler: [26, 9, 0, 2, 10, 26]\n",
            "adım  409 / 1000 | kayıp 2.8385, tokenler: [26, 12, 0, 7, 12, 20, 3, 26]\n",
            "adım  410 / 1000 | kayıp 2.9415, tokenler: [26, 12, 0, 7, 17, 20, 10, 7, 26]\n",
            "adım  411 / 1000 | kayıp 2.2064, tokenler: [26, 19, 0, 24, 11, 24, 13, 26]\n",
            "adım  412 / 1000 | kayıp 2.1636, tokenler: [26, 4, 11, 8, 0, 18, 26]\n",
            "adım  413 / 1000 | kayıp 2.2308, tokenler: [26, 0, 11, 20, 11, 0, 26]\n",
            "adım  414 / 1000 | kayıp 2.8363, tokenler: [26, 13, 0, 5, 19, 20, 11, 0, 26]\n",
            "adım  415 / 1000 | kayıp 2.0398, tokenler: [26, 0, 7, 11, 0, 13, 0, 26]\n",
            "adım  416 / 1000 | kayıp 2.4377, tokenler: [26, 18, 7, 4, 10, 8, 13, 0, 7, 26]\n",
            "adım  417 / 1000 | kayıp 2.9288, tokenler: [26, 18, 4, 8, 9, 8, 26]\n",
            "adım  418 / 1000 | kayıp 1.9164, tokenler: [26, 0, 12, 14, 17, 4, 26]\n",
            "adım  419 / 1000 | kayıp 2.4943, tokenler: [26, 12, 8, 18, 0, 26]\n",
            "adım  420 / 1000 | kayıp 2.7135, tokenler: [26, 4, 3, 3, 8, 18, 14, 13, 26]\n",
            "adım  421 / 1000 | kayıp 2.5427, tokenler: [26, 5, 8, 18, 7, 4, 17, 26]\n",
            "adım  422 / 1000 | kayıp 2.4804, tokenler: [26, 12, 0, 24, 11, 4, 8, 6, 7, 26]\n",
            "adım  423 / 1000 | kayıp 1.9508, tokenler: [26, 7, 14, 11, 11, 8, 4, 26]\n",
            "adım  424 / 1000 | kayıp 2.5618, tokenler: [26, 17, 24, 25, 4, 13, 26]\n",
            "adım  425 / 1000 | kayıp 2.6098, tokenler: [26, 0, 13, 18, 4, 11, 12, 14, 26]\n",
            "adım  426 / 1000 | kayıp 2.8338, tokenler: [26, 9, 4, 17, 20, 18, 0, 11, 4, 12, 26]\n",
            "adım  427 / 1000 | kayıp 2.4871, tokenler: [26, 1, 20, 17, 7, 0, 13, 26]\n",
            "adım  428 / 1000 | kayıp 2.3602, tokenler: [26, 14, 1, 17, 24, 0, 13, 26]\n",
            "adım  429 / 1000 | kayıp 2.0358, tokenler: [26, 25, 0, 8, 11, 4, 13, 26]\n",
            "adım  430 / 1000 | kayıp 2.3998, tokenler: [26, 10, 0, 24, 2, 4, 4, 26]\n",
            "adım  431 / 1000 | kayıp 2.1980, tokenler: [26, 0, 21, 0, 13, 26]\n",
            "adım  432 / 1000 | kayıp 2.0428, tokenler: [26, 0, 11, 4, 13, 4, 26]\n",
            "adım  433 / 1000 | kayıp 2.3457, tokenler: [26, 11, 14, 9, 0, 8, 13, 26]\n",
            "adım  434 / 1000 | kayıp 2.3509, tokenler: [26, 10, 0, 24, 2, 4, 26]\n",
            "adım  435 / 1000 | kayıp 2.4827, tokenler: [26, 4, 12, 17, 24, 18, 26]\n",
            "adım  436 / 1000 | kayıp 3.3131, tokenler: [26, 12, 2, 2, 0, 11, 11, 26]\n",
            "adım  437 / 1000 | kayıp 2.7833, tokenler: [26, 12, 4, 8, 26]\n",
            "adım  438 / 1000 | kayıp 1.8821, tokenler: [26, 12, 0, 2, 11, 24, 13, 26]\n",
            "adım  439 / 1000 | kayıp 1.9444, tokenler: [26, 2, 4, 11, 8, 0, 26]\n",
            "adım  440 / 1000 | kayıp 2.1377, tokenler: [26, 2, 0, 17, 11, 24, 0, 13, 13, 26]\n",
            "adım  441 / 1000 | kayıp 2.6178, tokenler: [26, 19, 24, 22, 0, 13, 26]\n",
            "adım  442 / 1000 | kayıp 3.1046, tokenler: [26, 8, 11, 24, 26]\n",
            "adım  443 / 1000 | kayıp 3.2299, tokenler: [26, 11, 4, 23, 24, 26]\n",
            "adım  444 / 1000 | kayıp 2.3159, tokenler: [26, 11, 14, 2, 10, 11, 0, 13, 26]\n",
            "adım  445 / 1000 | kayıp 2.3500, tokenler: [26, 6, 4, 12, 0, 26]\n",
            "adım  446 / 1000 | kayıp 2.0550, tokenler: [26, 3, 0, 17, 4, 11, 26]\n",
            "adım  447 / 1000 | kayıp 2.0598, tokenler: [26, 9, 0, 17, 24, 8, 0, 26]\n",
            "adım  448 / 1000 | kayıp 3.0721, tokenler: [26, 1, 14, 7, 3, 8, 26]\n",
            "adım  449 / 1000 | kayıp 2.1660, tokenler: [26, 14, 11, 4, 13, 13, 0, 26]\n",
            "adım  450 / 1000 | kayıp 3.0903, tokenler: [26, 22, 4, 18, 19, 26]\n",
            "adım  451 / 1000 | kayıp 2.8054, tokenler: [26, 12, 0, 2, 2, 0, 1, 4, 4, 26]\n",
            "adım  452 / 1000 | kayıp 2.8289, tokenler: [26, 4, 12, 1, 4, 17, 11, 24, 13, 13, 26]\n",
            "adım  453 / 1000 | kayıp 2.5301, tokenler: [26, 15, 17, 4, 18, 19, 14, 13, 26]\n",
            "adım  454 / 1000 | kayıp 1.9576, tokenler: [26, 10, 0, 8, 7, 0, 13, 26]\n",
            "adım  455 / 1000 | kayıp 2.2373, tokenler: [26, 10, 4, 13, 24, 0, 26]\n",
            "adım  456 / 1000 | kayıp 2.7489, tokenler: [26, 8, 25, 4, 10, 8, 4, 11, 26]\n",
            "adım  457 / 1000 | kayıp 2.5852, tokenler: [26, 0, 3, 14, 12, 26]\n",
            "adım  458 / 1000 | kayıp 2.7530, tokenler: [26, 19, 24, 22, 0, 20, 13, 26]\n",
            "adım  459 / 1000 | kayıp 1.7114, tokenler: [26, 9, 4, 17, 8, 13, 26]\n",
            "adım  460 / 1000 | kayıp 2.3958, tokenler: [26, 10, 24, 17, 4, 4, 2, 4, 26]\n",
            "adım  461 / 1000 | kayıp 1.8254, tokenler: [26, 12, 0, 4, 11, 24, 26]\n",
            "adım  462 / 1000 | kayıp 2.7834, tokenler: [26, 7, 0, 13, 25, 14, 26]\n",
            "adım  463 / 1000 | kayıp 2.0794, tokenler: [26, 0, 12, 14, 13, 8, 26]\n",
            "adım  464 / 1000 | kayıp 2.2029, tokenler: [26, 9, 4, 17, 8, 2, 14, 26]\n",
            "adım  465 / 1000 | kayıp 2.7421, tokenler: [26, 4, 21, 4, 17, 18, 26]\n",
            "adım  466 / 1000 | kayıp 2.2871, tokenler: [26, 10, 24, 11, 0, 7, 26]\n",
            "adım  467 / 1000 | kayıp 2.2345, tokenler: [26, 18, 14, 13, 13, 8, 4, 26]\n",
            "adım  468 / 1000 | kayıp 2.2340, tokenler: [26, 5, 0, 14, 11, 0, 13, 26]\n",
            "adım  469 / 1000 | kayıp 2.3651, tokenler: [26, 13, 0, 19, 20, 17, 4, 26]\n",
            "adım  470 / 1000 | kayıp 3.8820, tokenler: [26, 8, 21, 21, 24, 26]\n",
            "adım  471 / 1000 | kayıp 2.5910, tokenler: [26, 12, 24, 17, 8, 10, 0, 11, 26]\n",
            "adım  472 / 1000 | kayıp 2.7750, tokenler: [26, 0, 7, 25, 0, 1, 26]\n",
            "adım  473 / 1000 | kayıp 2.6283, tokenler: [26, 13, 0, 21, 0, 4, 7, 26]\n",
            "adım  474 / 1000 | kayıp 2.3571, tokenler: [26, 12, 4, 25, 8, 0, 7, 26]\n",
            "adım  475 / 1000 | kayıp 2.4745, tokenler: [26, 10, 4, 24, 14, 13, 13, 8, 26]\n",
            "adım  476 / 1000 | kayıp 2.1805, tokenler: [26, 24, 0, 13, 13, 0, 8, 26]\n",
            "adım  477 / 1000 | kayıp 2.9413, tokenler: [26, 8, 25, 25, 0, 1, 4, 11, 11, 4, 26]\n",
            "adım  478 / 1000 | kayıp 2.2745, tokenler: [26, 9, 0, 25, 11, 4, 13, 4, 26]\n",
            "adım  479 / 1000 | kayıp 2.0886, tokenler: [26, 0, 18, 7, 0, 17, 8, 26]\n",
            "adım  480 / 1000 | kayıp 2.0120, tokenler: [26, 4, 12, 8, 11, 4, 13, 4, 26]\n",
            "adım  481 / 1000 | kayıp 2.9853, tokenler: [26, 14, 11, 20, 22, 0, 18, 4, 12, 8, 11, 14, 17, 4, 26]\n",
            "adım  482 / 1000 | kayıp 2.7189, tokenler: [26, 4, 18, 19, 4, 15, 7, 0, 13, 24, 26]\n",
            "adım  483 / 1000 | kayıp 2.3466, tokenler: [26, 11, 4, 8, 3, 24, 26]\n",
            "adım  484 / 1000 | kayıp 2.8693, tokenler: [26, 10, 4, 13, 3, 17, 8, 23, 26]\n",
            "adım  485 / 1000 | kayıp 2.4805, tokenler: [26, 3, 4, 25, 8, 17, 0, 24, 26]\n",
            "adım  486 / 1000 | kayıp 2.1715, tokenler: [26, 11, 4, 4, 0, 13, 0, 26]\n",
            "adım  487 / 1000 | kayıp 2.7516, tokenler: [26, 0, 10, 18, 7, 8, 19, 7, 0, 26]\n",
            "adım  488 / 1000 | kayıp 2.6655, tokenler: [26, 13, 14, 4, 12, 24, 26]\n",
            "adım  489 / 1000 | kayıp 2.3425, tokenler: [26, 25, 0, 0, 21, 0, 13, 26]\n",
            "adım  490 / 1000 | kayıp 2.2978, tokenler: [26, 1, 4, 11, 11, 4, 12, 24, 26]\n",
            "adım  491 / 1000 | kayıp 2.2573, tokenler: [26, 13, 14, 17, 12, 0, 13, 26]\n",
            "adım  492 / 1000 | kayıp 2.3424, tokenler: [26, 15, 0, 8, 3, 24, 13, 26]\n",
            "adım  493 / 1000 | kayıp 2.4360, tokenler: [26, 19, 0, 8, 18, 11, 4, 24, 26]\n",
            "adım  494 / 1000 | kayıp 2.1313, tokenler: [26, 3, 0, 11, 14, 13, 26]\n",
            "adım  495 / 1000 | kayıp 2.4870, tokenler: [26, 24, 14, 0, 13, 0, 26]\n",
            "adım  496 / 1000 | kayıp 2.5856, tokenler: [26, 23, 14, 11, 0, 13, 8, 26]\n",
            "adım  497 / 1000 | kayıp 2.9952, tokenler: [26, 19, 17, 0, 8, 11, 26]\n",
            "adım  498 / 1000 | kayıp 2.4689, tokenler: [26, 0, 3, 8, 19, 8, 26]\n",
            "adım  499 / 1000 | kayıp 2.2353, tokenler: [26, 25, 0, 24, 3, 0, 26]\n",
            "adım  500 / 1000 | kayıp 2.0645, tokenler: [26, 18, 14, 17, 0, 8, 0, 26]\n",
            "adım  501 / 1000 | kayıp 2.4261, tokenler: [26, 19, 24, 18, 14, 13, 26]\n",
            "adım  502 / 1000 | kayıp 2.1254, tokenler: [26, 0, 13, 0, 24, 11, 0, 7, 26]\n",
            "adım  503 / 1000 | kayıp 2.7352, tokenler: [26, 12, 8, 13, 4, 17, 21, 0, 26]\n",
            "adım  504 / 1000 | kayıp 2.0662, tokenler: [26, 1, 17, 4, 11, 24, 13, 13, 26]\n",
            "adım  505 / 1000 | kayıp 2.3327, tokenler: [26, 4, 18, 7, 0, 26]\n",
            "adım  506 / 1000 | kayıp 2.4337, tokenler: [26, 18, 20, 18, 0, 13, 13, 0, 7, 26]\n",
            "adım  507 / 1000 | kayıp 2.4315, tokenler: [26, 14, 2, 4, 0, 13, 4, 26]\n",
            "adım  508 / 1000 | kayıp 2.6284, tokenler: [26, 21, 8, 7, 0, 0, 13, 26]\n",
            "adım  509 / 1000 | kayıp 2.8761, tokenler: [26, 7, 20, 4, 24, 26]\n",
            "adım  510 / 1000 | kayıp 2.7854, tokenler: [26, 11, 14, 21, 4, 26]\n",
            "adım  511 / 1000 | kayıp 2.2922, tokenler: [26, 18, 7, 24, 4, 13, 13, 4, 26]\n",
            "adım  512 / 1000 | kayıp 2.2573, tokenler: [26, 2, 11, 0, 8, 17, 4, 26]\n",
            "adım  513 / 1000 | kayıp 2.4115, tokenler: [26, 10, 0, 24, 19, 11, 24, 13, 13, 26]\n",
            "adım  514 / 1000 | kayıp 2.8810, tokenler: [26, 2, 8, 15, 17, 8, 0, 13, 14, 26]\n",
            "adım  515 / 1000 | kayıp 2.6771, tokenler: [26, 17, 20, 3, 17, 0, 13, 18, 7, 26]\n",
            "adım  516 / 1000 | kayıp 3.0052, tokenler: [26, 0, 10, 20, 11, 26]\n",
            "adım  517 / 1000 | kayıp 2.1366, tokenler: [26, 0, 13, 0, 7, 11, 8, 0, 26]\n",
            "adım  518 / 1000 | kayıp 2.2575, tokenler: [26, 0, 0, 18, 7, 13, 0, 26]\n",
            "adım  519 / 1000 | kayıp 2.0644, tokenler: [26, 1, 17, 14, 3, 0, 13, 26]\n",
            "adım  520 / 1000 | kayıp 2.7970, tokenler: [26, 24, 14, 20, 13, 8, 18, 26]\n",
            "adım  521 / 1000 | kayıp 1.6685, tokenler: [26, 0, 13, 0, 11, 24, 13, 26]\n",
            "adım  522 / 1000 | kayıp 1.8816, tokenler: [26, 0, 13, 0, 7, 11, 0, 26]\n",
            "adım  523 / 1000 | kayıp 2.1512, tokenler: [26, 12, 8, 17, 17, 4, 13, 26]\n",
            "adım  524 / 1000 | kayıp 2.4364, tokenler: [26, 0, 0, 17, 25, 0, 26]\n",
            "adım  525 / 1000 | kayıp 2.3002, tokenler: [26, 3, 4, 13, 13, 8, 26]\n",
            "adım  526 / 1000 | kayıp 2.6904, tokenler: [26, 10, 0, 1, 4, 4, 17, 26]\n",
            "adım  527 / 1000 | kayıp 1.7979, tokenler: [26, 2, 14, 13, 0, 13, 26]\n",
            "adım  528 / 1000 | kayıp 2.5294, tokenler: [26, 21, 0, 4, 3, 0, 26]\n",
            "adım  529 / 1000 | kayıp 2.3032, tokenler: [26, 12, 0, 17, 24, 9, 0, 13, 4, 26]\n",
            "adım  530 / 1000 | kayıp 1.6063, tokenler: [26, 12, 4, 11, 0, 13, 0, 26]\n",
            "adım  531 / 1000 | kayıp 2.5921, tokenler: [26, 9, 4, 25, 8, 4, 11, 26]\n",
            "adım  532 / 1000 | kayıp 2.3464, tokenler: [26, 15, 7, 0, 17, 17, 0, 7, 26]\n",
            "adım  533 / 1000 | kayıp 3.5815, tokenler: [26, 21, 4, 3, 7, 26]\n",
            "adım  534 / 1000 | kayıp 2.2109, tokenler: [26, 11, 4, 14, 11, 0, 26]\n",
            "adım  535 / 1000 | kayıp 3.1679, tokenler: [26, 19, 7, 4, 14, 26]\n",
            "adım  536 / 1000 | kayıp 1.8492, tokenler: [26, 25, 0, 17, 14, 13, 26]\n",
            "adım  537 / 1000 | kayıp 1.5782, tokenler: [26, 10, 0, 11, 4, 13, 0, 26]\n",
            "adım  538 / 1000 | kayıp 2.4474, tokenler: [26, 19, 0, 12, 8, 24, 0, 26]\n",
            "adım  539 / 1000 | kayıp 1.8286, tokenler: [26, 10, 0, 24, 11, 8, 13, 26]\n",
            "adım  540 / 1000 | kayıp 2.7201, tokenler: [26, 20, 17, 8, 4, 26]\n",
            "adım  541 / 1000 | kayıp 2.7791, tokenler: [26, 12, 0, 10, 24, 13, 25, 4, 4, 26]\n",
            "adım  542 / 1000 | kayıp 1.9045, tokenler: [26, 2, 0, 17, 11, 8, 13, 26]\n",
            "adım  543 / 1000 | kayıp 3.2878, tokenler: [26, 21, 0, 8, 1, 7, 0, 21, 26]\n",
            "adım  544 / 1000 | kayıp 2.3980, tokenler: [26, 5, 4, 24, 25, 0, 26]\n",
            "adım  545 / 1000 | kayıp 2.8266, tokenler: [26, 4, 11, 11, 14, 22, 24, 13, 13, 26]\n",
            "adım  546 / 1000 | kayıp 2.4227, tokenler: [26, 0, 13, 21, 8, 19, 0, 26]\n",
            "adım  547 / 1000 | kayıp 2.1204, tokenler: [26, 21, 0, 18, 7, 26]\n",
            "adım  548 / 1000 | kayıp 2.8575, tokenler: [26, 7, 8, 5, 25, 0, 26]\n",
            "adım  549 / 1000 | kayıp 2.0631, tokenler: [26, 7, 0, 13, 13, 14, 13, 26]\n",
            "adım  550 / 1000 | kayıp 1.9310, tokenler: [26, 12, 0, 2, 11, 8, 13, 26]\n",
            "adım  551 / 1000 | kayıp 2.6828, tokenler: [26, 24, 0, 25, 8, 3, 26]\n",
            "adım  552 / 1000 | kayıp 2.4919, tokenler: [26, 8, 24, 0, 13, 13, 8, 26]\n",
            "adım  553 / 1000 | kayıp 2.5412, tokenler: [26, 17, 14, 18, 0, 11, 4, 0, 7, 26]\n",
            "adım  554 / 1000 | kayıp 2.7195, tokenler: [26, 11, 8, 1, 1, 8, 4, 26]\n",
            "adım  555 / 1000 | kayıp 2.9065, tokenler: [26, 10, 24, 13, 25, 11, 4, 8, 6, 7, 26]\n",
            "adım  556 / 1000 | kayıp 2.3740, tokenler: [26, 0, 25, 17, 0, 7, 26]\n",
            "adım  557 / 1000 | kayıp 2.5296, tokenler: [26, 10, 4, 13, 25, 14, 26]\n",
            "adım  558 / 1000 | kayıp 1.9853, tokenler: [26, 19, 0, 18, 7, 8, 26]\n",
            "adım  559 / 1000 | kayıp 2.5890, tokenler: [26, 10, 4, 13, 25, 8, 13, 6, 19, 14, 13, 26]\n",
            "adım  560 / 1000 | kayıp 3.1969, tokenler: [26, 17, 4, 3, 26]\n",
            "adım  561 / 1000 | kayıp 1.8082, tokenler: [26, 10, 0, 17, 8, 18, 26]\n",
            "adım  562 / 1000 | kayıp 2.9966, tokenler: [26, 1, 0, 17, 10, 14, 19, 26]\n",
            "adım  563 / 1000 | kayıp 2.3597, tokenler: [26, 4, 8, 3, 4, 13, 26]\n",
            "adım  564 / 1000 | kayıp 2.0989, tokenler: [26, 9, 0, 13, 8, 24, 11, 0, 7, 26]\n",
            "adım  565 / 1000 | kayıp 3.0321, tokenler: [26, 15, 8, 13, 2, 7, 14, 18, 26]\n",
            "adım  566 / 1000 | kayıp 1.7108, tokenler: [26, 21, 8, 18, 7, 0, 13, 26]\n",
            "adım  567 / 1000 | kayıp 2.5155, tokenler: [26, 8, 24, 14, 13, 0, 26]\n",
            "adım  568 / 1000 | kayıp 2.7469, tokenler: [26, 1, 14, 1, 1, 24, 26]\n",
            "adım  569 / 1000 | kayıp 2.5179, tokenler: [26, 3, 8, 4, 12, 26]\n",
            "adım  570 / 1000 | kayıp 2.8211, tokenler: [26, 25, 7, 0, 13, 3, 4, 17, 26]\n",
            "adım  571 / 1000 | kayıp 1.9473, tokenler: [26, 10, 0, 24, 11, 24, 13, 13, 26]\n",
            "adım  572 / 1000 | kayıp 3.1226, tokenler: [26, 25, 8, 6, 12, 20, 13, 3, 26]\n",
            "adım  573 / 1000 | kayıp 3.0085, tokenler: [26, 0, 10, 1, 0, 17, 26]\n",
            "adım  574 / 1000 | kayıp 2.4998, tokenler: [26, 9, 0, 2, 14, 1, 8, 26]\n",
            "adım  575 / 1000 | kayıp 2.2788, tokenler: [26, 12, 0, 25, 25, 24, 26]\n",
            "adım  576 / 1000 | kayıp 2.0708, tokenler: [26, 25, 4, 11, 8, 4, 26]\n",
            "adım  577 / 1000 | kayıp 1.9976, tokenler: [26, 3, 4, 11, 0, 13, 24, 26]\n",
            "adım  578 / 1000 | kayıp 2.6646, tokenler: [26, 1, 4, 17, 13, 0, 3, 8, 13, 4, 26]\n",
            "adım  579 / 1000 | kayıp 2.0727, tokenler: [26, 25, 0, 11, 0, 26]\n",
            "adım  580 / 1000 | kayıp 2.4337, tokenler: [26, 11, 24, 13, 0, 26]\n",
            "adım  581 / 1000 | kayıp 2.3260, tokenler: [26, 2, 0, 12, 3, 24, 13, 26]\n",
            "adım  582 / 1000 | kayıp 2.4394, tokenler: [26, 4, 12, 4, 17, 18, 4, 13, 26]\n",
            "adım  583 / 1000 | kayıp 2.7697, tokenler: [26, 4, 11, 24, 18, 0, 1, 4, 19, 7, 26]\n",
            "adım  584 / 1000 | kayıp 2.9226, tokenler: [26, 13, 8, 0, 14, 12, 8, 26]\n",
            "adım  585 / 1000 | kayıp 2.2863, tokenler: [26, 9, 0, 8, 2, 4, 17, 4, 26]\n",
            "adım  586 / 1000 | kayıp 2.4610, tokenler: [26, 8, 24, 11, 0, 13, 3, 26]\n",
            "adım  587 / 1000 | kayıp 2.1763, tokenler: [26, 7, 0, 13, 8, 24, 0, 26]\n",
            "adım  588 / 1000 | kayıp 2.0816, tokenler: [26, 2, 14, 17, 17, 8, 13, 0, 26]\n",
            "adım  589 / 1000 | kayıp 1.8776, tokenler: [26, 10, 0, 24, 3, 4, 13, 26]\n",
            "adım  590 / 1000 | kayıp 2.4569, tokenler: [26, 9, 0, 24, 11, 0, 17, 14, 18, 4, 26]\n",
            "adım  591 / 1000 | kayıp 2.4763, tokenler: [26, 10, 4, 13, 13, 4, 3, 8, 8, 26]\n",
            "adım  592 / 1000 | kayıp 2.1966, tokenler: [26, 9, 14, 21, 8, 0, 13, 13, 4, 26]\n",
            "adım  593 / 1000 | kayıp 2.3452, tokenler: [26, 12, 0, 13, 0, 18, 21, 8, 13, 8, 26]\n",
            "adım  594 / 1000 | kayıp 2.8074, tokenler: [26, 21, 8, 17, 6, 8, 11, 8, 14, 26]\n",
            "adım  595 / 1000 | kayıp 2.4341, tokenler: [26, 17, 7, 24, 0, 13, 13, 26]\n",
            "adım  596 / 1000 | kayıp 2.1553, tokenler: [26, 10, 4, 11, 3, 14, 13, 26]\n",
            "adım  597 / 1000 | kayıp 2.6157, tokenler: [26, 18, 11, 0, 3, 4, 26]\n",
            "adım  598 / 1000 | kayıp 2.1024, tokenler: [26, 0, 21, 8, 24, 0, 13, 0, 26]\n",
            "adım  599 / 1000 | kayıp 2.3983, tokenler: [26, 10, 4, 13, 19, 14, 26]\n",
            "adım  600 / 1000 | kayıp 2.4851, tokenler: [26, 1, 17, 0, 24, 21, 4, 13, 26]\n",
            "adım  601 / 1000 | kayıp 2.1083, tokenler: [26, 0, 11, 4, 4, 13, 26]\n",
            "adım  602 / 1000 | kayıp 2.4919, tokenler: [26, 2, 7, 17, 8, 18, 19, 8, 14, 13, 26]\n",
            "adım  603 / 1000 | kayıp 2.7452, tokenler: [26, 4, 11, 6, 8, 13, 26]\n",
            "adım  604 / 1000 | kayıp 2.0589, tokenler: [26, 0, 13, 13, 0, 11, 8, 0, 7, 26]\n",
            "adım  605 / 1000 | kayıp 2.7860, tokenler: [26, 9, 20, 11, 8, 4, 19, 26]\n",
            "adım  606 / 1000 | kayıp 1.7675, tokenler: [26, 11, 8, 11, 8, 0, 13, 13, 26]\n",
            "adım  607 / 1000 | kayıp 2.7445, tokenler: [26, 8, 13, 3, 8, 26]\n",
            "adım  608 / 1000 | kayıp 2.2072, tokenler: [26, 9, 14, 17, 3, 8, 26]\n",
            "adım  609 / 1000 | kayıp 2.3056, tokenler: [26, 0, 8, 21, 4, 13, 26]\n",
            "adım  610 / 1000 | kayıp 2.4470, tokenler: [26, 10, 0, 22, 0, 8, 26]\n",
            "adım  611 / 1000 | kayıp 2.6861, tokenler: [26, 18, 0, 7, 12, 8, 17, 26]\n",
            "adım  612 / 1000 | kayıp 2.5383, tokenler: [26, 0, 1, 4, 11, 26]\n",
            "adım  613 / 1000 | kayıp 1.9791, tokenler: [26, 2, 7, 24, 0, 13, 13, 26]\n",
            "adım  614 / 1000 | kayıp 2.1122, tokenler: [26, 3, 4, 2, 11, 24, 13, 13, 26]\n",
            "adım  615 / 1000 | kayıp 2.4416, tokenler: [26, 13, 0, 7, 25, 8, 17, 26]\n",
            "adım  616 / 1000 | kayıp 2.9865, tokenler: [26, 22, 8, 11, 1, 4, 17, 26]\n",
            "adım  617 / 1000 | kayıp 2.7236, tokenler: [26, 1, 0, 4, 17, 26]\n",
            "adım  618 / 1000 | kayıp 2.3293, tokenler: [26, 0, 1, 8, 18, 7, 0, 8, 26]\n",
            "adım  619 / 1000 | kayıp 2.4571, tokenler: [26, 2, 0, 17, 11, 14, 19, 0, 26]\n",
            "adım  620 / 1000 | kayıp 2.6560, tokenler: [26, 5, 14, 17, 19, 20, 13, 4, 26]\n",
            "adım  621 / 1000 | kayıp 1.8379, tokenler: [26, 11, 4, 13, 13, 24, 13, 26]\n",
            "adım  622 / 1000 | kayıp 2.2556, tokenler: [26, 2, 0, 11, 0, 24, 0, 7, 26]\n",
            "adım  623 / 1000 | kayıp 2.0642, tokenler: [26, 2, 0, 17, 8, 18, 0, 26]\n",
            "adım  624 / 1000 | kayıp 2.4819, tokenler: [26, 0, 19, 25, 8, 17, 8, 26]\n",
            "adım  625 / 1000 | kayıp 1.7747, tokenler: [26, 0, 17, 8, 0, 13, 13, 0, 26]\n",
            "adım  626 / 1000 | kayıp 2.5039, tokenler: [26, 18, 0, 21, 4, 0, 7, 26]\n",
            "adım  627 / 1000 | kayıp 2.0995, tokenler: [26, 4, 11, 8, 25, 4, 26]\n",
            "adım  628 / 1000 | kayıp 2.2031, tokenler: [26, 11, 0, 21, 4, 17, 0, 26]\n",
            "adım  629 / 1000 | kayıp 2.6526, tokenler: [26, 0, 11, 19, 7, 4, 0, 26]\n",
            "adım  630 / 1000 | kayıp 2.6197, tokenler: [26, 19, 7, 4, 14, 17, 24, 26]\n",
            "adım  631 / 1000 | kayıp 3.0481, tokenler: [26, 19, 0, 1, 0, 18, 18, 20, 12, 26]\n",
            "adım  632 / 1000 | kayıp 1.7443, tokenler: [26, 0, 17, 4, 13, 0, 26]\n",
            "adım  633 / 1000 | kayıp 2.6695, tokenler: [26, 12, 0, 6, 3, 0, 11, 4, 13, 4, 26]\n",
            "adım  634 / 1000 | kayıp 2.5338, tokenler: [26, 11, 24, 14, 13, 4, 11, 26]\n",
            "adım  635 / 1000 | kayıp 3.2450, tokenler: [26, 19, 17, 24, 6, 21, 4, 26]\n",
            "adım  636 / 1000 | kayıp 2.8575, tokenler: [26, 19, 24, 10, 4, 26]\n",
            "adım  637 / 1000 | kayıp 2.5257, tokenler: [26, 12, 14, 14, 17, 4, 0, 26]\n",
            "adım  638 / 1000 | kayıp 2.2855, tokenler: [26, 0, 11, 4, 23, 8, 0, 7, 26]\n",
            "adım  639 / 1000 | kayıp 2.6202, tokenler: [26, 13, 4, 10, 14, 3, 0, 26]\n",
            "adım  640 / 1000 | kayıp 1.9703, tokenler: [26, 10, 0, 11, 11, 8, 26]\n",
            "adım  641 / 1000 | kayıp 2.2895, tokenler: [26, 25, 0, 13, 3, 17, 0, 26]\n",
            "adım  642 / 1000 | kayıp 1.9095, tokenler: [26, 25, 0, 24, 13, 0, 26]\n",
            "adım  643 / 1000 | kayıp 2.5737, tokenler: [26, 3, 0, 17, 8, 14, 20, 18, 26]\n",
            "adım  644 / 1000 | kayıp 2.2433, tokenler: [26, 3, 0, 13, 3, 17, 4, 26]\n",
            "adım  645 / 1000 | kayıp 2.3000, tokenler: [26, 17, 4, 13, 11, 24, 26]\n",
            "adım  646 / 1000 | kayıp 2.0239, tokenler: [26, 13, 0, 24, 0, 7, 26]\n",
            "adım  647 / 1000 | kayıp 2.3138, tokenler: [26, 0, 4, 19, 7, 0, 13, 26]\n",
            "adım  648 / 1000 | kayıp 3.1185, tokenler: [26, 1, 17, 14, 14, 10, 11, 24, 13, 4, 26]\n",
            "adım  649 / 1000 | kayıp 2.1672, tokenler: [26, 11, 8, 11, 11, 8, 4, 13, 13, 4, 26]\n",
            "adım  650 / 1000 | kayıp 2.6138, tokenler: [26, 12, 8, 2, 7, 4, 0, 11, 0, 26]\n",
            "adım  651 / 1000 | kayıp 2.4730, tokenler: [26, 2, 8, 13, 19, 7, 24, 0, 26]\n",
            "adım  652 / 1000 | kayıp 2.4868, tokenler: [26, 17, 14, 18, 4, 0, 11, 4, 4, 26]\n",
            "adım  653 / 1000 | kayıp 2.3750, tokenler: [26, 0, 13, 20, 7, 4, 0, 26]\n",
            "adım  654 / 1000 | kayıp 2.1639, tokenler: [26, 11, 4, 14, 17, 0, 26]\n",
            "adım  655 / 1000 | kayıp 3.0494, tokenler: [26, 21, 0, 20, 6, 7, 13, 26]\n",
            "adım  656 / 1000 | kayıp 2.4772, tokenler: [26, 1, 17, 0, 13, 18, 19, 14, 13, 26]\n",
            "adım  657 / 1000 | kayıp 2.1428, tokenler: [26, 18, 7, 24, 13, 4, 26]\n",
            "adım  658 / 1000 | kayıp 2.9535, tokenler: [26, 4, 14, 8, 13, 26]\n",
            "adım  659 / 1000 | kayıp 2.5928, tokenler: [26, 14, 3, 4, 11, 11, 26]\n",
            "adım  660 / 1000 | kayıp 2.4115, tokenler: [26, 4, 11, 8, 18, 0, 13, 3, 17, 0, 26]\n",
            "adım  661 / 1000 | kayıp 2.1242, tokenler: [26, 17, 4, 13, 13, 4, 17, 26]\n",
            "adım  662 / 1000 | kayıp 2.9471, tokenler: [26, 10, 14, 20, 17, 19, 13, 8, 26]\n",
            "adım  663 / 1000 | kayıp 2.6772, tokenler: [26, 19, 0, 21, 0, 17, 8, 14, 20, 18, 26]\n",
            "adım  664 / 1000 | kayıp 2.6958, tokenler: [26, 15, 0, 0, 17, 19, 7, 26]\n",
            "adım  665 / 1000 | kayıp 2.4493, tokenler: [26, 0, 0, 1, 8, 17, 26]\n",
            "adım  666 / 1000 | kayıp 2.0646, tokenler: [26, 0, 11, 4, 23, 8, 0, 13, 13, 0, 26]\n",
            "adım  667 / 1000 | kayıp 2.9612, tokenler: [26, 2, 17, 20, 25, 8, 19, 14, 26]\n",
            "adım  668 / 1000 | kayıp 2.8441, tokenler: [26, 12, 7, 4, 17, 26]\n",
            "adım  669 / 1000 | kayıp 2.1719, tokenler: [26, 0, 25, 24, 11, 0, 7, 26]\n",
            "adım  670 / 1000 | kayıp 2.1952, tokenler: [26, 10, 0, 8, 18, 11, 24, 13, 13, 26]\n",
            "adım  671 / 1000 | kayıp 2.1350, tokenler: [26, 10, 8, 17, 19, 0, 13, 26]\n",
            "adım  672 / 1000 | kayıp 1.8856, tokenler: [26, 12, 0, 17, 8, 4, 11, 26]\n",
            "adım  673 / 1000 | kayıp 2.5404, tokenler: [26, 7, 0, 13, 21, 8, 10, 0, 26]\n",
            "adım  674 / 1000 | kayıp 2.4887, tokenler: [26, 15, 0, 17, 24, 18, 26]\n",
            "adım  675 / 1000 | kayıp 2.7627, tokenler: [26, 19, 14, 17, 26]\n",
            "adım  676 / 1000 | kayıp 2.1296, tokenler: [26, 13, 8, 11, 0, 13, 26]\n",
            "adım  677 / 1000 | kayıp 2.0944, tokenler: [26, 12, 0, 17, 8, 9, 0, 26]\n",
            "adım  678 / 1000 | kayıp 2.2733, tokenler: [26, 12, 0, 11, 4, 4, 7, 0, 26]\n",
            "adım  679 / 1000 | kayıp 2.3283, tokenler: [26, 2, 7, 0, 17, 11, 4, 24, 26]\n",
            "adım  680 / 1000 | kayıp 2.2191, tokenler: [26, 3, 0, 11, 14, 13, 19, 4, 26]\n",
            "adım  681 / 1000 | kayıp 2.9738, tokenler: [26, 1, 11, 0, 24, 10, 11, 4, 8, 6, 7, 26]\n",
            "adım  682 / 1000 | kayıp 2.0353, tokenler: [26, 18, 7, 24, 0, 13, 26]\n",
            "adım  683 / 1000 | kayıp 1.5894, tokenler: [26, 10, 0, 17, 11, 8, 13, 0, 26]\n",
            "adım  684 / 1000 | kayıp 2.3880, tokenler: [26, 12, 8, 17, 0, 9, 0, 13, 4, 26]\n",
            "adım  685 / 1000 | kayıp 1.8963, tokenler: [26, 17, 0, 4, 11, 4, 13, 4, 26]\n",
            "adım  686 / 1000 | kayıp 2.4264, tokenler: [26, 0, 1, 8, 9, 0, 7, 26]\n",
            "adım  687 / 1000 | kayıp 1.8933, tokenler: [26, 3, 24, 11, 0, 13, 13, 26]\n",
            "adım  688 / 1000 | kayıp 2.3557, tokenler: [26, 2, 7, 0, 17, 1, 4, 11, 26]\n",
            "adım  689 / 1000 | kayıp 2.3917, tokenler: [26, 18, 7, 0, 12, 18, 7, 14, 13, 26]\n",
            "adım  690 / 1000 | kayıp 2.3202, tokenler: [26, 2, 7, 0, 17, 11, 4, 19, 19, 4, 26]\n",
            "adım  691 / 1000 | kayıp 2.0521, tokenler: [26, 9, 4, 17, 12, 0, 13, 4, 26]\n",
            "adım  692 / 1000 | kayıp 1.8742, tokenler: [26, 10, 0, 17, 18, 14, 13, 26]\n",
            "adım  693 / 1000 | kayıp 2.1245, tokenler: [26, 18, 0, 1, 8, 17, 8, 13, 26]\n",
            "adım  694 / 1000 | kayıp 3.7008, tokenler: [26, 0, 1, 3, 20, 11, 22, 0, 7, 0, 1, 26]\n",
            "adım  695 / 1000 | kayıp 2.7782, tokenler: [26, 18, 0, 11, 18, 0, 1, 8, 11, 26]\n",
            "adım  696 / 1000 | kayıp 2.4651, tokenler: [26, 3, 0, 10, 18, 19, 14, 13, 26]\n",
            "adım  697 / 1000 | kayıp 3.2385, tokenler: [26, 17, 14, 14, 10, 26]\n",
            "adım  698 / 1000 | kayıp 2.6590, tokenler: [26, 17, 8, 19, 0, 26]\n",
            "adım  699 / 1000 | kayıp 2.6012, tokenler: [26, 8, 18, 0, 20, 17, 0, 26]\n",
            "adım  700 / 1000 | kayıp 2.3357, tokenler: [26, 13, 4, 4, 11, 24, 26]\n",
            "adım  701 / 1000 | kayıp 2.1908, tokenler: [26, 3, 7, 4, 4, 17, 0, 13, 26]\n",
            "adım  702 / 1000 | kayıp 3.2303, tokenler: [26, 0, 9, 13, 0, 26]\n",
            "adım  703 / 1000 | kayıp 2.5401, tokenler: [26, 0, 13, 13, 20, 4, 11, 26]\n",
            "adım  704 / 1000 | kayıp 2.0141, tokenler: [26, 7, 0, 8, 11, 0, 26]\n",
            "adım  705 / 1000 | kayıp 2.2466, tokenler: [26, 19, 4, 21, 8, 14, 13, 26]\n",
            "adım  706 / 1000 | kayıp 2.2559, tokenler: [26, 13, 14, 11, 11, 8, 4, 26]\n",
            "adım  707 / 1000 | kayıp 2.6487, tokenler: [26, 6, 8, 0, 13, 26]\n",
            "adım  708 / 1000 | kayıp 2.7316, tokenler: [26, 1, 17, 14, 14, 10, 4, 11, 24, 13, 13, 26]\n",
            "adım  709 / 1000 | kayıp 2.0201, tokenler: [26, 10, 0, 24, 11, 14, 17, 26]\n",
            "adım  710 / 1000 | kayıp 2.2398, tokenler: [26, 9, 8, 17, 0, 7, 26]\n",
            "adım  711 / 1000 | kayıp 2.8304, tokenler: [26, 19, 4, 12, 8, 11, 14, 11, 20, 22, 0, 26]\n",
            "adım  712 / 1000 | kayıp 2.4438, tokenler: [26, 0, 11, 4, 10, 7, 24, 0, 26]\n",
            "adım  713 / 1000 | kayıp 2.4199, tokenler: [26, 4, 3, 8, 11, 26]\n",
            "adım  714 / 1000 | kayıp 2.5542, tokenler: [26, 4, 11, 11, 8, 14, 19, 26]\n",
            "adım  715 / 1000 | kayıp 1.9634, tokenler: [26, 12, 8, 11, 8, 0, 7, 26]\n",
            "adım  716 / 1000 | kayıp 1.8876, tokenler: [26, 3, 4, 24, 11, 0, 13, 26]\n",
            "adım  717 / 1000 | kayıp 2.1661, tokenler: [26, 10, 8, 13, 18, 19, 14, 13, 26]\n",
            "adım  718 / 1000 | kayıp 2.0400, tokenler: [26, 18, 7, 8, 24, 0, 26]\n",
            "adım  719 / 1000 | kayıp 2.6692, tokenler: [26, 12, 20, 13, 0, 18, 0, 17, 26]\n",
            "adım  720 / 1000 | kayıp 2.1266, tokenler: [26, 7, 0, 24, 25, 4, 11, 26]\n",
            "adım  721 / 1000 | kayıp 2.1274, tokenler: [26, 10, 0, 2, 7, 4, 26]\n",
            "adım  722 / 1000 | kayıp 2.6668, tokenler: [26, 9, 8, 13, 26]\n",
            "adım  723 / 1000 | kayıp 2.1620, tokenler: [26, 0, 13, 13, 4, 26]\n",
            "adım  724 / 1000 | kayıp 2.7405, tokenler: [26, 18, 20, 7, 0, 18, 26]\n",
            "adım  725 / 1000 | kayıp 2.8878, tokenler: [26, 18, 2, 0, 17, 11, 4, 19, 19, 26]\n",
            "adım  726 / 1000 | kayıp 2.6247, tokenler: [26, 10, 17, 8, 18, 11, 4, 8, 6, 7, 26]\n",
            "adım  727 / 1000 | kayıp 1.7349, tokenler: [26, 10, 0, 24, 11, 4, 13, 0, 26]\n",
            "adım  728 / 1000 | kayıp 2.1850, tokenler: [26, 12, 14, 13, 0, 4, 26]\n",
            "adım  729 / 1000 | kayıp 2.2787, tokenler: [26, 10, 4, 24, 0, 8, 17, 0, 26]\n",
            "adım  730 / 1000 | kayıp 2.2568, tokenler: [26, 4, 13, 14, 18, 7, 26]\n",
            "adım  731 / 1000 | kayıp 2.5408, tokenler: [26, 25, 24, 17, 4, 4, 26]\n",
            "adım  732 / 1000 | kayıp 2.5605, tokenler: [26, 18, 10, 24, 11, 14, 17, 26]\n",
            "adım  733 / 1000 | kayıp 2.5687, tokenler: [26, 2, 11, 0, 17, 0, 1, 4, 11, 11, 0, 26]\n",
            "adım  734 / 1000 | kayıp 2.9981, tokenler: [26, 15, 7, 8, 11, 14, 15, 0, 19, 4, 4, 17, 26]\n",
            "adım  735 / 1000 | kayıp 3.1957, tokenler: [26, 22, 8, 18, 3, 14, 12, 26]\n",
            "adım  736 / 1000 | kayıp 2.4961, tokenler: [26, 9, 0, 6, 4, 17, 26]\n",
            "adım  737 / 1000 | kayıp 3.1245, tokenler: [26, 0, 11, 4, 23, 18, 0, 13, 3, 17, 0, 26]\n",
            "adım  738 / 1000 | kayıp 1.8570, tokenler: [26, 9, 0, 24, 3, 4, 13, 26]\n",
            "adım  739 / 1000 | kayıp 2.1931, tokenler: [26, 25, 0, 21, 8, 14, 17, 26]\n",
            "adım  740 / 1000 | kayıp 3.2648, tokenler: [26, 18, 14, 5, 8, 26]\n",
            "adım  741 / 1000 | kayıp 2.7264, tokenler: [26, 11, 4, 19, 19, 8, 26]\n",
            "adım  742 / 1000 | kayıp 2.7551, tokenler: [26, 2, 24, 3, 13, 4, 4, 26]\n",
            "adım  743 / 1000 | kayıp 2.4624, tokenler: [26, 9, 20, 3, 8, 0, 26]\n",
            "adım  744 / 1000 | kayıp 2.4762, tokenler: [26, 0, 12, 8, 10, 14, 26]\n",
            "adım  745 / 1000 | kayıp 2.1545, tokenler: [26, 10, 7, 24, 17, 4, 13, 26]\n",
            "adım  746 / 1000 | kayıp 2.8443, tokenler: [26, 8, 13, 3, 8, 6, 14, 26]\n",
            "adım  747 / 1000 | kayıp 2.7363, tokenler: [26, 4, 19, 19, 0, 11, 24, 13, 26]\n",
            "adım  748 / 1000 | kayıp 2.8508, tokenler: [26, 12, 0, 3, 24, 23, 26]\n",
            "adım  749 / 1000 | kayıp 2.4379, tokenler: [26, 4, 11, 8, 25, 4, 1, 4, 19, 7, 26]\n",
            "adım  750 / 1000 | kayıp 2.0780, tokenler: [26, 18, 7, 4, 17, 24, 11, 26]\n",
            "adım  751 / 1000 | kayıp 2.3346, tokenler: [26, 18, 0, 12, 24, 17, 0, 26]\n",
            "adım  752 / 1000 | kayıp 1.8021, tokenler: [26, 10, 0, 8, 18, 4, 13, 26]\n",
            "adım  753 / 1000 | kayıp 3.0455, tokenler: [26, 11, 24, 18, 26]\n",
            "adım  754 / 1000 | kayıp 2.4193, tokenler: [26, 0, 11, 8, 2, 9, 0, 26]\n",
            "adım  755 / 1000 | kayıp 2.6941, tokenler: [26, 7, 0, 13, 4, 4, 5, 26]\n",
            "adım  756 / 1000 | kayıp 2.6088, tokenler: [26, 10, 4, 13, 3, 17, 8, 10, 26]\n",
            "adım  757 / 1000 | kayıp 2.4175, tokenler: [26, 9, 0, 2, 8, 13, 19, 14, 26]\n",
            "adım  758 / 1000 | kayıp 2.3642, tokenler: [26, 1, 17, 4, 24, 4, 17, 26]\n",
            "adım  759 / 1000 | kayıp 2.2976, tokenler: [26, 2, 24, 13, 8, 0, 7, 26]\n",
            "adım  760 / 1000 | kayıp 2.6314, tokenler: [26, 0, 19, 7, 25, 8, 17, 24, 26]\n",
            "adım  761 / 1000 | kayıp 2.4459, tokenler: [26, 12, 0, 11, 0, 24, 18, 8, 0, 26]\n",
            "adım  762 / 1000 | kayıp 2.1060, tokenler: [26, 18, 4, 24, 3, 8, 13, 0, 26]\n",
            "adım  763 / 1000 | kayıp 2.1103, tokenler: [26, 10, 4, 13, 3, 17, 0, 26]\n",
            "adım  764 / 1000 | kayıp 2.0754, tokenler: [26, 18, 0, 17, 0, 1, 8, 26]\n",
            "adım  765 / 1000 | kayıp 2.0023, tokenler: [26, 9, 4, 17, 14, 13, 4, 26]\n",
            "adım  766 / 1000 | kayıp 2.4650, tokenler: [26, 3, 0, 10, 0, 17, 0, 8, 26]\n",
            "adım  767 / 1000 | kayıp 2.7972, tokenler: [26, 9, 0, 25, 25, 12, 8, 13, 26]\n",
            "adım  768 / 1000 | kayıp 2.5172, tokenler: [26, 24, 0, 18, 7, 20, 0, 26]\n",
            "adım  769 / 1000 | kayıp 1.9687, tokenler: [26, 9, 0, 25, 4, 11, 24, 13, 26]\n",
            "adım  770 / 1000 | kayıp 2.2378, tokenler: [26, 25, 0, 10, 4, 17, 24, 26]\n",
            "adım  771 / 1000 | kayıp 2.4757, tokenler: [26, 14, 18, 18, 8, 0, 13, 26]\n",
            "adım  772 / 1000 | kayıp 2.0182, tokenler: [26, 9, 0, 7, 14, 13, 26]\n",
            "adım  773 / 1000 | kayıp 1.7604, tokenler: [26, 10, 0, 24, 0, 13, 26]\n",
            "adım  774 / 1000 | kayıp 2.6085, tokenler: [26, 19, 0, 11, 8, 1, 26]\n",
            "adım  775 / 1000 | kayıp 2.8517, tokenler: [26, 13, 24, 14, 12, 8, 8, 26]\n",
            "adım  776 / 1000 | kayıp 1.8031, tokenler: [26, 11, 0, 17, 4, 13, 26]\n",
            "adım  777 / 1000 | kayıp 2.8917, tokenler: [26, 14, 18, 8, 13, 0, 2, 7, 8, 26]\n",
            "adım  778 / 1000 | kayıp 2.0491, tokenler: [26, 12, 4, 4, 18, 7, 0, 26]\n",
            "adım  779 / 1000 | kayıp 2.7976, tokenler: [26, 18, 0, 12, 22, 4, 11, 11, 26]\n",
            "adım  780 / 1000 | kayıp 2.0455, tokenler: [26, 0, 17, 4, 4, 13, 26]\n",
            "adım  781 / 1000 | kayıp 1.8593, tokenler: [26, 12, 0, 17, 8, 10, 0, 26]\n",
            "adım  782 / 1000 | kayıp 2.8120, tokenler: [26, 4, 10, 17, 4, 12, 26]\n",
            "adım  783 / 1000 | kayıp 1.7626, tokenler: [26, 19, 0, 24, 11, 4, 13, 26]\n",
            "adım  784 / 1000 | kayıp 2.4415, tokenler: [26, 18, 4, 21, 4, 17, 8, 3, 4, 26]\n",
            "adım  785 / 1000 | kayıp 2.2726, tokenler: [26, 0, 17, 2, 4, 11, 8, 0, 26]\n",
            "adım  786 / 1000 | kayıp 2.1308, tokenler: [26, 12, 0, 10, 0, 8, 0, 7, 26]\n",
            "adım  787 / 1000 | kayıp 2.6911, tokenler: [26, 6, 17, 0, 2, 8, 4, 11, 24, 13, 13, 26]\n",
            "adım  788 / 1000 | kayıp 2.7761, tokenler: [26, 18, 10, 0, 8, 8, 26]\n",
            "adım  789 / 1000 | kayıp 1.9803, tokenler: [26, 0, 3, 0, 17, 0, 7, 26]\n",
            "adım  790 / 1000 | kayıp 2.2568, tokenler: [26, 19, 24, 0, 8, 17, 0, 26]\n",
            "adım  791 / 1000 | kayıp 2.1672, tokenler: [26, 0, 13, 0, 18, 26]\n",
            "adım  792 / 1000 | kayıp 2.1728, tokenler: [26, 0, 25, 0, 17, 8, 24, 0, 7, 26]\n",
            "adım  793 / 1000 | kayıp 2.1669, tokenler: [26, 1, 17, 24, 3, 14, 13, 26]\n",
            "adım  794 / 1000 | kayıp 2.2664, tokenler: [26, 9, 0, 10, 0, 24, 11, 13, 26]\n",
            "adım  795 / 1000 | kayıp 1.9224, tokenler: [26, 11, 0, 8, 11, 0, 7, 26]\n",
            "adım  796 / 1000 | kayıp 2.4312, tokenler: [26, 0, 11, 19, 4, 17, 26]\n",
            "adım  797 / 1000 | kayıp 2.1678, tokenler: [26, 0, 2, 4, 18, 19, 14, 13, 26]\n",
            "adım  798 / 1000 | kayıp 2.7734, tokenler: [26, 21, 8, 7, 0, 26]\n",
            "adım  799 / 1000 | kayıp 1.8007, tokenler: [26, 3, 0, 17, 8, 0, 13, 13, 0, 26]\n",
            "adım  800 / 1000 | kayıp 2.2632, tokenler: [26, 0, 24, 25, 11, 8, 13, 26]\n",
            "adım  801 / 1000 | kayıp 2.1064, tokenler: [26, 12, 0, 3, 4, 11, 24, 13, 13, 4, 26]\n",
            "adım  802 / 1000 | kayıp 2.1354, tokenler: [26, 11, 0, 19, 8, 0, 26]\n",
            "adım  803 / 1000 | kayıp 1.8741, tokenler: [26, 9, 0, 25, 24, 0, 7, 26]\n",
            "adım  804 / 1000 | kayıp 1.9609, tokenler: [26, 18, 0, 1, 0, 13, 26]\n",
            "adım  805 / 1000 | kayıp 2.6330, tokenler: [26, 10, 4, 11, 2, 8, 26]\n",
            "adım  806 / 1000 | kayıp 2.1938, tokenler: [26, 13, 4, 17, 0, 26]\n",
            "adım  807 / 1000 | kayıp 2.1032, tokenler: [26, 12, 24, 0, 11, 24, 13, 13, 26]\n",
            "adım  808 / 1000 | kayıp 1.9303, tokenler: [26, 9, 0, 18, 4, 17, 26]\n",
            "adım  809 / 1000 | kayıp 2.2945, tokenler: [26, 19, 17, 8, 11, 11, 8, 14, 13, 26]\n",
            "adım  810 / 1000 | kayıp 2.0318, tokenler: [26, 0, 13, 13, 14, 17, 0, 7, 26]\n",
            "adım  811 / 1000 | kayıp 2.0004, tokenler: [26, 0, 3, 17, 8, 4, 11, 26]\n",
            "adım  812 / 1000 | kayıp 2.3280, tokenler: [26, 21, 0, 0, 13, 24, 0, 26]\n",
            "adım  813 / 1000 | kayıp 2.4433, tokenler: [26, 14, 25, 8, 4, 11, 26]\n",
            "adım  814 / 1000 | kayıp 2.2201, tokenler: [26, 25, 8, 24, 0, 7, 26]\n",
            "adım  815 / 1000 | kayıp 2.2991, tokenler: [26, 0, 11, 8, 25, 25, 0, 26]\n",
            "adım  816 / 1000 | kayıp 2.7418, tokenler: [26, 4, 12, 12, 0, 9, 0, 13, 4, 26]\n",
            "adım  817 / 1000 | kayıp 1.7048, tokenler: [26, 0, 11, 14, 13, 0, 7, 26]\n",
            "adım  818 / 1000 | kayıp 2.5284, tokenler: [26, 8, 11, 0, 8, 26]\n",
            "adım  819 / 1000 | kayıp 1.9636, tokenler: [26, 5, 0, 1, 8, 0, 13, 26]\n",
            "adım  820 / 1000 | kayıp 2.4420, tokenler: [26, 9, 0, 23, 18, 14, 13, 26]\n",
            "adım  821 / 1000 | kayıp 2.2038, tokenler: [26, 0, 11, 11, 8, 25, 14, 13, 26]\n",
            "adım  822 / 1000 | kayıp 2.5172, tokenler: [26, 0, 11, 7, 0, 18, 18, 0, 13, 4, 26]\n",
            "adım  823 / 1000 | kayıp 1.7077, tokenler: [26, 9, 0, 12, 8, 0, 7, 26]\n",
            "adım  824 / 1000 | kayıp 2.2398, tokenler: [26, 24, 0, 11, 8, 26]\n",
            "adım  825 / 1000 | kayıp 2.8151, tokenler: [26, 4, 23, 0, 13, 3, 4, 17, 26]\n",
            "adım  826 / 1000 | kayıp 2.4977, tokenler: [26, 17, 14, 13, 13, 4, 11, 11, 26]\n",
            "adım  827 / 1000 | kayıp 2.6141, tokenler: [26, 24, 20, 2, 7, 4, 13, 26]\n",
            "adım  828 / 1000 | kayıp 2.7821, tokenler: [26, 13, 20, 18, 0, 8, 1, 0, 7, 26]\n",
            "adım  829 / 1000 | kayıp 1.8019, tokenler: [26, 9, 0, 4, 11, 0, 26]\n",
            "adım  830 / 1000 | kayıp 2.4835, tokenler: [26, 17, 24, 0, 7, 26]\n",
            "adım  831 / 1000 | kayıp 2.0712, tokenler: [26, 25, 24, 0, 13, 0, 26]\n",
            "adım  832 / 1000 | kayıp 2.0766, tokenler: [26, 9, 14, 24, 0, 13, 13, 0, 26]\n",
            "adım  833 / 1000 | kayıp 1.8469, tokenler: [26, 3, 0, 17, 8, 4, 26]\n",
            "adım  834 / 1000 | kayıp 2.2951, tokenler: [26, 12, 14, 11, 11, 8, 4, 26]\n",
            "adım  835 / 1000 | kayıp 2.4414, tokenler: [26, 12, 0, 23, 8, 26]\n",
            "adım  836 / 1000 | kayıp 2.5103, tokenler: [26, 9, 8, 14, 21, 0, 13, 13, 24, 26]\n",
            "adım  837 / 1000 | kayıp 3.3694, tokenler: [26, 6, 4, 0, 26]\n",
            "adım  838 / 1000 | kayıp 2.3500, tokenler: [26, 0, 17, 8, 0, 3, 13, 4, 26]\n",
            "adım  839 / 1000 | kayıp 2.3950, tokenler: [26, 6, 17, 0, 24, 11, 14, 13, 26]\n",
            "adım  840 / 1000 | kayıp 2.5399, tokenler: [26, 3, 4, 21, 0, 17, 18, 7, 26]\n",
            "adım  841 / 1000 | kayıp 2.9150, tokenler: [26, 18, 4, 24, 13, 0, 1, 14, 20, 26]\n",
            "adım  842 / 1000 | kayıp 2.4967, tokenler: [26, 8, 11, 24, 4, 18, 26]\n",
            "adım  843 / 1000 | kayıp 1.9816, tokenler: [26, 9, 4, 12, 8, 13, 0, 26]\n",
            "adım  844 / 1000 | kayıp 2.6846, tokenler: [26, 12, 0, 10, 26]\n",
            "adım  845 / 1000 | kayıp 2.5020, tokenler: [26, 9, 0, 8, 2, 14, 1, 26]\n",
            "adım  846 / 1000 | kayıp 1.8127, tokenler: [26, 2, 0, 4, 11, 8, 13, 26]\n",
            "adım  847 / 1000 | kayıp 2.8528, tokenler: [26, 7, 20, 18, 13, 0, 26]\n",
            "adım  848 / 1000 | kayıp 2.0746, tokenler: [26, 2, 0, 21, 4, 13, 26]\n",
            "adım  849 / 1000 | kayıp 1.5794, tokenler: [26, 10, 0, 21, 8, 0, 13, 26]\n",
            "adım  850 / 1000 | kayıp 2.4860, tokenler: [26, 4, 11, 11, 8, 4, 19, 19, 26]\n",
            "adım  851 / 1000 | kayıp 2.7039, tokenler: [26, 17, 0, 10, 4, 1, 26]\n",
            "adım  852 / 1000 | kayıp 2.1478, tokenler: [26, 3, 0, 12, 24, 17, 0, 26]\n",
            "adım  853 / 1000 | kayıp 2.3845, tokenler: [26, 0, 17, 19, 8, 4, 26]\n",
            "adım  854 / 1000 | kayıp 2.3782, tokenler: [26, 4, 11, 4, 14, 13, 14, 17, 0, 26]\n",
            "adım  855 / 1000 | kayıp 2.3659, tokenler: [26, 12, 0, 6, 3, 0, 11, 8, 13, 0, 26]\n",
            "adım  856 / 1000 | kayıp 2.1089, tokenler: [26, 11, 4, 4, 14, 13, 13, 0, 26]\n",
            "adım  857 / 1000 | kayıp 2.8112, tokenler: [26, 17, 4, 12, 24, 26]\n",
            "adım  858 / 1000 | kayıp 2.7589, tokenler: [26, 15, 17, 0, 13, 18, 7, 8, 26]\n",
            "adım  859 / 1000 | kayıp 2.1425, tokenler: [26, 18, 19, 4, 11, 11, 0, 7, 26]\n",
            "adım  860 / 1000 | kayıp 2.4466, tokenler: [26, 2, 0, 18, 19, 20, 11, 14, 26]\n",
            "adım  861 / 1000 | kayıp 2.6435, tokenler: [26, 2, 14, 13, 17, 0, 3, 26]\n",
            "adım  862 / 1000 | kayıp 2.6565, tokenler: [26, 3, 8, 14, 13, 8, 18, 8, 14, 26]\n",
            "adım  863 / 1000 | kayıp 2.5271, tokenler: [26, 17, 0, 3, 22, 0, 13, 26]\n",
            "adım  864 / 1000 | kayıp 3.1404, tokenler: [26, 5, 14, 17, 3, 26]\n",
            "adım  865 / 1000 | kayıp 2.0112, tokenler: [26, 18, 0, 1, 8, 7, 0, 26]\n",
            "adım  866 / 1000 | kayıp 2.0564, tokenler: [26, 0, 13, 3, 14, 13, 26]\n",
            "adım  867 / 1000 | kayıp 2.1266, tokenler: [26, 10, 4, 18, 19, 4, 17, 26]\n",
            "adım  868 / 1000 | kayıp 1.8993, tokenler: [26, 18, 0, 12, 0, 17, 8, 26]\n",
            "adım  869 / 1000 | kayıp 2.4955, tokenler: [26, 5, 0, 13, 20, 4, 11, 26]\n",
            "adım  870 / 1000 | kayıp 2.7364, tokenler: [26, 3, 14, 12, 8, 13, 8, 10, 26]\n",
            "adım  871 / 1000 | kayıp 2.2273, tokenler: [26, 8, 11, 4, 4, 13, 26]\n",
            "adım  872 / 1000 | kayıp 2.3312, tokenler: [26, 9, 14, 14, 13, 26]\n",
            "adım  873 / 1000 | kayıp 2.7687, tokenler: [26, 2, 14, 20, 17, 19, 11, 24, 13, 26]\n",
            "adım  874 / 1000 | kayıp 2.2820, tokenler: [26, 14, 2, 4, 0, 13, 13, 0, 26]\n",
            "adım  875 / 1000 | kayıp 2.2595, tokenler: [26, 10, 4, 13, 25, 4, 4, 26]\n",
            "adım  876 / 1000 | kayıp 2.3459, tokenler: [26, 13, 0, 7, 14, 12, 26]\n",
            "adım  877 / 1000 | kayıp 2.0663, tokenler: [26, 10, 8, 0, 24, 0, 26]\n",
            "adım  878 / 1000 | kayıp 2.7865, tokenler: [26, 9, 4, 19, 7, 17, 14, 26]\n",
            "adım  879 / 1000 | kayıp 2.1826, tokenler: [26, 0, 13, 6, 4, 11, 24, 13, 4, 26]\n",
            "adım  880 / 1000 | kayıp 2.6298, tokenler: [26, 0, 3, 3, 11, 4, 24, 26]\n",
            "adım  881 / 1000 | kayıp 2.3814, tokenler: [26, 4, 12, 0, 13, 8, 8, 26]\n",
            "adım  882 / 1000 | kayıp 1.8578, tokenler: [26, 4, 3, 4, 11, 24, 13, 26]\n",
            "adım  883 / 1000 | kayıp 2.1931, tokenler: [26, 25, 0, 8, 0, 26]\n",
            "adım  884 / 1000 | kayıp 2.1980, tokenler: [26, 11, 14, 17, 2, 0, 13, 26]\n",
            "adım  885 / 1000 | kayıp 2.2070, tokenler: [26, 12, 4, 17, 8, 18, 18, 0, 26]\n",
            "adım  886 / 1000 | kayıp 2.1261, tokenler: [26, 17, 8, 24, 0, 7, 26]\n",
            "adım  887 / 1000 | kayıp 3.0004, tokenler: [26, 8, 13, 5, 8, 13, 8, 19, 8, 26]\n",
            "adım  888 / 1000 | kayıp 2.2790, tokenler: [26, 10, 8, 13, 11, 4, 24, 26]\n",
            "adım  889 / 1000 | kayıp 2.6385, tokenler: [26, 14, 12, 4, 8, 17, 26]\n",
            "adım  890 / 1000 | kayıp 2.0798, tokenler: [26, 25, 8, 13, 13, 8, 0, 26]\n",
            "adım  891 / 1000 | kayıp 2.1188, tokenler: [26, 10, 0, 24, 2, 8, 14, 13, 26]\n",
            "adım  892 / 1000 | kayıp 3.4579, tokenler: [26, 10, 13, 14, 23, 26]\n",
            "adım  893 / 1000 | kayıp 2.0826, tokenler: [26, 9, 4, 12, 0, 17, 26]\n",
            "adım  894 / 1000 | kayıp 1.7378, tokenler: [26, 0, 11, 8, 11, 0, 26]\n",
            "adım  895 / 1000 | kayıp 2.0197, tokenler: [26, 3, 4, 18, 19, 24, 13, 26]\n",
            "adım  896 / 1000 | kayıp 2.4508, tokenler: [26, 18, 7, 4, 17, 22, 8, 13, 26]\n",
            "adım  897 / 1000 | kayıp 2.2737, tokenler: [26, 0, 21, 4, 17, 24, 26]\n",
            "adım  898 / 1000 | kayıp 1.9217, tokenler: [26, 0, 13, 0, 17, 4, 11, 24, 26]\n",
            "adım  899 / 1000 | kayıp 2.2933, tokenler: [26, 9, 4, 17, 0, 12, 24, 26]\n",
            "adım  900 / 1000 | kayıp 2.7785, tokenler: [26, 1, 14, 24, 2, 4, 26]\n",
            "adım  901 / 1000 | kayıp 2.0881, tokenler: [26, 3, 0, 11, 0, 13, 24, 26]\n",
            "adım  902 / 1000 | kayıp 2.3490, tokenler: [26, 10, 4, 13, 13, 0, 17, 3, 26]\n",
            "adım  903 / 1000 | kayıp 1.7459, tokenler: [26, 9, 0, 12, 8, 17, 0, 26]\n",
            "adım  904 / 1000 | kayıp 2.0612, tokenler: [26, 0, 0, 11, 8, 0, 7, 26]\n",
            "adım  905 / 1000 | kayıp 2.1511, tokenler: [26, 3, 0, 17, 17, 8, 4, 11, 11, 4, 26]\n",
            "adım  906 / 1000 | kayıp 1.9278, tokenler: [26, 18, 0, 12, 4, 24, 0, 26]\n",
            "adım  907 / 1000 | kayıp 2.6180, tokenler: [26, 4, 8, 14, 13, 26]\n",
            "adım  908 / 1000 | kayıp 2.3714, tokenler: [26, 3, 4, 13, 21, 4, 17, 26]\n",
            "adım  909 / 1000 | kayıp 2.2607, tokenler: [26, 0, 17, 3, 8, 18, 26]\n",
            "adım  910 / 1000 | kayıp 2.7556, tokenler: [26, 17, 8, 14, 19, 19, 26]\n",
            "adım  911 / 1000 | kayıp 2.2940, tokenler: [26, 18, 0, 17, 10, 8, 18, 26]\n",
            "adım  912 / 1000 | kayıp 2.6726, tokenler: [26, 11, 24, 13, 4, 23, 26]\n",
            "adım  913 / 1000 | kayıp 2.4291, tokenler: [26, 17, 7, 24, 0, 13, 26]\n",
            "adım  914 / 1000 | kayıp 2.8404, tokenler: [26, 19, 4, 3, 17, 8, 2, 10, 26]\n",
            "adım  915 / 1000 | kayıp 2.2663, tokenler: [26, 17, 14, 13, 25, 0, 26]\n",
            "adım  916 / 1000 | kayıp 2.3037, tokenler: [26, 12, 8, 2, 0, 26]\n",
            "adım  917 / 1000 | kayıp 2.2782, tokenler: [26, 9, 20, 1, 17, 0, 13, 26]\n",
            "adım  918 / 1000 | kayıp 2.4194, tokenler: [26, 1, 11, 0, 8, 13, 4, 26]\n",
            "adım  919 / 1000 | kayıp 2.4164, tokenler: [26, 10, 14, 11, 4, 19, 19, 4, 26]\n",
            "adım  920 / 1000 | kayıp 2.6305, tokenler: [26, 18, 22, 0, 13, 26]\n",
            "adım  921 / 1000 | kayıp 1.9157, tokenler: [26, 10, 0, 13, 4, 26]\n",
            "adım  922 / 1000 | kayıp 1.8924, tokenler: [26, 4, 12, 8, 11, 8, 0, 26]\n",
            "adım  923 / 1000 | kayıp 2.0604, tokenler: [26, 2, 0, 17, 8, 18, 18, 0, 26]\n",
            "adım  924 / 1000 | kayıp 2.5970, tokenler: [26, 2, 7, 0, 17, 3, 14, 13, 13, 0, 24, 26]\n",
            "adım  925 / 1000 | kayıp 2.1268, tokenler: [26, 0, 11, 4, 12, 26]\n",
            "adım  926 / 1000 | kayıp 2.0386, tokenler: [26, 18, 0, 8, 4, 17, 26]\n",
            "adım  927 / 1000 | kayıp 2.5987, tokenler: [26, 12, 4, 4, 10, 14, 26]\n",
            "adım  928 / 1000 | kayıp 2.3180, tokenler: [26, 11, 20, 8, 18, 0, 13, 0, 26]\n",
            "adım  929 / 1000 | kayıp 1.8104, tokenler: [26, 3, 0, 21, 8, 0, 13, 0, 26]\n",
            "adım  930 / 1000 | kayıp 2.4971, tokenler: [26, 8, 18, 14, 1, 4, 11, 11, 0, 26]\n",
            "adım  931 / 1000 | kayıp 3.1351, tokenler: [26, 18, 7, 0, 16, 20, 0, 13, 26]\n",
            "adım  932 / 1000 | kayıp 2.3636, tokenler: [26, 8, 3, 0, 11, 24, 26]\n",
            "adım  933 / 1000 | kayıp 2.4958, tokenler: [26, 18, 24, 12, 8, 17, 26]\n",
            "adım  934 / 1000 | kayıp 2.1538, tokenler: [26, 3, 0, 13, 8, 11, 14, 26]\n",
            "adım  935 / 1000 | kayıp 2.0586, tokenler: [26, 1, 0, 24, 0, 13, 26]\n",
            "adım  936 / 1000 | kayıp 1.8687, tokenler: [26, 10, 0, 24, 4, 13, 26]\n",
            "adım  937 / 1000 | kayıp 1.8116, tokenler: [26, 0, 3, 0, 11, 4, 13, 0, 26]\n",
            "adım  938 / 1000 | kayıp 1.6251, tokenler: [26, 3, 4, 17, 8, 0, 13, 26]\n",
            "adım  939 / 1000 | kayıp 1.9955, tokenler: [26, 0, 12, 8, 17, 24, 0, 7, 26]\n",
            "adım  940 / 1000 | kayıp 1.7995, tokenler: [26, 0, 11, 11, 4, 13, 26]\n",
            "adım  941 / 1000 | kayıp 1.9697, tokenler: [26, 19, 24, 11, 0, 13, 26]\n",
            "adım  942 / 1000 | kayıp 2.1796, tokenler: [26, 2, 0, 17, 11, 14, 18, 26]\n",
            "adım  943 / 1000 | kayıp 1.9453, tokenler: [26, 2, 0, 13, 0, 0, 13, 26]\n",
            "adım  944 / 1000 | kayıp 2.6730, tokenler: [26, 3, 20, 6, 0, 13, 26]\n",
            "adım  945 / 1000 | kayıp 2.1508, tokenler: [26, 0, 1, 17, 0, 26]\n",
            "adım  946 / 1000 | kayıp 2.3271, tokenler: [26, 9, 4, 17, 12, 4, 11, 11, 26]\n",
            "adım  947 / 1000 | kayıp 2.0929, tokenler: [26, 1, 17, 4, 13, 13, 0, 13, 26]\n",
            "adım  948 / 1000 | kayıp 1.7849, tokenler: [26, 12, 0, 13, 14, 13, 26]\n",
            "adım  949 / 1000 | kayıp 1.9801, tokenler: [26, 1, 0, 24, 0, 13, 26]\n",
            "adım  950 / 1000 | kayıp 2.3016, tokenler: [26, 0, 21, 24, 13, 26]\n",
            "adım  951 / 1000 | kayıp 2.7790, tokenler: [26, 11, 20, 25, 12, 0, 17, 8, 0, 26]\n",
            "adım  952 / 1000 | kayıp 2.0783, tokenler: [26, 25, 0, 13, 24, 11, 0, 7, 26]\n",
            "adım  953 / 1000 | kayıp 2.2319, tokenler: [26, 12, 0, 4, 21, 0, 26]\n",
            "adım  954 / 1000 | kayıp 2.1295, tokenler: [26, 13, 8, 0, 11, 0, 26]\n",
            "adım  955 / 1000 | kayıp 2.5928, tokenler: [26, 4, 11, 8, 14, 4, 13, 0, 8, 26]\n",
            "adım  956 / 1000 | kayıp 3.0061, tokenler: [26, 8, 14, 18, 4, 5, 0, 26]\n",
            "adım  957 / 1000 | kayıp 2.1160, tokenler: [26, 8, 24, 0, 13, 0, 7, 26]\n",
            "adım  958 / 1000 | kayıp 2.2593, tokenler: [26, 21, 8, 13, 8, 18, 7, 0, 26]\n",
            "adım  959 / 1000 | kayıp 2.0209, tokenler: [26, 0, 25, 4, 11, 4, 0, 26]\n",
            "adım  960 / 1000 | kayıp 2.1214, tokenler: [26, 10, 4, 24, 6, 0, 13, 26]\n",
            "adım  961 / 1000 | kayıp 2.2633, tokenler: [26, 12, 8, 8, 0, 26]\n",
            "adım  962 / 1000 | kayıp 2.3385, tokenler: [26, 17, 8, 19, 19, 4, 17, 26]\n",
            "adım  963 / 1000 | kayıp 2.5537, tokenler: [26, 2, 7, 8, 18, 14, 12, 26]\n",
            "adım  964 / 1000 | kayıp 2.7235, tokenler: [26, 17, 14, 24, 0, 11, 19, 24, 26]\n",
            "adım  965 / 1000 | kayıp 3.3042, tokenler: [26, 13, 20, 17, 26]\n",
            "adım  966 / 1000 | kayıp 2.1621, tokenler: [26, 12, 0, 10, 18, 14, 13, 26]\n",
            "adım  967 / 1000 | kayıp 2.9326, tokenler: [26, 1, 4, 2, 10, 4, 19, 19, 26]\n",
            "adım  968 / 1000 | kayıp 1.8063, tokenler: [26, 9, 14, 13, 13, 0, 26]\n",
            "adım  969 / 1000 | kayıp 2.2380, tokenler: [26, 9, 0, 0, 25, 8, 4, 11, 26]\n",
            "adım  970 / 1000 | kayıp 1.9579, tokenler: [26, 0, 11, 0, 24, 11, 0, 7, 26]\n",
            "adım  971 / 1000 | kayıp 2.3572, tokenler: [26, 6, 8, 0, 13, 13, 8, 26]\n",
            "adım  972 / 1000 | kayıp 2.1710, tokenler: [26, 25, 8, 3, 14, 13, 26]\n",
            "adım  973 / 1000 | kayıp 2.5142, tokenler: [26, 13, 14, 20, 17, 8, 26]\n",
            "adım  974 / 1000 | kayıp 2.0779, tokenler: [26, 0, 21, 4, 13, 26]\n",
            "adım  975 / 1000 | kayıp 1.9271, tokenler: [26, 0, 17, 8, 4, 0, 13, 13, 0, 26]\n",
            "adım  976 / 1000 | kayıp 2.0277, tokenler: [26, 9, 0, 24, 4, 18, 7, 26]\n",
            "adım  977 / 1000 | kayıp 2.5328, tokenler: [26, 18, 24, 17, 0, 8, 26]\n",
            "adım  978 / 1000 | kayıp 1.8817, tokenler: [26, 0, 11, 4, 18, 0, 26]\n",
            "adım  979 / 1000 | kayıp 1.9636, tokenler: [26, 2, 0, 8, 3, 24, 13, 26]\n",
            "adım  980 / 1000 | kayıp 1.9525, tokenler: [26, 25, 4, 11, 0, 24, 0, 26]\n",
            "adım  981 / 1000 | kayıp 2.4269, tokenler: [26, 0, 25, 17, 4, 0, 11, 26]\n",
            "adım  982 / 1000 | kayıp 2.8226, tokenler: [26, 7, 4, 0, 21, 4, 13, 11, 4, 8, 6, 7, 26]\n",
            "adım  983 / 1000 | kayıp 2.4713, tokenler: [26, 9, 0, 25, 25, 11, 4, 4, 13, 26]\n",
            "adım  984 / 1000 | kayıp 2.0303, tokenler: [26, 17, 8, 4, 11, 11, 4, 26]\n",
            "adım  985 / 1000 | kayıp 2.7422, tokenler: [26, 11, 8, 13, 3, 18, 0, 24, 26]\n",
            "adım  986 / 1000 | kayıp 2.6811, tokenler: [26, 22, 8, 11, 11, 18, 14, 13, 26]\n",
            "adım  987 / 1000 | kayıp 1.9173, tokenler: [26, 18, 7, 0, 13, 13, 14, 13, 26]\n",
            "adım  988 / 1000 | kayıp 2.4303, tokenler: [26, 11, 14, 0, 13, 24, 26]\n",
            "adım  989 / 1000 | kayıp 2.4466, tokenler: [26, 17, 24, 4, 11, 11, 26]\n",
            "adım  990 / 1000 | kayıp 2.6354, tokenler: [26, 1, 17, 8, 6, 7, 19, 14, 13, 26]\n",
            "adım  991 / 1000 | kayıp 2.1729, tokenler: [26, 18, 7, 0, 17, 14, 3, 26]\n",
            "adım  992 / 1000 | kayıp 1.9659, tokenler: [26, 10, 0, 24, 11, 4, 0, 7, 26]\n",
            "adım  993 / 1000 | kayıp 2.4409, tokenler: [26, 14, 11, 0, 12, 8, 3, 4, 26]\n",
            "adım  994 / 1000 | kayıp 1.9618, tokenler: [26, 17, 14, 11, 0, 13, 26]\n",
            "adım  995 / 1000 | kayıp 2.5188, tokenler: [26, 9, 7, 14, 17, 3, 0, 13, 26]\n",
            "adım  996 / 1000 | kayıp 2.1018, tokenler: [26, 9, 4, 13, 4, 4, 26]\n",
            "adım  997 / 1000 | kayıp 1.7791, tokenler: [26, 0, 11, 14, 13, 26]\n",
            "adım  998 / 1000 | kayıp 2.4764, tokenler: [26, 14, 2, 4, 0, 13, 8, 0, 26]\n",
            "adım  999 / 1000 | kayıp 2.4730, tokenler: [26, 8, 13, 18, 8, 24, 0, 26]\n",
            "adım 1000 / 1000 | kayıp 2.6497, tokenler: [26, 0, 10, 8, 14, 26]\n"
          ]
        }
      ],
      "source": [
        "# ADAM olsun, kutsanmış optimize edici\n",
        "learning_rate, beta1, beta2, eps_adam = 0.01, 0.85, 0.99, 1e-8 # ADAM hiperparametreleri\n",
        "m = [0.0] * len(params) # birinci moment\n",
        "v = [0.0] * len(params) # ikinci moment\n",
        "\n",
        "# Sırayla tekrarla\n",
        "num_steps = 1000 # eğitim adımı sayısı\n",
        "for step in range(num_steps):\n",
        "\n",
        "    # Tek bir doküman al, tokenize et, iki yanına BAS özel token’ını koy\n",
        "    doc = docs[step % len(docs)] # her eğitim adımında 1 döküman işliyoruz (batch büyüklüğü = 1)\n",
        "    tokens = [BAS] + [uchars.index(ch) for ch in doc] + [BAS] #  Tokenleri oluştur (Harfin uchars listesi içindeki sırası o harfin token id'sini veriyor)\n",
        "    n = min(block_size, len(tokens) - 1) # dizi boyutu (en fazla block_size = 16)\n",
        "    # Token dizisini modelden geçir, kayba kadar tüm hesaplama grafiğini kur.\n",
        "    keys, values = [[] for _ in range(n_layer)], [[] for _ in range(n_layer)]\n",
        "    losses = [] # Dizi boyunca her token için hesaplanacak kayıpların listesi\n",
        "    for pos_id in range(n): # dizi boyunca pozisyonları gez\n",
        "        token_id, target_id = tokens[pos_id], tokens[pos_id + 1] # şimdiki token ve bir sonraki token. bir sonraki token target (eğitim hedefi) olacak.\n",
        "        logits = gpt(token_id, pos_id, keys, values) # gpt modelimizi şimdiki tokeni ve pozisyonunu vererek ileri yönlü çalıştır. gelecek token tahmini için logitleri dönecek.\n",
        "        probs = softmax(logits) # Softmax ile logitleri toplamları 1.0 olan olasılık değerlerine çevir.\n",
        "        loss_t = -probs[target_id].log() # KAYIP Fonksiyonu: Çapraz Entropi (Cross Entropy). Doğru target için modelin verdiği olasılıpın negatif logu.\n",
        "        losses.append(loss_t) # kayıplar listesine ekle\n",
        "    loss = (1 / n) * sum(losses) # doküman dizisi üzerindeki nihai ortalama kayıp. Düşük olsun.\n",
        "\n",
        "    # Kaybı geri yay, tüm model parametrelerine göre gradyanları hesapla.\n",
        "    loss.backward()\n",
        "\n",
        "    # Adam güncellemesi: gradyanlara göre model parametrelerini güncelle.\n",
        "    lr_t = learning_rate * (1 - step / num_steps) # doğrusal öğrenme oranı azaltımı\n",
        "    for i, p in enumerate(params):\n",
        "        m[i] = beta1 * m[i] + (1 - beta1) * p.grad # birinci moment. momentum.\n",
        "        v[i] = beta2 * v[i] + (1 - beta2) * p.grad ** 2 # ikinci moment\n",
        "        m_hat = m[i] / (1 - beta1 ** (step + 1)) # birinci moment sapma duzeltmesi\n",
        "        v_hat = v[i] / (1 - beta2 ** (step + 1)) # ikinci moment sapma duzeltmesi\n",
        "        p.data -= lr_t * m_hat / (v_hat ** 0.5 + eps_adam) # parametre güncellemesi\n",
        "        p.grad = 0 # sonraki eğitim adımı için gradyanı sıfırla\n",
        "\n",
        "    print(f\"adım {step+1:4d} / {num_steps:4d} | kayıp {loss.data:.4f}, tokenler: {tokens}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ySdqNyV308U"
      },
      "source": [
        "## Çıkarım\n",
        "**Çıkarım** (**Inference** veya **Generation**) için eğitimdekine benzer şekilde yine `gpt()` fonksiyonunu kullanacağız. Yeni bir isim üretmesi için girdi olarak 'BAS' (dizi başlangıcı, 26 id'li token) tokenini veriyoruz. Hatırlarsanız eğitimde de her ismin başına ve sonuna bu tokenden koymuştuk.\n",
        "\n",
        "`gpt`'nin döndürdüğü logitleri yine softmax ile olasılığa döndüreceğiz. Fakat burada ufak bir farklılık var: `temperature` (**Sıcaklık**) parametresi. Bu sıcaklık parametresini yükseltmek olasılık dağılımını biraz daha rastgele hale getiriyor. `temperature = 1` olursa eğitimde kullandığımız dağılımın aynısı olacak. 1'den küçük değerler dağılımı daha çok keskinleştirecek, yani büyük değerlere daha çok olasılık atayacak. Sıcaklık sıfıra yakşatıkça maksimum dışındaki her tokenin olasılığı sıfıra yaklaşacak. Sıcaklık büyük bir sayı olduğunda ise tersine, **Uniform (Düzgün) dağılım**a benzemeye başlayacak ve her tokenin seçilme şansı artacak.\n",
        "\n",
        "Sonrasında, `random.choices` ile oluşturduğumuz bu **olasılık dağılımını kullanarak** bir harf örnekliyoruz.\n",
        "\n",
        "Bunu harf üretme işini BAS tokeni gelene veya `block_size = 16` sınırına ulaşana kadar tekrar ettiğimizde ismimiz üretilmiş."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbwNkQ-ZR_6O",
        "outputId": "9d4b8ff0-aec2-437f-b4de-1b582a6d0767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- çıkarım (yeni, halüsinasyon isimler) ---\n",
            "örnek  1: kamon\n",
            "örnek  2: ann\n",
            "örnek  3: karai\n",
            "örnek  4: jaire\n",
            "örnek  5: vialan\n",
            "örnek  6: karia\n",
            "örnek  7: yeran\n",
            "örnek  8: anna\n",
            "örnek  9: areli\n",
            "örnek 10: kaina\n",
            "örnek 11: konna\n",
            "örnek 12: keylen\n",
            "örnek 13: liole\n",
            "örnek 14: alerin\n",
            "örnek 15: earan\n",
            "örnek 16: lenne\n",
            "örnek 17: kana\n",
            "örnek 18: lara\n",
            "örnek 19: alela\n",
            "örnek 20: anton\n"
          ]
        }
      ],
      "source": [
        "# Çıkarım (Inference): model bize geri “gevezelesin”\n",
        "temperature = 0.5 # (0, 1] aralığında, üretilen metnin “yaratıcılığını” kontrol eder, düşükten yükseğe\n",
        "print(\"\\n--- çıkarım (yeni, halüsinasyon isimler) ---\")\n",
        "for sample_idx in range(20): # üretilecek örnek (isim) sayısı\n",
        "    keys, values = [[] for _ in range(n_layer)], [[] for _ in range(n_layer)] # KV-önbelleğini boş olarak yarat\n",
        "    token_id = BAS # Dizi Başlangıç tokeni ile başlıyoruz\n",
        "    sample = [] # üreteceğimiz isim, harf listesi olarak tutulacak\n",
        "    for pos_id in range(block_size): # en fazla 16 tokenlik dizi üret\n",
        "        logits = gpt(token_id, pos_id, keys, values) # eldeki en yeni tokenle gpt'yi çağır ve logitleri üret\n",
        "        probs = softmax([l / temperature for l in logits]) # Sıcaklık kullanarak olasılıkları hesapla: softmax(logits/T)\n",
        "        token_id = random.choices(range(vocab_size), weights=[p.data for p in probs])[0] # olasılık dağılımına göre bir token örnekle\n",
        "        if token_id == BAS: # BAS tokeni gelirse üretilen isim tamamlandı demektir\n",
        "            break\n",
        "        sample.append(uchars[token_id]) # üretilen token id'yi harfe çevir ve sonuç listesine ekle\n",
        "    print(f\"örnek {sample_idx+1:2d}: {''.join(sample)}\") # üretilen ismi yazdır"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yGhFGQV72f3"
      },
      "source": [
        "## Sonuç ve Notlar\n",
        "\n",
        "Hayırlı olsun, iki gpt'nizi eğittiniz 🎉\n",
        "\n",
        "Bu arada çok basitleştirilmiş olsa da, CPU'da çalıştığı için ne kadar yavaş çalıştığını da gördünüz.\n",
        "\n",
        "GPU veya TPU gibi özelleşmiş işlemcilerin kullanılmasını sebebi yukarıda tanımladığımız matris çarpımı gibi işlemleri bu işlemcilerde paralel olarak çok daha hızlı yapabilmemiz. Ayrıca burada her adımda sadece bir isim için eğittik. Örneğin bir adet H100 GPU içinde, bu tür matris çarpımı gibi işlemler için özelleşmiş 528 tane Tensor Core, genel matematiksel işlemler için de 16896 adet CUDA çekirdeği var. Bunların her birini basit işlemciler olarak düşünebilirsiniz. Hepsi aynı anda paralel olarak çalışıyor, ve her biri yukarıdaki işlemlerin belli bir kısmını bağımsız olarak yapıyor.\n",
        "\n",
        "Gerçek sistemlerin bu örnekten farkının daha kapsamlı bir anlatımı için [Karphaty'nin blog yazısı](https://https://karpathy.github.io/2026/02/12/microgpt/)'na bakabilirsiniz. Bunların bir çoğu yukarıda yaptığımız şeyi devasa ölçeklere çıkarmak için kullanılan mühendislik tekninkleri. İşin temeli ve matematiği neredeyse hiç değişmiyor. Dolayısıyla bu temelleri iyi kavramış olmak diğer her şeye açılan kapı.\n",
        "\n",
        "Son olarak, umarım şu mesajı verebilmişimdir. GPT gibi modern Yapay Zeka modelleri ne mucizevi ve anlaşılmaz şeyler, ne de hafife alınması gereken şeyler. Elimizde basit prensiplere dayanan, ama çok güçlü, çok fazla karmaşıklaşmaya uygun bir makine var. Aldatıcı basitliğinin arkasında insanlığın ürettiği en karmaşık icatlardan biri gizleniyor. Gördüğünüz gibi bu temel prensipler sizin de rahatlıkla dokunabileceğiniz uzaklıkta. Ancak bir de buzdağının görünmeyen dev kısmı var ki oralara henüz hiçbir insan tam anlamıyla inebilmiş değil. Kim bilir, belki gelecekte oraya inenlerden biri de siz olursunuz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eHkGsCD-Hqwl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
